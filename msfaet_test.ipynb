{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# MSFAET vs CCT Performance Comparison\n",
        "## Multi-Scale Frequency-Aware EEG Transformer の性能評価\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import time\n",
        "import pickle\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchinfo import summary\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import models\n",
        "from model.cct import CCT\n",
        "from model.msfaet import MSFAET\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Model Architecture Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models for comparison\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# CCT model (original)\n",
        "cct_model = CCT(\n",
        "    kernel_sizes=[(22, 1), (1, 24)], stride=(1, 1), padding=(0, 0),\n",
        "    pooling_kernel_size=(3, 3), pooling_stride=(1, 1), pooling_padding=(0, 0),\n",
        "    n_conv_layers=2, n_input_channels=1, in_planes=64, activation=None,\n",
        "    max_pool=False, conv_bias=False, dim=64, num_layers=4, num_heads=8, num_classes=2,\n",
        "    attn_dropout=0.1, dropout=0.1, mlp_size=64, positional_emb=\"learnable\"\n",
        ").to(device)\n",
        "\n",
        "# MSFAET model (new)\n",
        "msfaet_model = MSFAET(\n",
        "    n_channels=22, n_classes=2, dim=64, depth=4, num_heads=8,\n",
        "    mlp_ratio=4., qkv_bias=True, drop_rate=0.1, attn_drop_rate=0.1\n",
        ").to(device)\n",
        "\n",
        "print(\"\\n=== Model Summary ===\")\n",
        "print(\"\\nCCT Model:\")\n",
        "summary(cct_model, input_size=(32, 1, 22, 1000), verbose=0)\n",
        "\n",
        "print(\"\\nMSFAET Model:\")\n",
        "summary(msfaet_model, input_size=(32, 1, 22, 1000), verbose=0)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
