{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.cct import CCT\n",
    "from torchinfo import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCT(kernel_sizes=[(22, 1), (1, 24), (1, 24)], stride=(1, 1), padding=(0, 0),\n",
    "            pooling_kernel_size=(3, 3), pooling_stride=(1, 1), pooling_padding=(0, 0),\n",
    "            n_conv_layers=3, n_input_channels=1,\n",
    "            in_planes=48, activation=None, # ReLU\n",
    "            max_pool=False, conv_bias=False,\n",
    "            dim=48, num_layers=2,\n",
    "            num_heads=4, num_classes=2, \n",
    "            attn_dropout=0.1, dropout=0.1, \n",
    "            mlp_size=48, positional_emb=\"learnable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "CCT (CCT)                                          [64, 1, 22, 321]     [64, 2]              --                   True\n",
       "├─Tokenizer (tokenizer)                            [64, 1, 22, 321]     [64, 275, 48]        --                   True\n",
       "│    └─Sequential (conv_layers)                    [64, 1, 22, 321]     [64, 48, 1, 275]     --                   True\n",
       "│    │    └─Sequential (0)                         [64, 1, 22, 321]     [64, 48, 1, 321]     1,056                True\n",
       "│    │    └─Sequential (1)                         [64, 48, 1, 321]     [64, 48, 1, 298]     55,296               True\n",
       "│    │    └─Sequential (2)                         [64, 48, 1, 298]     [64, 48, 1, 275]     55,296               True\n",
       "│    └─Flatten (flattener)                         [64, 48, 1, 275]     [64, 48, 275]        --                   --\n",
       "├─Transformer (transformer)                        [64, 275, 48]        [64, 2]              13,200               True\n",
       "│    └─Dropout (dropout)                           [64, 275, 48]        [64, 275, 48]        --                   --\n",
       "│    └─ModuleList (blocks)                         --                   --                   --                   True\n",
       "│    │    └─EncoderLayer (0)                       [64, 275, 48]        [64, 275, 48]        14,064               True\n",
       "│    │    └─EncoderLayer (1)                       [64, 275, 48]        [64, 275, 48]        14,064               True\n",
       "│    └─LayerNorm (norm)                            [64, 275, 48]        [64, 275, 48]        96                   True\n",
       "│    └─Linear (attention_pool)                     [64, 275, 48]        [64, 275, 1]         49                   True\n",
       "│    └─Linear (fc)                                 [64, 48]             [64, 2]              98                   True\n",
       "==================================================================================================================================\n",
       "Total params: 153,219\n",
       "Trainable params: 153,219\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.05\n",
       "==================================================================================================================================\n",
       "Input size (MB): 1.81\n",
       "Forward/backward pass size (MB): 123.49\n",
       "Params size (MB): 0.56\n",
       "Estimated Total Size (MB): 125.86\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(64, 1, 22, 321),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['datasets/aBNCI2014001R.pickle', 'datasets/aBNCI2014004R.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "data = load_data(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 321)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = ['left_hand', 'right_hand']\n",
    "subject = 0\n",
    "s1 = data[subject]\n",
    "s1.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU device name : NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dev.type == 'cuda':\n",
    "    print('Your GPU device name :', torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCCT():\n",
    "    def __init__(self, nsub, n_subj=9):\n",
    "        super(ExP, self).__init__()\n",
    "        self.batch_size = 36\n",
    "        self.n_epochs = 25  #2000\n",
    "        self.c_dim = 4\n",
    "        self.lr = 3e-5\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.dimension = (190, 50)\n",
    "        self.nSub = nsub\n",
    "        self.n_subjects = 8 # total?\n",
    "        self.start_epoch = 0\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "        self.FloatTensor = torch.cuda.FloatTensor\n",
    "\n",
    "        self.criterion_l1 = torch.nn.L1Loss().cuda()\n",
    "        self.criterion_l2 = torch.nn.MSELoss().cuda()\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = model.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to(\"cuda\")\n",
    "            \n",
    "        self.total_params = sum(param.numel() for param in self.model.parameters())\n",
    "        print(\"Number of parameters: \", self.total_params)\n",
    "\n",
    "        #self.model = self.model.cuda()\n",
    "        # summary(self.model, (1, 22, 1000))\n",
    "\n",
    "\n",
    "    # Segmentation and Reconstruction (S&R) data augmentation\n",
    "    def interaug(self, timg, label):  \n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "        for cls4aug in range(2):\n",
    "            cls_idx = np.where(label == cls4aug + 1)\n",
    "            tmp_data = timg[cls_idx]\n",
    "            tmp_label = label[cls_idx]\n",
    "\n",
    "            tmp_aug_data = np.zeros((int(self.batch_size / 2), 1, 22, 321))\n",
    "            for ri in range(int(self.batch_size / 2)):\n",
    "                for rj in range(3):\n",
    "                    rand_idx = np.random.randint(0, tmp_data.shape[0], 3)\n",
    "                    tmp_aug_data[ri, :, :, rj * 107:(rj + 1) * 107] = tmp_data[rand_idx[rj], :, :,\n",
    "                                                                      rj * 107:(rj + 1) * 107]\n",
    "\n",
    "            aug_data.append(tmp_aug_data)\n",
    "            aug_label.append(tmp_label[:int(self.batch_size / 2)])\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        aug_data = aug_data[aug_shuffle, :, :]\n",
    "        aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        aug_data = torch.from_numpy(aug_data).cuda()\n",
    "        aug_data = aug_data.float()\n",
    "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
    "        aug_label = aug_label.long()\n",
    "        return aug_data, aug_label\n",
    "\n",
    "    def get_source_data(self):\n",
    "        \n",
    "        self.test_subject = self.nSub\n",
    "\n",
    "        # Get the data from the epochs object\n",
    "        self.data = load_data(datasets[0])\n",
    "        print('Dataset: ', datasets[0])\n",
    "\n",
    "        self.train_subjects = [i for i in range(self.n_subjects) if i != self.test_subject]\n",
    "\n",
    "        # Prepare test data\n",
    "        self.X_test = self.data[self.test_subject].get_data()\n",
    "        self.y_test = self.data[self.test_subject].events[:, -1]\n",
    "\n",
    "        # Prepare training data\n",
    "        self.X_train = np.concatenate([self.data[i].get_data() for i in self.train_subjects], axis=0)\n",
    "        self.y_train = np.concatenate([self.data[i].events[:, -1] for i in self.train_subjects], axis=0)\n",
    "\n",
    "        # train and val data\n",
    "        self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(self.X_train, self.y_train, test_size=0.1, random_state=42)\n",
    "        \n",
    "        self.allData = np.expand_dims(self.train_data, axis=1)\n",
    "        self.allLabel = self.train_label\n",
    "        \n",
    "        self.valData = np.expand_dims(self.val_data, axis=1)\n",
    "        self.valLabel = self.val_label\n",
    "\n",
    "        shuffle_num = np.random.permutation(len(self.allData))\n",
    "        self.allData = self.allData[shuffle_num, :, :, :]\n",
    "        self.allLabel = self.allLabel[shuffle_num]\n",
    "\n",
    "        # test data  \n",
    "        self.testData = np.expand_dims(self.X_test, axis=1)\n",
    "        self.testLabel = self.y_test\n",
    "        \n",
    "        # standardize\n",
    "        target_mean = np.mean(self.allData)\n",
    "        target_std = np.std(self.allData)\n",
    "        self.allData = (self.allData - target_mean) / target_std\n",
    "        self.testData = (self.testData - target_mean) / target_std\n",
    "        self.valData = (self.valData - target_mean) / target_std\n",
    "\n",
    "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
    "        return self.allData, self.allLabel, self.valData, self.valLabel, self.testData, self.testLabel\n",
    "\n",
    "    def train(self):\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        #img, label, test_data, test_label = self.get_source_data()\n",
    "        img, label, val_data, val_label, test_data, test_label = self.get_source_data()\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label - 1)\n",
    "        dataset = torch.utils.data.TensorDataset(img, label)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        val_data = torch.from_numpy(val_data)\n",
    "        val_label = torch.from_numpy(val_label - 1)\n",
    "        val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label - 1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(test_label.type(self.LongTensor))\n",
    "        \n",
    "        val_data = Variable(val_data.type(self.Tensor))\n",
    "        val_label = Variable(val_label.type(self.LongTensor))\n",
    "        \n",
    "        bestAcc = 0\n",
    "        averAcc = 0\n",
    "        num = 0\n",
    "        Y_true = 0\n",
    "        Y_pred = 0\n",
    "\n",
    "        # Train the cnn model\n",
    "        total_step = len(self.dataloader)\n",
    "        curr_lr = self.lr\n",
    "\n",
    "        for e in range(self.n_epochs):\n",
    "            # in_epoch = time.time()\n",
    "            self.model.train()\n",
    "            for i, (img, label) in enumerate(self.dataloader):\n",
    "\n",
    "                img = Variable(img.cuda().type(self.Tensor))\n",
    "                label = Variable(label.cuda().type(self.LongTensor)) #FloatTensor\n",
    "\n",
    "                # data augmentation\n",
    "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "                img = torch.cat((img, aug_data))\n",
    "                label = torch.cat((label, aug_label))\n",
    "\n",
    "                outputs = self.model(img)\n",
    "\n",
    "                loss = self.criterion_cls(outputs, label) \n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # test process\n",
    "            if (e + 1) % 1 == 0:\n",
    "                self.model.eval()\n",
    "                Cls = self.model(test_data)\n",
    "                probs = softmax(Cls, dim=1).cpu().detach().numpy()\n",
    "                loss_test = self.criterion_cls(Cls, test_label)\n",
    "                y_pred = torch.max(Cls, 1)[1]\n",
    "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
    "\n",
    "                #self.model.eval()\n",
    "                ValCls = self.model(val_data)\n",
    "                loss_val = self.criterion_cls(ValCls, val_label)\n",
    "                val_pred = torch.max(ValCls, 1)[1]\n",
    "                val_acc = float((val_pred == val_label).cpu().numpy().astype(int).sum()) / float(val_label.size(0))\n",
    "                \n",
    "                train_pred = torch.max(outputs, 1)[1]\n",
    "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
    "                \n",
    "                print('Epoch:', e,\n",
    "                      '  Train loss: %.4f' % loss.detach().cpu().numpy(),\n",
    "                      '  Val loss: %.4f' % loss_val.detach().cpu().numpy(),\n",
    "                      '  Test loss: %.4f' % loss_test.detach().cpu().numpy(),\n",
    "                      '  Train acc: %.4f' % train_acc,\n",
    "                      '  Val acc: %.4f' % val_acc,\n",
    "                      '  Test acc: %.4f' % acc)\n",
    "\n",
    "                num = num + 1\n",
    "                averAcc = averAcc + acc\n",
    "                if acc > bestAcc:\n",
    "                    bestAcc = acc\n",
    "                    Y_true = test_label\n",
    "                    Y_pred = y_pred\n",
    "            \n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            train_losses.append(loss.detach().cpu().numpy())\n",
    "            val_losses.append(loss_val.detach().cpu().numpy())\n",
    "\n",
    "        #torch.save(self.model.module.state_dict(), 'model.pth')\n",
    "        averAcc = averAcc / num\n",
    "        print('The average accuracy is:', averAcc)\n",
    "        print('The best accuracy is:', bestAcc)\n",
    "        \n",
    "        return bestAcc, averAcc, Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    best = 0\n",
    "    aver = 0\n",
    "\n",
    "    for i in range(9):\n",
    "        starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "        seed_n = np.random.randint(2021)\n",
    "        print('seed is ' + str(seed_n))\n",
    "        random.seed(seed_n)\n",
    "        np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "\n",
    "        print('Subject %d' % (i+1))\n",
    "        exp = EEGCCT(i)\n",
    "\n",
    "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
    "        print('THE BEST ACCURACY IS ' + str(bestAcc))\n",
    "\n",
    "        endtime = datetime.datetime.now()\n",
    "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
    "        best = best + bestAcc\n",
    "        aver = aver + averAcc\n",
    "        if i == 0:\n",
    "            yt = Y_true\n",
    "            yp = Y_pred\n",
    "        else:\n",
    "            yt = torch.cat((yt, Y_true))\n",
    "            yp = torch.cat((yp, Y_pred))\n",
    "\n",
    "\n",
    "    best = best / 9\n",
    "    aver = aver / 9\n",
    "    \n",
    "    print(f\"Mean of best is {best}\")\n",
    "    print(f\"Mean of average is {aver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 175\n",
      "Subject 1\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.6840   Val loss: 0.6902   Test loss: 0.6957   Train acc: 0.5600   Val acc: 0.4703   Test acc: 0.5104\n",
      "Epoch: 1   Train loss: 0.6652   Val loss: 0.6839   Test loss: 0.6929   Train acc: 0.6200   Val acc: 0.5198   Test acc: 0.5035\n",
      "Epoch: 2   Train loss: 0.6601   Val loss: 0.6790   Test loss: 0.6848   Train acc: 0.5800   Val acc: 0.5000   Test acc: 0.5208\n",
      "Epoch: 3   Train loss: 0.6491   Val loss: 0.6678   Test loss: 0.6833   Train acc: 0.6000   Val acc: 0.5495   Test acc: 0.5486\n",
      "Epoch: 4   Train loss: 0.5915   Val loss: 0.6320   Test loss: 0.6629   Train acc: 0.7200   Val acc: 0.6337   Test acc: 0.5833\n",
      "Epoch: 5   Train loss: 0.5352   Val loss: 0.5807   Test loss: 0.6072   Train acc: 0.7400   Val acc: 0.6931   Test acc: 0.6424\n",
      "Epoch: 6   Train loss: 0.5710   Val loss: 0.5676   Test loss: 0.5745   Train acc: 0.7000   Val acc: 0.7178   Test acc: 0.6736\n",
      "Epoch: 7   Train loss: 0.4987   Val loss: 0.5638   Test loss: 0.5427   Train acc: 0.7800   Val acc: 0.7030   Test acc: 0.7118\n",
      "Epoch: 8   Train loss: 0.4721   Val loss: 0.5624   Test loss: 0.5306   Train acc: 0.7800   Val acc: 0.7178   Test acc: 0.6910\n",
      "Epoch: 9   Train loss: 0.4854   Val loss: 0.5663   Test loss: 0.5082   Train acc: 0.7600   Val acc: 0.6931   Test acc: 0.7153\n",
      "Epoch: 10   Train loss: 0.4877   Val loss: 0.5680   Test loss: 0.5050   Train acc: 0.8400   Val acc: 0.6881   Test acc: 0.7188\n",
      "Epoch: 11   Train loss: 0.4465   Val loss: 0.5860   Test loss: 0.5402   Train acc: 0.8400   Val acc: 0.7079   Test acc: 0.7014\n",
      "Epoch: 12   Train loss: 0.5289   Val loss: 0.5829   Test loss: 0.4909   Train acc: 0.7600   Val acc: 0.7030   Test acc: 0.7361\n",
      "Epoch: 13   Train loss: 0.3615   Val loss: 0.5757   Test loss: 0.4977   Train acc: 0.8200   Val acc: 0.7376   Test acc: 0.7222\n",
      "Epoch: 14   Train loss: 0.5243   Val loss: 0.5646   Test loss: 0.4781   Train acc: 0.7800   Val acc: 0.7277   Test acc: 0.7292\n",
      "Epoch: 15   Train loss: 0.4530   Val loss: 0.5821   Test loss: 0.5487   Train acc: 0.7600   Val acc: 0.7475   Test acc: 0.6840\n",
      "Epoch: 16   Train loss: 0.4365   Val loss: 0.5735   Test loss: 0.4715   Train acc: 0.7800   Val acc: 0.7327   Test acc: 0.7569\n",
      "Epoch: 17   Train loss: 0.4687   Val loss: 0.5562   Test loss: 0.4983   Train acc: 0.7800   Val acc: 0.7228   Test acc: 0.7361\n",
      "Epoch: 18   Train loss: 0.3315   Val loss: 0.5540   Test loss: 0.4656   Train acc: 0.8200   Val acc: 0.7327   Test acc: 0.7569\n",
      "Epoch: 19   Train loss: 0.4423   Val loss: 0.5637   Test loss: 0.4714   Train acc: 0.7600   Val acc: 0.7178   Test acc: 0.7500\n",
      "Epoch: 20   Train loss: 0.4268   Val loss: 0.5523   Test loss: 0.4703   Train acc: 0.8200   Val acc: 0.7277   Test acc: 0.7569\n",
      "Epoch: 21   Train loss: 0.3362   Val loss: 0.5474   Test loss: 0.4895   Train acc: 0.9200   Val acc: 0.7426   Test acc: 0.7535\n",
      "Epoch: 22   Train loss: 0.4443   Val loss: 0.5743   Test loss: 0.4970   Train acc: 0.8200   Val acc: 0.7624   Test acc: 0.7535\n",
      "Epoch: 23   Train loss: 0.3159   Val loss: 0.5714   Test loss: 0.5289   Train acc: 0.8200   Val acc: 0.7376   Test acc: 0.7361\n",
      "Epoch: 24   Train loss: 0.3200   Val loss: 0.5948   Test loss: 0.5004   Train acc: 0.8600   Val acc: 0.7376   Test acc: 0.7465\n",
      "The average accuracy is: 0.6855555555555556\n",
      "The best accuracy is: 0.7569444444444444\n",
      "THE BEST ACCURACY IS 0.7569444444444444\n",
      "subject 1 duration: 0:01:02.995063\n",
      "seed is 1754\n",
      "Subject 2\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.4429   Val loss: 0.5290   Test loss: 0.5040   Train acc: 0.7600   Val acc: 0.7574   Test acc: 0.7847\n",
      "Epoch: 1   Train loss: 0.2859   Val loss: 0.5164   Test loss: 0.5120   Train acc: 0.9000   Val acc: 0.7624   Test acc: 0.7743\n",
      "Epoch: 2   Train loss: 0.4003   Val loss: 0.5494   Test loss: 0.5684   Train acc: 0.7800   Val acc: 0.7723   Test acc: 0.7361\n",
      "Epoch: 3   Train loss: 0.4644   Val loss: 0.5490   Test loss: 0.5458   Train acc: 0.8200   Val acc: 0.7376   Test acc: 0.7604\n",
      "Epoch: 4   Train loss: 0.3371   Val loss: 0.5501   Test loss: 0.5524   Train acc: 0.8400   Val acc: 0.7277   Test acc: 0.7500\n",
      "Epoch: 5   Train loss: 0.3784   Val loss: 0.5440   Test loss: 0.5737   Train acc: 0.7600   Val acc: 0.7673   Test acc: 0.7396\n",
      "Epoch: 6   Train loss: 0.2684   Val loss: 0.5464   Test loss: 0.5750   Train acc: 0.9000   Val acc: 0.7673   Test acc: 0.7326\n",
      "Epoch: 7   Train loss: 0.2967   Val loss: 0.5402   Test loss: 0.6122   Train acc: 0.8200   Val acc: 0.7624   Test acc: 0.7188\n",
      "Epoch: 8   Train loss: 0.3896   Val loss: 0.5470   Test loss: 0.6225   Train acc: 0.8200   Val acc: 0.7525   Test acc: 0.7118\n",
      "Epoch: 9   Train loss: 0.3168   Val loss: 0.5613   Test loss: 0.6163   Train acc: 0.8200   Val acc: 0.7624   Test acc: 0.7431\n",
      "Epoch: 10   Train loss: 0.3368   Val loss: 0.5652   Test loss: 0.6025   Train acc: 0.8800   Val acc: 0.7673   Test acc: 0.7326\n",
      "Epoch: 11   Train loss: 0.2851   Val loss: 0.5404   Test loss: 0.6181   Train acc: 0.9000   Val acc: 0.7723   Test acc: 0.7014\n",
      "Epoch: 12   Train loss: 0.1961   Val loss: 0.5604   Test loss: 0.6511   Train acc: 0.9400   Val acc: 0.7574   Test acc: 0.7049\n",
      "Epoch: 13   Train loss: 0.2673   Val loss: 0.5743   Test loss: 0.6575   Train acc: 0.8600   Val acc: 0.7624   Test acc: 0.7118\n",
      "Epoch: 14   Train loss: 0.2136   Val loss: 0.6186   Test loss: 0.6414   Train acc: 0.9400   Val acc: 0.7525   Test acc: 0.7188\n",
      "Epoch: 15   Train loss: 0.2154   Val loss: 0.6021   Test loss: 0.6500   Train acc: 0.9800   Val acc: 0.7624   Test acc: 0.7153\n",
      "Epoch: 16   Train loss: 0.2230   Val loss: 0.5705   Test loss: 0.6497   Train acc: 0.9400   Val acc: 0.7574   Test acc: 0.7257\n",
      "Epoch: 17   Train loss: 0.2451   Val loss: 0.5997   Test loss: 0.6498   Train acc: 0.8800   Val acc: 0.7723   Test acc: 0.7118\n",
      "Epoch: 18   Train loss: 0.2084   Val loss: 0.6348   Test loss: 0.6811   Train acc: 0.8800   Val acc: 0.7475   Test acc: 0.6736\n",
      "Epoch: 19   Train loss: 0.2179   Val loss: 0.6306   Test loss: 0.6913   Train acc: 0.9200   Val acc: 0.7426   Test acc: 0.6910\n",
      "Epoch: 20   Train loss: 0.3486   Val loss: 0.6409   Test loss: 0.6999   Train acc: 0.8400   Val acc: 0.7525   Test acc: 0.7118\n",
      "Epoch: 21   Train loss: 0.2698   Val loss: 0.6605   Test loss: 0.7018   Train acc: 0.9000   Val acc: 0.7525   Test acc: 0.7083\n",
      "Epoch: 22   Train loss: 0.1920   Val loss: 0.6434   Test loss: 0.7345   Train acc: 0.9200   Val acc: 0.7475   Test acc: 0.7083\n",
      "Epoch: 23   Train loss: 0.2684   Val loss: 0.6634   Test loss: 0.7124   Train acc: 0.9000   Val acc: 0.7178   Test acc: 0.7153\n",
      "Epoch: 24   Train loss: 0.2793   Val loss: 0.6566   Test loss: 0.7608   Train acc: 0.8800   Val acc: 0.7525   Test acc: 0.7049\n",
      "The average accuracy is: 0.7234722222222222\n",
      "The best accuracy is: 0.7847222222222222\n",
      "THE BEST ACCURACY IS 0.7847222222222222\n",
      "subject 2 duration: 0:01:03.625415\n",
      "seed is 379\n",
      "Subject 3\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.4285   Val loss: 0.7543   Test loss: 0.0755   Train acc: 0.8000   Val acc: 0.7129   Test acc: 0.9792\n",
      "Epoch: 1   Train loss: 0.3542   Val loss: 0.7682   Test loss: 0.0746   Train acc: 0.8600   Val acc: 0.7129   Test acc: 0.9792\n",
      "Epoch: 2   Train loss: 0.1742   Val loss: 0.7477   Test loss: 0.0780   Train acc: 0.9600   Val acc: 0.7228   Test acc: 0.9757\n",
      "Epoch: 3   Train loss: 0.2924   Val loss: 0.8105   Test loss: 0.0860   Train acc: 0.8600   Val acc: 0.7030   Test acc: 0.9722\n",
      "Epoch: 4   Train loss: 0.1897   Val loss: 0.7736   Test loss: 0.0789   Train acc: 0.9200   Val acc: 0.6931   Test acc: 0.9757\n",
      "Epoch: 5   Train loss: 0.1426   Val loss: 0.8223   Test loss: 0.0978   Train acc: 0.9800   Val acc: 0.6980   Test acc: 0.9653\n",
      "Epoch: 6   Train loss: 0.2464   Val loss: 0.8142   Test loss: 0.0974   Train acc: 0.9400   Val acc: 0.7030   Test acc: 0.9792\n",
      "Epoch: 7   Train loss: 0.2846   Val loss: 0.8460   Test loss: 0.0892   Train acc: 0.8600   Val acc: 0.6634   Test acc: 0.9792\n",
      "Epoch: 8   Train loss: 0.3701   Val loss: 0.8215   Test loss: 0.0952   Train acc: 0.8400   Val acc: 0.6881   Test acc: 0.9757\n",
      "Epoch: 9   Train loss: 0.3311   Val loss: 0.8197   Test loss: 0.0841   Train acc: 0.9000   Val acc: 0.6980   Test acc: 0.9757\n",
      "Epoch: 10   Train loss: 0.1307   Val loss: 0.8375   Test loss: 0.0975   Train acc: 0.9800   Val acc: 0.6931   Test acc: 0.9653\n",
      "Epoch: 11   Train loss: 0.3325   Val loss: 0.8556   Test loss: 0.1062   Train acc: 0.8400   Val acc: 0.6881   Test acc: 0.9618\n",
      "Epoch: 12   Train loss: 0.2010   Val loss: 0.8677   Test loss: 0.1344   Train acc: 0.9200   Val acc: 0.6980   Test acc: 0.9514\n",
      "Epoch: 13   Train loss: 0.3590   Val loss: 0.8833   Test loss: 0.1016   Train acc: 0.8400   Val acc: 0.6980   Test acc: 0.9618\n",
      "Epoch: 14   Train loss: 0.3620   Val loss: 0.8768   Test loss: 0.1136   Train acc: 0.8800   Val acc: 0.7079   Test acc: 0.9618\n",
      "Epoch: 15   Train loss: 0.1929   Val loss: 0.8888   Test loss: 0.1063   Train acc: 0.9200   Val acc: 0.7079   Test acc: 0.9618\n",
      "Epoch: 16   Train loss: 0.2625   Val loss: 0.8941   Test loss: 0.1142   Train acc: 0.8600   Val acc: 0.6980   Test acc: 0.9618\n",
      "Epoch: 17   Train loss: 0.2820   Val loss: 0.8622   Test loss: 0.1116   Train acc: 0.9000   Val acc: 0.7129   Test acc: 0.9688\n",
      "Epoch: 18   Train loss: 0.2004   Val loss: 0.9266   Test loss: 0.1215   Train acc: 0.9200   Val acc: 0.6832   Test acc: 0.9618\n",
      "Epoch: 19   Train loss: 0.2420   Val loss: 0.8997   Test loss: 0.1528   Train acc: 0.8800   Val acc: 0.7030   Test acc: 0.9479\n",
      "Epoch: 20   Train loss: 0.1820   Val loss: 0.9098   Test loss: 0.1186   Train acc: 0.9400   Val acc: 0.7030   Test acc: 0.9583\n",
      "Epoch: 21   Train loss: 0.4465   Val loss: 0.9390   Test loss: 0.1337   Train acc: 0.8000   Val acc: 0.7079   Test acc: 0.9618\n",
      "Epoch: 22   Train loss: 0.1763   Val loss: 0.9413   Test loss: 0.1303   Train acc: 0.9400   Val acc: 0.6931   Test acc: 0.9549\n",
      "Epoch: 23   Train loss: 0.1890   Val loss: 0.9682   Test loss: 0.1608   Train acc: 0.9200   Val acc: 0.7129   Test acc: 0.9444\n",
      "Epoch: 24   Train loss: 0.1842   Val loss: 0.9747   Test loss: 0.1527   Train acc: 0.8600   Val acc: 0.6782   Test acc: 0.9410\n",
      "The average accuracy is: 0.9648611111111112\n",
      "The best accuracy is: 0.9791666666666666\n",
      "THE BEST ACCURACY IS 0.9791666666666666\n",
      "subject 3 duration: 0:01:03.453729\n",
      "seed is 1891\n",
      "Subject 4\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1268   Val loss: 0.8665   Test loss: 0.1293   Train acc: 0.9800   Val acc: 0.7079   Test acc: 0.9722\n",
      "Epoch: 1   Train loss: 0.1710   Val loss: 0.8434   Test loss: 0.1522   Train acc: 0.9000   Val acc: 0.6980   Test acc: 0.9583\n",
      "Epoch: 2   Train loss: 0.1485   Val loss: 0.8242   Test loss: 0.1469   Train acc: 0.9600   Val acc: 0.7030   Test acc: 0.9722\n",
      "Epoch: 3   Train loss: 0.2169   Val loss: 0.8303   Test loss: 0.1699   Train acc: 0.9400   Val acc: 0.7228   Test acc: 0.9514\n",
      "Epoch: 4   Train loss: 0.1739   Val loss: 0.8683   Test loss: 0.1362   Train acc: 0.9600   Val acc: 0.7079   Test acc: 0.9757\n",
      "Epoch: 5   Train loss: 0.3089   Val loss: 0.8965   Test loss: 0.1586   Train acc: 0.8600   Val acc: 0.6881   Test acc: 0.9653\n",
      "Epoch: 6   Train loss: 0.1589   Val loss: 0.9102   Test loss: 0.1638   Train acc: 0.9400   Val acc: 0.6931   Test acc: 0.9583\n",
      "Epoch: 7   Train loss: 0.1705   Val loss: 0.8642   Test loss: 0.1446   Train acc: 0.9400   Val acc: 0.7129   Test acc: 0.9722\n",
      "Epoch: 8   Train loss: 0.0761   Val loss: 0.8653   Test loss: 0.1562   Train acc: 0.9800   Val acc: 0.7129   Test acc: 0.9444\n",
      "Epoch: 9   Train loss: 0.1362   Val loss: 0.8854   Test loss: 0.1490   Train acc: 0.9600   Val acc: 0.7079   Test acc: 0.9583\n",
      "Epoch: 10   Train loss: 0.1605   Val loss: 0.9096   Test loss: 0.2124   Train acc: 0.9000   Val acc: 0.7079   Test acc: 0.9201\n",
      "Epoch: 11   Train loss: 0.1198   Val loss: 0.9035   Test loss: 0.1791   Train acc: 0.9400   Val acc: 0.7030   Test acc: 0.9340\n",
      "Epoch: 12   Train loss: 0.2316   Val loss: 0.8801   Test loss: 0.1848   Train acc: 0.9000   Val acc: 0.7277   Test acc: 0.9444\n",
      "Epoch: 13   Train loss: 0.1995   Val loss: 0.8635   Test loss: 0.1660   Train acc: 0.9200   Val acc: 0.7228   Test acc: 0.9444\n",
      "Epoch: 14   Train loss: 0.2415   Val loss: 0.8920   Test loss: 0.2113   Train acc: 0.9200   Val acc: 0.7030   Test acc: 0.9097\n",
      "Epoch: 15   Train loss: 0.1781   Val loss: 0.9633   Test loss: 0.1753   Train acc: 0.9400   Val acc: 0.6931   Test acc: 0.9375\n",
      "Epoch: 16   Train loss: 0.0972   Val loss: 0.8984   Test loss: 0.1856   Train acc: 0.9600   Val acc: 0.6881   Test acc: 0.9514\n",
      "Epoch: 17   Train loss: 0.1118   Val loss: 0.9332   Test loss: 0.1799   Train acc: 0.9800   Val acc: 0.7030   Test acc: 0.9271\n",
      "Epoch: 18   Train loss: 0.2299   Val loss: 0.9589   Test loss: 0.1869   Train acc: 0.9200   Val acc: 0.6931   Test acc: 0.9444\n",
      "Epoch: 19   Train loss: 0.2157   Val loss: 0.9276   Test loss: 0.2086   Train acc: 0.9200   Val acc: 0.7079   Test acc: 0.9271\n",
      "Epoch: 20   Train loss: 0.0813   Val loss: 0.9594   Test loss: 0.2125   Train acc: 0.9600   Val acc: 0.7079   Test acc: 0.9201\n",
      "Epoch: 21   Train loss: 0.1809   Val loss: 0.9300   Test loss: 0.2012   Train acc: 0.9200   Val acc: 0.7178   Test acc: 0.9167\n",
      "Epoch: 22   Train loss: 0.1305   Val loss: 0.9006   Test loss: 0.1961   Train acc: 0.9600   Val acc: 0.7178   Test acc: 0.9340\n",
      "Epoch: 23   Train loss: 0.0866   Val loss: 0.8879   Test loss: 0.2225   Train acc: 0.9800   Val acc: 0.6931   Test acc: 0.9201\n",
      "Epoch: 24   Train loss: 0.1869   Val loss: 0.8594   Test loss: 0.2110   Train acc: 0.9400   Val acc: 0.7327   Test acc: 0.9340\n",
      "The average accuracy is: 0.94375\n",
      "The best accuracy is: 0.9756944444444444\n",
      "THE BEST ACCURACY IS 0.9756944444444444\n",
      "subject 4 duration: 0:01:03.201338\n",
      "seed is 1088\n",
      "Subject 5\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1215   Val loss: 0.7117   Test loss: 0.2066   Train acc: 0.9400   Val acc: 0.7525   Test acc: 0.9514\n",
      "Epoch: 1   Train loss: 0.0850   Val loss: 0.6526   Test loss: 0.2181   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.9479\n",
      "Epoch: 2   Train loss: 0.1429   Val loss: 0.7172   Test loss: 0.2380   Train acc: 0.9600   Val acc: 0.7525   Test acc: 0.9444\n",
      "Epoch: 3   Train loss: 0.2249   Val loss: 0.7316   Test loss: 0.2372   Train acc: 0.9200   Val acc: 0.7574   Test acc: 0.9410\n",
      "Epoch: 4   Train loss: 0.0742   Val loss: 0.7439   Test loss: 0.2267   Train acc: 1.0000   Val acc: 0.7475   Test acc: 0.9444\n",
      "Epoch: 5   Train loss: 0.0698   Val loss: 0.6921   Test loss: 0.2399   Train acc: 0.9800   Val acc: 0.7673   Test acc: 0.9410\n",
      "Epoch: 6   Train loss: 0.1470   Val loss: 0.7105   Test loss: 0.2618   Train acc: 0.9400   Val acc: 0.7723   Test acc: 0.9167\n",
      "Epoch: 7   Train loss: 0.1588   Val loss: 0.6812   Test loss: 0.2358   Train acc: 0.9600   Val acc: 0.7772   Test acc: 0.9375\n",
      "Epoch: 8   Train loss: 0.1344   Val loss: 0.7312   Test loss: 0.2347   Train acc: 0.9200   Val acc: 0.7772   Test acc: 0.9375\n",
      "Epoch: 9   Train loss: 0.1217   Val loss: 0.7288   Test loss: 0.2298   Train acc: 0.9400   Val acc: 0.7822   Test acc: 0.9375\n",
      "Epoch: 10   Train loss: 0.1648   Val loss: 0.7633   Test loss: 0.2776   Train acc: 0.9200   Val acc: 0.7624   Test acc: 0.9306\n",
      "Epoch: 11   Train loss: 0.1336   Val loss: 0.7110   Test loss: 0.2798   Train acc: 0.9600   Val acc: 0.7772   Test acc: 0.9236\n",
      "Epoch: 12   Train loss: 0.1183   Val loss: 0.7626   Test loss: 0.3314   Train acc: 0.9400   Val acc: 0.7772   Test acc: 0.9028\n",
      "Epoch: 13   Train loss: 0.1221   Val loss: 0.7966   Test loss: 0.3135   Train acc: 0.9600   Val acc: 0.7525   Test acc: 0.9132\n",
      "Epoch: 14   Train loss: 0.0682   Val loss: 0.6892   Test loss: 0.2757   Train acc: 0.9600   Val acc: 0.7673   Test acc: 0.9097\n",
      "Epoch: 15   Train loss: 0.1795   Val loss: 0.7810   Test loss: 0.3622   Train acc: 0.9400   Val acc: 0.7574   Test acc: 0.8889\n",
      "Epoch: 16   Train loss: 0.1249   Val loss: 0.7359   Test loss: 0.3309   Train acc: 0.9400   Val acc: 0.7772   Test acc: 0.9097\n",
      "Epoch: 17   Train loss: 0.0993   Val loss: 0.6845   Test loss: 0.3163   Train acc: 0.9800   Val acc: 0.7723   Test acc: 0.9028\n",
      "Epoch: 18   Train loss: 0.0441   Val loss: 0.6980   Test loss: 0.3173   Train acc: 1.0000   Val acc: 0.7871   Test acc: 0.9062\n",
      "Epoch: 19   Train loss: 0.1076   Val loss: 0.7465   Test loss: 0.3324   Train acc: 0.9200   Val acc: 0.7723   Test acc: 0.8993\n",
      "Epoch: 20   Train loss: 0.0496   Val loss: 0.7896   Test loss: 0.3322   Train acc: 0.9800   Val acc: 0.7426   Test acc: 0.8958\n",
      "Epoch: 21   Train loss: 0.0973   Val loss: 0.7347   Test loss: 0.3475   Train acc: 0.9800   Val acc: 0.7772   Test acc: 0.8993\n",
      "Epoch: 22   Train loss: 0.1713   Val loss: 0.7262   Test loss: 0.3260   Train acc: 0.9400   Val acc: 0.7426   Test acc: 0.9132\n",
      "Epoch: 23   Train loss: 0.1535   Val loss: 0.7741   Test loss: 0.4088   Train acc: 0.9200   Val acc: 0.7624   Test acc: 0.8854\n",
      "Epoch: 24   Train loss: 0.2441   Val loss: 0.7569   Test loss: 0.3263   Train acc: 0.9200   Val acc: 0.7525   Test acc: 0.9097\n",
      "The average accuracy is: 0.9195833333333334\n",
      "The best accuracy is: 0.9513888888888888\n",
      "THE BEST ACCURACY IS 0.9513888888888888\n",
      "subject 5 duration: 0:01:02.406561\n",
      "seed is 666\n",
      "Subject 6\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1740   Val loss: 0.6645   Test loss: 0.1307   Train acc: 0.9400   Val acc: 0.7921   Test acc: 0.9653\n",
      "Epoch: 1   Train loss: 0.1061   Val loss: 0.6652   Test loss: 0.1350   Train acc: 0.9600   Val acc: 0.7772   Test acc: 0.9688\n",
      "Epoch: 2   Train loss: 0.0983   Val loss: 0.6410   Test loss: 0.1559   Train acc: 0.9800   Val acc: 0.8119   Test acc: 0.9549\n",
      "Epoch: 3   Train loss: 0.1376   Val loss: 0.6624   Test loss: 0.1596   Train acc: 0.9800   Val acc: 0.7871   Test acc: 0.9618\n",
      "Epoch: 4   Train loss: 0.0766   Val loss: 0.6774   Test loss: 0.1613   Train acc: 0.9600   Val acc: 0.7871   Test acc: 0.9618\n",
      "Epoch: 5   Train loss: 0.1154   Val loss: 0.6895   Test loss: 0.1567   Train acc: 0.9600   Val acc: 0.7921   Test acc: 0.9583\n",
      "Epoch: 6   Train loss: 0.1592   Val loss: 0.6577   Test loss: 0.1517   Train acc: 0.9600   Val acc: 0.7921   Test acc: 0.9653\n",
      "Epoch: 7   Train loss: 0.1207   Val loss: 0.6727   Test loss: 0.1658   Train acc: 0.9800   Val acc: 0.8020   Test acc: 0.9583\n",
      "Epoch: 8   Train loss: 0.1332   Val loss: 0.6526   Test loss: 0.1642   Train acc: 0.9400   Val acc: 0.7673   Test acc: 0.9653\n",
      "Epoch: 9   Train loss: 0.2586   Val loss: 0.6850   Test loss: 0.1614   Train acc: 0.9000   Val acc: 0.7921   Test acc: 0.9618\n",
      "Epoch: 10   Train loss: 0.1105   Val loss: 0.6929   Test loss: 0.1515   Train acc: 0.9600   Val acc: 0.7970   Test acc: 0.9583\n",
      "Epoch: 11   Train loss: 0.1258   Val loss: 0.7018   Test loss: 0.1664   Train acc: 0.9400   Val acc: 0.7822   Test acc: 0.9514\n",
      "Epoch: 12   Train loss: 0.1770   Val loss: 0.6103   Test loss: 0.1608   Train acc: 0.9400   Val acc: 0.8168   Test acc: 0.9549\n",
      "Epoch: 13   Train loss: 0.0626   Val loss: 0.7521   Test loss: 0.2213   Train acc: 0.9800   Val acc: 0.7822   Test acc: 0.9201\n",
      "Epoch: 14   Train loss: 0.1293   Val loss: 0.6941   Test loss: 0.1647   Train acc: 0.9200   Val acc: 0.7970   Test acc: 0.9653\n",
      "Epoch: 15   Train loss: 0.1393   Val loss: 0.7267   Test loss: 0.1648   Train acc: 0.9400   Val acc: 0.7673   Test acc: 0.9549\n",
      "Epoch: 16   Train loss: 0.0593   Val loss: 0.6729   Test loss: 0.1734   Train acc: 1.0000   Val acc: 0.8020   Test acc: 0.9479\n",
      "Epoch: 17   Train loss: 0.0321   Val loss: 0.6994   Test loss: 0.1766   Train acc: 1.0000   Val acc: 0.7921   Test acc: 0.9444\n",
      "Epoch: 18   Train loss: 0.0513   Val loss: 0.7682   Test loss: 0.1843   Train acc: 0.9800   Val acc: 0.7822   Test acc: 0.9444\n",
      "Epoch: 19   Train loss: 0.1234   Val loss: 0.7503   Test loss: 0.1978   Train acc: 0.9400   Val acc: 0.7624   Test acc: 0.9340\n",
      "Epoch: 20   Train loss: 0.1124   Val loss: 0.7097   Test loss: 0.1885   Train acc: 0.9400   Val acc: 0.7822   Test acc: 0.9340\n",
      "Epoch: 21   Train loss: 0.0738   Val loss: 0.7525   Test loss: 0.1787   Train acc: 1.0000   Val acc: 0.7822   Test acc: 0.9514\n",
      "Epoch: 22   Train loss: 0.1763   Val loss: 0.6882   Test loss: 0.1795   Train acc: 0.9200   Val acc: 0.7772   Test acc: 0.9583\n",
      "Epoch: 23   Train loss: 0.0523   Val loss: 0.7236   Test loss: 0.1805   Train acc: 0.9800   Val acc: 0.7871   Test acc: 0.9514\n",
      "Epoch: 24   Train loss: 0.1765   Val loss: 0.7176   Test loss: 0.2202   Train acc: 0.9600   Val acc: 0.7772   Test acc: 0.9167\n",
      "The average accuracy is: 0.9523611111111111\n",
      "The best accuracy is: 0.96875\n",
      "THE BEST ACCURACY IS 0.96875\n",
      "subject 6 duration: 0:01:05.583225\n",
      "seed is 1789\n",
      "Subject 7\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2605   Val loss: 0.4959   Test loss: 0.1724   Train acc: 0.9200   Val acc: 0.8366   Test acc: 0.9583\n",
      "Epoch: 1   Train loss: 0.1559   Val loss: 0.5572   Test loss: 0.1548   Train acc: 0.9200   Val acc: 0.8119   Test acc: 0.9583\n",
      "Epoch: 2   Train loss: 0.0605   Val loss: 0.5039   Test loss: 0.1577   Train acc: 0.9800   Val acc: 0.8317   Test acc: 0.9618\n",
      "Epoch: 3   Train loss: 0.0752   Val loss: 0.5214   Test loss: 0.1766   Train acc: 0.9800   Val acc: 0.8317   Test acc: 0.9583\n",
      "Epoch: 4   Train loss: 0.0539   Val loss: 0.5073   Test loss: 0.1631   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9583\n",
      "Epoch: 5   Train loss: 0.1208   Val loss: 0.5621   Test loss: 0.1911   Train acc: 0.9600   Val acc: 0.8168   Test acc: 0.9549\n",
      "Epoch: 6   Train loss: 0.0904   Val loss: 0.5039   Test loss: 0.1814   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9583\n",
      "Epoch: 7   Train loss: 0.0563   Val loss: 0.5474   Test loss: 0.1771   Train acc: 0.9800   Val acc: 0.8119   Test acc: 0.9549\n",
      "Epoch: 8   Train loss: 0.0433   Val loss: 0.5200   Test loss: 0.1968   Train acc: 1.0000   Val acc: 0.8267   Test acc: 0.9549\n",
      "Epoch: 9   Train loss: 0.1755   Val loss: 0.5650   Test loss: 0.1896   Train acc: 0.9000   Val acc: 0.8416   Test acc: 0.9583\n",
      "Epoch: 10   Train loss: 0.1723   Val loss: 0.5124   Test loss: 0.1939   Train acc: 0.9400   Val acc: 0.8218   Test acc: 0.9583\n",
      "Epoch: 11   Train loss: 0.1760   Val loss: 0.5469   Test loss: 0.1781   Train acc: 0.9200   Val acc: 0.8317   Test acc: 0.9618\n",
      "Epoch: 12   Train loss: 0.0486   Val loss: 0.5363   Test loss: 0.1854   Train acc: 0.9800   Val acc: 0.8317   Test acc: 0.9583\n",
      "Epoch: 13   Train loss: 0.2500   Val loss: 0.5202   Test loss: 0.1774   Train acc: 0.9000   Val acc: 0.8564   Test acc: 0.9514\n",
      "Epoch: 14   Train loss: 0.1347   Val loss: 0.5769   Test loss: 0.1743   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9583\n",
      "Epoch: 15   Train loss: 0.1096   Val loss: 0.5356   Test loss: 0.1889   Train acc: 0.9600   Val acc: 0.8465   Test acc: 0.9549\n",
      "Epoch: 16   Train loss: 0.1276   Val loss: 0.5705   Test loss: 0.1952   Train acc: 0.9400   Val acc: 0.8317   Test acc: 0.9514\n",
      "Epoch: 17   Train loss: 0.1820   Val loss: 0.5724   Test loss: 0.2049   Train acc: 0.9000   Val acc: 0.8267   Test acc: 0.9479\n",
      "Epoch: 18   Train loss: 0.0348   Val loss: 0.6022   Test loss: 0.2048   Train acc: 1.0000   Val acc: 0.8366   Test acc: 0.9514\n",
      "Epoch: 19   Train loss: 0.0906   Val loss: 0.5827   Test loss: 0.1896   Train acc: 0.9400   Val acc: 0.8267   Test acc: 0.9514\n",
      "Epoch: 20   Train loss: 0.1036   Val loss: 0.5701   Test loss: 0.1938   Train acc: 0.9400   Val acc: 0.8366   Test acc: 0.9549\n",
      "Epoch: 21   Train loss: 0.0631   Val loss: 0.5542   Test loss: 0.2318   Train acc: 0.9800   Val acc: 0.8267   Test acc: 0.9375\n",
      "Epoch: 22   Train loss: 0.0947   Val loss: 0.5516   Test loss: 0.2124   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9479\n",
      "Epoch: 23   Train loss: 0.0966   Val loss: 0.5495   Test loss: 0.1961   Train acc: 0.9800   Val acc: 0.8267   Test acc: 0.9444\n",
      "Epoch: 24   Train loss: 0.1004   Val loss: 0.5430   Test loss: 0.2029   Train acc: 0.9800   Val acc: 0.8317   Test acc: 0.9444\n",
      "The average accuracy is: 0.9540277777777778\n",
      "The best accuracy is: 0.9618055555555556\n",
      "THE BEST ACCURACY IS 0.9618055555555556\n",
      "subject 7 duration: 0:01:01.751323\n",
      "seed is 1685\n",
      "Subject 8\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0541   Val loss: 0.5228   Test loss: 0.0221   Train acc: 0.9800   Val acc: 0.8119   Test acc: 0.9931\n",
      "Epoch: 1   Train loss: 0.1003   Val loss: 0.5611   Test loss: 0.0188   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9931\n",
      "Epoch: 2   Train loss: 0.0981   Val loss: 0.5414   Test loss: 0.0200   Train acc: 0.9800   Val acc: 0.8267   Test acc: 0.9931\n",
      "Epoch: 3   Train loss: 0.1754   Val loss: 0.5319   Test loss: 0.0172   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9931\n",
      "Epoch: 4   Train loss: 0.2914   Val loss: 0.5387   Test loss: 0.0190   Train acc: 0.8800   Val acc: 0.8168   Test acc: 0.9931\n",
      "Epoch: 5   Train loss: 0.1632   Val loss: 0.5438   Test loss: 0.0274   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.9896\n",
      "Epoch: 6   Train loss: 0.0605   Val loss: 0.4915   Test loss: 0.0203   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9931\n",
      "Epoch: 7   Train loss: 0.0799   Val loss: 0.5356   Test loss: 0.0347   Train acc: 0.9800   Val acc: 0.8069   Test acc: 0.9896\n",
      "Epoch: 8   Train loss: 0.0959   Val loss: 0.5068   Test loss: 0.0273   Train acc: 0.9600   Val acc: 0.8564   Test acc: 0.9896\n",
      "Epoch: 9   Train loss: 0.2913   Val loss: 0.5303   Test loss: 0.0226   Train acc: 0.9000   Val acc: 0.8416   Test acc: 0.9931\n",
      "Epoch: 10   Train loss: 0.0797   Val loss: 0.5964   Test loss: 0.0253   Train acc: 0.9600   Val acc: 0.8119   Test acc: 0.9931\n",
      "Epoch: 11   Train loss: 0.2497   Val loss: 0.5540   Test loss: 0.0244   Train acc: 0.9400   Val acc: 0.8119   Test acc: 0.9896\n",
      "Epoch: 12   Train loss: 0.2123   Val loss: 0.6025   Test loss: 0.0262   Train acc: 0.9200   Val acc: 0.8267   Test acc: 0.9931\n",
      "Epoch: 13   Train loss: 0.0726   Val loss: 0.6113   Test loss: 0.0291   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9931\n",
      "Epoch: 14   Train loss: 0.1100   Val loss: 0.7013   Test loss: 0.0429   Train acc: 0.9600   Val acc: 0.8020   Test acc: 0.9861\n",
      "Epoch: 15   Train loss: 0.1315   Val loss: 0.6793   Test loss: 0.0229   Train acc: 0.9200   Val acc: 0.8020   Test acc: 0.9931\n",
      "Epoch: 16   Train loss: 0.1671   Val loss: 0.5908   Test loss: 0.0272   Train acc: 0.9800   Val acc: 0.7921   Test acc: 0.9896\n",
      "Epoch: 17   Train loss: 0.0372   Val loss: 0.5858   Test loss: 0.0284   Train acc: 0.9800   Val acc: 0.8069   Test acc: 0.9896\n",
      "Epoch: 18   Train loss: 0.1011   Val loss: 0.5755   Test loss: 0.0285   Train acc: 0.9400   Val acc: 0.8218   Test acc: 0.9931\n",
      "Epoch: 19   Train loss: 0.1091   Val loss: 0.6150   Test loss: 0.0262   Train acc: 0.9400   Val acc: 0.8317   Test acc: 0.9931\n",
      "Epoch: 20   Train loss: 0.0701   Val loss: 0.5412   Test loss: 0.0217   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9896\n",
      "Epoch: 21   Train loss: 0.1715   Val loss: 0.5481   Test loss: 0.0222   Train acc: 0.9200   Val acc: 0.8366   Test acc: 0.9965\n",
      "Epoch: 22   Train loss: 0.0914   Val loss: 0.5782   Test loss: 0.0307   Train acc: 0.9800   Val acc: 0.8119   Test acc: 0.9931\n",
      "Epoch: 23   Train loss: 0.0346   Val loss: 0.6064   Test loss: 0.0310   Train acc: 1.0000   Val acc: 0.8267   Test acc: 0.9931\n",
      "Epoch: 24   Train loss: 0.1405   Val loss: 0.5908   Test loss: 0.0289   Train acc: 0.9400   Val acc: 0.8218   Test acc: 0.9931\n",
      "The average accuracy is: 0.9919444444444445\n",
      "The best accuracy is: 0.9965277777777778\n",
      "THE BEST ACCURACY IS 0.9965277777777778\n",
      "subject 8 duration: 0:01:03.071230\n",
      "seed is 54\n",
      "Subject 9\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1559   Val loss: 0.0871   Test loss: 1.5568   Train acc: 0.9649   Val acc: 0.9784   Test acc: 0.6424\n",
      "Epoch: 1   Train loss: 0.0381   Val loss: 0.0939   Test loss: 1.6256   Train acc: 0.9825   Val acc: 0.9784   Test acc: 0.6285\n",
      "Epoch: 2   Train loss: 0.0992   Val loss: 0.0768   Test loss: 1.6202   Train acc: 0.9649   Val acc: 0.9740   Test acc: 0.6250\n",
      "Epoch: 3   Train loss: 0.1433   Val loss: 0.0804   Test loss: 1.5306   Train acc: 0.9474   Val acc: 0.9784   Test acc: 0.6458\n",
      "Epoch: 4   Train loss: 0.1463   Val loss: 0.0768   Test loss: 1.4868   Train acc: 0.9474   Val acc: 0.9784   Test acc: 0.6528\n",
      "Epoch: 5   Train loss: 0.1019   Val loss: 0.0975   Test loss: 1.7451   Train acc: 0.9474   Val acc: 0.9784   Test acc: 0.6181\n",
      "Epoch: 6   Train loss: 0.1019   Val loss: 0.0900   Test loss: 1.6366   Train acc: 0.9649   Val acc: 0.9740   Test acc: 0.6076\n",
      "Epoch: 7   Train loss: 0.0855   Val loss: 0.1004   Test loss: 1.5876   Train acc: 0.9825   Val acc: 0.9697   Test acc: 0.6424\n",
      "Epoch: 8   Train loss: 0.0871   Val loss: 0.0918   Test loss: 1.5096   Train acc: 0.9474   Val acc: 0.9827   Test acc: 0.6493\n",
      "Epoch: 9   Train loss: 0.0243   Val loss: 0.0978   Test loss: 1.5642   Train acc: 1.0000   Val acc: 0.9784   Test acc: 0.6354\n",
      "Epoch: 10   Train loss: 0.0895   Val loss: 0.0976   Test loss: 1.5732   Train acc: 0.9649   Val acc: 0.9827   Test acc: 0.6285\n",
      "Epoch: 11   Train loss: 0.0479   Val loss: 0.0988   Test loss: 1.5266   Train acc: 0.9649   Val acc: 0.9567   Test acc: 0.6493\n",
      "Epoch: 12   Train loss: 0.0650   Val loss: 0.0958   Test loss: 1.5688   Train acc: 0.9649   Val acc: 0.9654   Test acc: 0.6424\n",
      "Epoch: 13   Train loss: 0.0478   Val loss: 0.0818   Test loss: 1.5945   Train acc: 1.0000   Val acc: 0.9740   Test acc: 0.6285\n",
      "Epoch: 14   Train loss: 0.1669   Val loss: 0.1124   Test loss: 1.7323   Train acc: 0.9474   Val acc: 0.9697   Test acc: 0.6007\n",
      "Epoch: 15   Train loss: 0.0386   Val loss: 0.0903   Test loss: 1.5287   Train acc: 1.0000   Val acc: 0.9740   Test acc: 0.6458\n",
      "Epoch: 16   Train loss: 0.1012   Val loss: 0.0963   Test loss: 1.6649   Train acc: 0.9649   Val acc: 0.9784   Test acc: 0.6285\n",
      "Epoch: 17   Train loss: 0.0389   Val loss: 0.0776   Test loss: 1.8292   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6181\n",
      "Epoch: 18   Train loss: 0.0914   Val loss: 0.0818   Test loss: 1.5959   Train acc: 0.9298   Val acc: 0.9827   Test acc: 0.6319\n",
      "Epoch: 19   Train loss: 0.1059   Val loss: 0.0966   Test loss: 1.6216   Train acc: 0.9649   Val acc: 0.9740   Test acc: 0.6181\n",
      "Epoch: 20   Train loss: 0.3348   Val loss: 0.0943   Test loss: 1.7527   Train acc: 0.8596   Val acc: 0.9697   Test acc: 0.6042\n",
      "Epoch: 21   Train loss: 0.0796   Val loss: 0.0841   Test loss: 1.6474   Train acc: 0.9649   Val acc: 0.9697   Test acc: 0.6319\n",
      "Epoch: 22   Train loss: 0.0617   Val loss: 0.1054   Test loss: 1.7634   Train acc: 0.9825   Val acc: 0.9740   Test acc: 0.6250\n",
      "Epoch: 23   Train loss: 0.0806   Val loss: 0.0946   Test loss: 1.7161   Train acc: 0.9649   Val acc: 0.9697   Test acc: 0.6215\n",
      "Epoch: 24   Train loss: 0.0686   Val loss: 0.0866   Test loss: 1.7064   Train acc: 0.9825   Val acc: 0.9740   Test acc: 0.6146\n",
      "The average accuracy is: 0.6294444444444445\n",
      "The best accuracy is: 0.6527777777777778\n",
      "THE BEST ACCURACY IS 0.6527777777777778\n",
      "subject 9 duration: 0:01:16.447737\n",
      "Mean of best is 0.8919753086419752\n",
      "Mean of average is 0.8627777777777778\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
