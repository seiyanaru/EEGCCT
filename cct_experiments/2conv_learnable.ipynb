{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.cct import CCT\n",
    "from torchinfo import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input into tokenizer is torch.Size([1, 1, 22, 321])\n",
      "Shape of output from tokenizer is torch.Size([1, 298, 64])\n"
     ]
    }
   ],
   "source": [
    "model = CCT(kernel_sizes=[(22, 1), (1, 24)], stride=(1, 1), padding=(0, 0),\n",
    "            pooling_kernel_size=(3, 3), pooling_stride=(1, 1), pooling_padding=(0, 0),\n",
    "            n_conv_layers=2, n_input_channels=1,\n",
    "            in_planes=64, activation=None, # ReLU\n",
    "            max_pool=False, conv_bias=False,\n",
    "            dim=64, num_layers=3,\n",
    "            num_heads=4, num_classes=2, \n",
    "            attn_dropout=0.1, dropout=0.1, \n",
    "            mlp_size=64, positional_emb=\"learnable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "CCT (CCT)                                          [64, 1, 22, 321]     [64, 2]              --                   True\n",
       "├─Tokenizer (tokenizer)                            [64, 1, 22, 321]     [64, 298, 64]        --                   True\n",
       "│    └─Sequential (conv_layers)                    [64, 1, 22, 321]     [64, 64, 1, 298]     --                   True\n",
       "│    │    └─Sequential (0)                         [64, 1, 22, 321]     [64, 64, 1, 321]     1,408                True\n",
       "│    │    └─Sequential (1)                         [64, 64, 1, 321]     [64, 64, 1, 298]     98,304               True\n",
       "│    └─Flatten (flattener)                         [64, 64, 1, 298]     [64, 64, 298]        --                   --\n",
       "├─Transformer (transformer)                        [64, 298, 64]        [64, 2]              19,072               True\n",
       "│    └─Dropout (dropout)                           [64, 298, 64]        [64, 298, 64]        --                   --\n",
       "│    └─ModuleList (blocks)                         --                   --                   --                   True\n",
       "│    │    └─EncoderLayer (0)                       [64, 298, 64]        [64, 298, 64]        24,896               True\n",
       "│    │    └─EncoderLayer (1)                       [64, 298, 64]        [64, 298, 64]        24,896               True\n",
       "│    │    └─EncoderLayer (2)                       [64, 298, 64]        [64, 298, 64]        24,896               True\n",
       "│    └─LayerNorm (norm)                            [64, 298, 64]        [64, 298, 64]        128                  True\n",
       "│    └─Linear (attention_pool)                     [64, 298, 64]        [64, 298, 1]         65                   True\n",
       "│    └─Linear (fc)                                 [64, 64]             [64, 2]              130                  True\n",
       "==================================================================================================================================\n",
       "Total params: 193,795\n",
       "Trainable params: 193,795\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.91\n",
       "==================================================================================================================================\n",
       "Input size (MB): 1.81\n",
       "Forward/backward pass size (MB): 235.26\n",
       "Params size (MB): 0.70\n",
       "Estimated Total Size (MB): 237.77\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(64, 1, 22, 321),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['datasets/aBNCI2014001R.pickle', 'datasets/aBNCI2014004R.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "data = load_data(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 321)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = ['left_hand', 'right_hand']\n",
    "subject = 0\n",
    "s1 = data[subject]\n",
    "s1.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU device name : NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dev.type == 'cuda':\n",
    "    print('Your GPU device name :', torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCCT():\n",
    "    def __init__(self, nsub, n_subj=9):\n",
    "        super(ExP, self).__init__()\n",
    "        self.batch_size = 36\n",
    "        self.n_epochs = 25  #2000\n",
    "        self.c_dim = 4\n",
    "        self.lr = 3e-5\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.dimension = (190, 50)\n",
    "        self.nSub = nsub\n",
    "        self.n_subjects = 8 # total?\n",
    "        self.start_epoch = 0\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "        self.FloatTensor = torch.cuda.FloatTensor\n",
    "\n",
    "        self.criterion_l1 = torch.nn.L1Loss().cuda()\n",
    "        self.criterion_l2 = torch.nn.MSELoss().cuda()\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = model.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to(\"cuda\")\n",
    "            \n",
    "        self.total_params = sum(param.numel() for param in self.model.parameters())\n",
    "        print(\"Number of parameters: \", self.total_params)\n",
    "\n",
    "        #self.model = self.model.cuda()\n",
    "        # summary(self.model, (1, 22, 1000))\n",
    "\n",
    "\n",
    "    # Segmentation and Reconstruction (S&R) data augmentation\n",
    "    def interaug(self, timg, label):  \n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "        for cls4aug in range(2):\n",
    "            cls_idx = np.where(label == cls4aug + 1)\n",
    "            tmp_data = timg[cls_idx]\n",
    "            tmp_label = label[cls_idx]\n",
    "\n",
    "            tmp_aug_data = np.zeros((int(self.batch_size / 2), 1, 22, 321))\n",
    "            for ri in range(int(self.batch_size / 2)):\n",
    "                for rj in range(3):\n",
    "                    rand_idx = np.random.randint(0, tmp_data.shape[0], 3)\n",
    "                    tmp_aug_data[ri, :, :, rj * 107:(rj + 1) * 107] = tmp_data[rand_idx[rj], :, :,\n",
    "                                                                      rj * 107:(rj + 1) * 107]\n",
    "\n",
    "            aug_data.append(tmp_aug_data)\n",
    "            aug_label.append(tmp_label[:int(self.batch_size / 2)])\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        aug_data = aug_data[aug_shuffle, :, :]\n",
    "        aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        aug_data = torch.from_numpy(aug_data).cuda()\n",
    "        aug_data = aug_data.float()\n",
    "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
    "        aug_label = aug_label.long()\n",
    "        return aug_data, aug_label\n",
    "\n",
    "    def get_source_data(self):\n",
    "        \n",
    "        self.test_subject = self.nSub\n",
    "\n",
    "        # Get the data from the epochs object\n",
    "        self.data = load_data(datasets[0])\n",
    "        print('Dataset: ', datasets[0])\n",
    "\n",
    "        self.train_subjects = [i for i in range(self.n_subjects) if i != self.test_subject]\n",
    "\n",
    "        # Prepare test data\n",
    "        self.X_test = self.data[self.test_subject].get_data()\n",
    "        self.y_test = self.data[self.test_subject].events[:, -1]\n",
    "\n",
    "        # Prepare training data\n",
    "        self.X_train = np.concatenate([self.data[i].get_data() for i in self.train_subjects], axis=0)\n",
    "        self.y_train = np.concatenate([self.data[i].events[:, -1] for i in self.train_subjects], axis=0)\n",
    "\n",
    "        # train and val data\n",
    "        self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(self.X_train, self.y_train, test_size=0.1, random_state=42)\n",
    "        \n",
    "        self.allData = np.expand_dims(self.train_data, axis=1)\n",
    "        self.allLabel = self.train_label\n",
    "        \n",
    "        self.valData = np.expand_dims(self.val_data, axis=1)\n",
    "        self.valLabel = self.val_label\n",
    "\n",
    "        shuffle_num = np.random.permutation(len(self.allData))\n",
    "        self.allData = self.allData[shuffle_num, :, :, :]\n",
    "        self.allLabel = self.allLabel[shuffle_num]\n",
    "\n",
    "        # test data  \n",
    "        self.testData = np.expand_dims(self.X_test, axis=1)\n",
    "        self.testLabel = self.y_test\n",
    "        \n",
    "        # standardize\n",
    "        target_mean = np.mean(self.allData)\n",
    "        target_std = np.std(self.allData)\n",
    "        self.allData = (self.allData - target_mean) / target_std\n",
    "        self.testData = (self.testData - target_mean) / target_std\n",
    "        self.valData = (self.valData - target_mean) / target_std\n",
    "\n",
    "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
    "        return self.allData, self.allLabel, self.valData, self.valLabel, self.testData, self.testLabel\n",
    "\n",
    "    def train(self):\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        #img, label, test_data, test_label = self.get_source_data()\n",
    "        img, label, val_data, val_label, test_data, test_label = self.get_source_data()\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label - 1)\n",
    "        dataset = torch.utils.data.TensorDataset(img, label)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        val_data = torch.from_numpy(val_data)\n",
    "        val_label = torch.from_numpy(val_label - 1)\n",
    "        val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label - 1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(test_label.type(self.LongTensor))\n",
    "        \n",
    "        val_data = Variable(val_data.type(self.Tensor))\n",
    "        val_label = Variable(val_label.type(self.LongTensor))\n",
    "        \n",
    "        bestAcc = 0\n",
    "        averAcc = 0\n",
    "        num = 0\n",
    "        Y_true = 0\n",
    "        Y_pred = 0\n",
    "\n",
    "        # Train the cnn model\n",
    "        total_step = len(self.dataloader)\n",
    "        curr_lr = self.lr\n",
    "\n",
    "        for e in range(self.n_epochs):\n",
    "            # in_epoch = time.time()\n",
    "            self.model.train()\n",
    "            for i, (img, label) in enumerate(self.dataloader):\n",
    "\n",
    "                img = Variable(img.cuda().type(self.Tensor))\n",
    "                label = Variable(label.cuda().type(self.LongTensor)) #FloatTensor\n",
    "\n",
    "                # data augmentation\n",
    "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "                img = torch.cat((img, aug_data))\n",
    "                label = torch.cat((label, aug_label))\n",
    "\n",
    "                outputs = self.model(img)\n",
    "\n",
    "                loss = self.criterion_cls(outputs, label) \n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # test process\n",
    "            if (e + 1) % 1 == 0:\n",
    "                self.model.eval()\n",
    "                Cls = self.model(test_data)\n",
    "                probs = softmax(Cls, dim=1).cpu().detach().numpy()\n",
    "                loss_test = self.criterion_cls(Cls, test_label)\n",
    "                y_pred = torch.max(Cls, 1)[1]\n",
    "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
    "\n",
    "                #self.model.eval()\n",
    "                ValCls = self.model(val_data)\n",
    "                loss_val = self.criterion_cls(ValCls, val_label)\n",
    "                val_pred = torch.max(ValCls, 1)[1]\n",
    "                val_acc = float((val_pred == val_label).cpu().numpy().astype(int).sum()) / float(val_label.size(0))\n",
    "                \n",
    "                train_pred = torch.max(outputs, 1)[1]\n",
    "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
    "                \n",
    "                print('Epoch:', e,\n",
    "                      '  Train loss: %.4f' % loss.detach().cpu().numpy(),\n",
    "                      '  Val loss: %.4f' % loss_val.detach().cpu().numpy(),\n",
    "                      '  Test loss: %.4f' % loss_test.detach().cpu().numpy(),\n",
    "                      '  Train acc: %.4f' % train_acc,\n",
    "                      '  Val acc: %.4f' % val_acc,\n",
    "                      '  Test acc: %.4f' % acc)\n",
    "\n",
    "                num = num + 1\n",
    "                averAcc = averAcc + acc\n",
    "                if acc > bestAcc:\n",
    "                    bestAcc = acc\n",
    "                    Y_true = test_label\n",
    "                    Y_pred = y_pred\n",
    "            \n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            train_losses.append(loss.detach().cpu().numpy())\n",
    "            val_losses.append(loss_val.detach().cpu().numpy())\n",
    "\n",
    "        #torch.save(self.model.module.state_dict(), 'model.pth')\n",
    "        averAcc = averAcc / num\n",
    "        print('The average accuracy is:', averAcc)\n",
    "        print('The best accuracy is:', bestAcc)\n",
    "        \n",
    "        return bestAcc, averAcc, Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    best = 0\n",
    "    aver = 0\n",
    "\n",
    "    for i in range(9):\n",
    "        starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "        seed_n = np.random.randint(2021)\n",
    "        print('seed is ' + str(seed_n))\n",
    "        random.seed(seed_n)\n",
    "        np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "\n",
    "        print('Subject %d' % (i+1))\n",
    "        exp = EEGCCT(i)\n",
    "\n",
    "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
    "        print('THE BEST ACCURACY IS ' + str(bestAcc))\n",
    "\n",
    "        endtime = datetime.datetime.now()\n",
    "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
    "        best = best + bestAcc\n",
    "        aver = aver + averAcc\n",
    "        if i == 0:\n",
    "            yt = Y_true\n",
    "            yp = Y_pred\n",
    "        else:\n",
    "            yt = torch.cat((yt, Y_true))\n",
    "            yp = torch.cat((yp, Y_pred))\n",
    "\n",
    "\n",
    "    best = best / 9\n",
    "    aver = aver / 9\n",
    "    \n",
    "    print(f\"Mean of best is {best}\")\n",
    "    print(f\"Mean of average is {aver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 2017\n",
      "Subject 1\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.6751   Val loss: 0.6853   Test loss: 0.6880   Train acc: 0.6600   Val acc: 0.4802   Test acc: 0.5035\n",
      "Epoch: 1   Train loss: 0.6514   Val loss: 0.6773   Test loss: 0.6819   Train acc: 0.6800   Val acc: 0.5495   Test acc: 0.5729\n",
      "Epoch: 2   Train loss: 0.6145   Val loss: 0.6565   Test loss: 0.6363   Train acc: 0.7400   Val acc: 0.5693   Test acc: 0.6250\n",
      "Epoch: 3   Train loss: 0.5899   Val loss: 0.5903   Test loss: 0.5798   Train acc: 0.6800   Val acc: 0.6931   Test acc: 0.6597\n",
      "Epoch: 4   Train loss: 0.5508   Val loss: 0.5675   Test loss: 0.5323   Train acc: 0.7600   Val acc: 0.7327   Test acc: 0.7396\n",
      "Epoch: 5   Train loss: 0.5684   Val loss: 0.5596   Test loss: 0.5074   Train acc: 0.7400   Val acc: 0.7079   Test acc: 0.7535\n",
      "Epoch: 6   Train loss: 0.4904   Val loss: 0.5559   Test loss: 0.4965   Train acc: 0.7800   Val acc: 0.7129   Test acc: 0.7500\n",
      "Epoch: 7   Train loss: 0.4501   Val loss: 0.5520   Test loss: 0.4865   Train acc: 0.8200   Val acc: 0.7129   Test acc: 0.7535\n",
      "Epoch: 8   Train loss: 0.4918   Val loss: 0.5776   Test loss: 0.5384   Train acc: 0.7200   Val acc: 0.7178   Test acc: 0.6910\n",
      "Epoch: 9   Train loss: 0.4776   Val loss: 0.5475   Test loss: 0.4655   Train acc: 0.7400   Val acc: 0.7277   Test acc: 0.7708\n",
      "Epoch: 10   Train loss: 0.5519   Val loss: 0.5667   Test loss: 0.4539   Train acc: 0.7600   Val acc: 0.7178   Test acc: 0.7812\n",
      "Epoch: 11   Train loss: 0.3533   Val loss: 0.5458   Test loss: 0.4747   Train acc: 0.9200   Val acc: 0.7475   Test acc: 0.7465\n",
      "Epoch: 12   Train loss: 0.3936   Val loss: 0.5380   Test loss: 0.4414   Train acc: 0.8600   Val acc: 0.7475   Test acc: 0.7778\n",
      "Epoch: 13   Train loss: 0.4886   Val loss: 0.5577   Test loss: 0.4941   Train acc: 0.7400   Val acc: 0.7327   Test acc: 0.7569\n",
      "Epoch: 14   Train loss: 0.4321   Val loss: 0.5506   Test loss: 0.4569   Train acc: 0.7600   Val acc: 0.7376   Test acc: 0.7743\n",
      "Epoch: 15   Train loss: 0.3399   Val loss: 0.5309   Test loss: 0.4414   Train acc: 0.8800   Val acc: 0.7277   Test acc: 0.7917\n",
      "Epoch: 16   Train loss: 0.4637   Val loss: 0.5469   Test loss: 0.4367   Train acc: 0.7800   Val acc: 0.7277   Test acc: 0.7882\n",
      "Epoch: 17   Train loss: 0.3718   Val loss: 0.5459   Test loss: 0.4339   Train acc: 0.8400   Val acc: 0.7129   Test acc: 0.7847\n",
      "Epoch: 18   Train loss: 0.3527   Val loss: 0.5564   Test loss: 0.4439   Train acc: 0.8200   Val acc: 0.7327   Test acc: 0.7812\n",
      "Epoch: 19   Train loss: 0.4496   Val loss: 0.5594   Test loss: 0.4441   Train acc: 0.7600   Val acc: 0.7228   Test acc: 0.7812\n",
      "Epoch: 20   Train loss: 0.4613   Val loss: 0.5806   Test loss: 0.4477   Train acc: 0.7400   Val acc: 0.7178   Test acc: 0.7917\n",
      "Epoch: 21   Train loss: 0.2539   Val loss: 0.5660   Test loss: 0.4488   Train acc: 0.9000   Val acc: 0.7277   Test acc: 0.7812\n",
      "Epoch: 22   Train loss: 0.4097   Val loss: 0.5726   Test loss: 0.4506   Train acc: 0.8000   Val acc: 0.7376   Test acc: 0.7778\n",
      "Epoch: 23   Train loss: 0.3572   Val loss: 0.5708   Test loss: 0.4384   Train acc: 0.8400   Val acc: 0.7129   Test acc: 0.7847\n",
      "Epoch: 24   Train loss: 0.3165   Val loss: 0.5642   Test loss: 0.4584   Train acc: 0.8800   Val acc: 0.7030   Test acc: 0.7847\n",
      "The average accuracy is: 0.7401388888888889\n",
      "The best accuracy is: 0.7916666666666666\n",
      "THE BEST ACCURACY IS 0.7916666666666666\n",
      "subject 1 duration: 0:01:59.324506\n",
      "seed is 1092\n",
      "Subject 2\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.3656   Val loss: 0.5006   Test loss: 0.4407   Train acc: 0.8200   Val acc: 0.7475   Test acc: 0.7917\n",
      "Epoch: 1   Train loss: 0.3670   Val loss: 0.5061   Test loss: 0.4532   Train acc: 0.7800   Val acc: 0.7475   Test acc: 0.8160\n",
      "Epoch: 2   Train loss: 0.2869   Val loss: 0.4949   Test loss: 0.4605   Train acc: 0.9000   Val acc: 0.7624   Test acc: 0.8056\n",
      "Epoch: 3   Train loss: 0.2111   Val loss: 0.5011   Test loss: 0.4742   Train acc: 0.8800   Val acc: 0.7624   Test acc: 0.7986\n",
      "Epoch: 4   Train loss: 0.2515   Val loss: 0.4976   Test loss: 0.4818   Train acc: 0.9200   Val acc: 0.7772   Test acc: 0.7812\n",
      "Epoch: 5   Train loss: 0.4428   Val loss: 0.4971   Test loss: 0.4946   Train acc: 0.8000   Val acc: 0.7822   Test acc: 0.7743\n",
      "Epoch: 6   Train loss: 0.2555   Val loss: 0.5175   Test loss: 0.5037   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.7778\n",
      "Epoch: 7   Train loss: 0.2394   Val loss: 0.5180   Test loss: 0.5233   Train acc: 0.8800   Val acc: 0.7574   Test acc: 0.7639\n",
      "Epoch: 8   Train loss: 0.1563   Val loss: 0.5330   Test loss: 0.5611   Train acc: 0.9400   Val acc: 0.7376   Test acc: 0.7847\n",
      "Epoch: 9   Train loss: 0.2369   Val loss: 0.5543   Test loss: 0.6068   Train acc: 0.9000   Val acc: 0.7525   Test acc: 0.7500\n",
      "Epoch: 10   Train loss: 0.2530   Val loss: 0.5467   Test loss: 0.5351   Train acc: 0.8800   Val acc: 0.7327   Test acc: 0.7917\n",
      "Epoch: 11   Train loss: 0.2187   Val loss: 0.5650   Test loss: 0.5376   Train acc: 0.8800   Val acc: 0.7426   Test acc: 0.7674\n",
      "Epoch: 12   Train loss: 0.1648   Val loss: 0.5664   Test loss: 0.5588   Train acc: 0.9200   Val acc: 0.7525   Test acc: 0.7431\n",
      "Epoch: 13   Train loss: 0.2294   Val loss: 0.5919   Test loss: 0.6241   Train acc: 0.9000   Val acc: 0.7624   Test acc: 0.7361\n",
      "Epoch: 14   Train loss: 0.2713   Val loss: 0.5848   Test loss: 0.5495   Train acc: 0.9000   Val acc: 0.7327   Test acc: 0.7500\n",
      "Epoch: 15   Train loss: 0.2057   Val loss: 0.5927   Test loss: 0.5941   Train acc: 0.8800   Val acc: 0.7673   Test acc: 0.7604\n",
      "Epoch: 16   Train loss: 0.1627   Val loss: 0.6016   Test loss: 0.5916   Train acc: 0.9000   Val acc: 0.7277   Test acc: 0.7361\n",
      "Epoch: 17   Train loss: 0.2238   Val loss: 0.6566   Test loss: 0.6607   Train acc: 0.9000   Val acc: 0.7426   Test acc: 0.7118\n",
      "Epoch: 18   Train loss: 0.3449   Val loss: 0.6484   Test loss: 0.6114   Train acc: 0.8400   Val acc: 0.7079   Test acc: 0.7396\n",
      "Epoch: 19   Train loss: 0.1459   Val loss: 0.6464   Test loss: 0.6451   Train acc: 0.9400   Val acc: 0.7426   Test acc: 0.7431\n",
      "Epoch: 20   Train loss: 0.2727   Val loss: 0.6534   Test loss: 0.7228   Train acc: 0.9000   Val acc: 0.7673   Test acc: 0.7222\n",
      "Epoch: 21   Train loss: 0.1670   Val loss: 0.6194   Test loss: 0.6381   Train acc: 0.9400   Val acc: 0.7426   Test acc: 0.7292\n",
      "Epoch: 22   Train loss: 0.1863   Val loss: 0.6712   Test loss: 0.6277   Train acc: 0.9200   Val acc: 0.7426   Test acc: 0.7014\n",
      "Epoch: 23   Train loss: 0.2384   Val loss: 0.6497   Test loss: 0.7254   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.7118\n",
      "Epoch: 24   Train loss: 0.3060   Val loss: 0.6200   Test loss: 0.6376   Train acc: 0.9000   Val acc: 0.7475   Test acc: 0.7222\n",
      "The average accuracy is: 0.756388888888889\n",
      "The best accuracy is: 0.8159722222222222\n",
      "THE BEST ACCURACY IS 0.8159722222222222\n",
      "subject 2 duration: 0:01:57.523739\n",
      "seed is 1441\n",
      "Subject 3\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.4406   Val loss: 0.6968   Test loss: 0.0591   Train acc: 0.8200   Val acc: 0.7228   Test acc: 0.9792\n",
      "Epoch: 1   Train loss: 0.2114   Val loss: 0.7470   Test loss: 0.0674   Train acc: 0.9000   Val acc: 0.7228   Test acc: 0.9792\n",
      "Epoch: 2   Train loss: 0.1462   Val loss: 0.7360   Test loss: 0.0775   Train acc: 0.9400   Val acc: 0.7376   Test acc: 0.9757\n",
      "Epoch: 3   Train loss: 0.2452   Val loss: 0.7582   Test loss: 0.0945   Train acc: 0.9000   Val acc: 0.7030   Test acc: 0.9618\n",
      "Epoch: 4   Train loss: 0.2490   Val loss: 0.7361   Test loss: 0.0998   Train acc: 0.8400   Val acc: 0.7178   Test acc: 0.9549\n",
      "Epoch: 5   Train loss: 0.2341   Val loss: 0.6931   Test loss: 0.0996   Train acc: 0.9400   Val acc: 0.7426   Test acc: 0.9618\n",
      "Epoch: 6   Train loss: 0.2177   Val loss: 0.7221   Test loss: 0.0915   Train acc: 0.8800   Val acc: 0.7228   Test acc: 0.9653\n",
      "Epoch: 7   Train loss: 0.2509   Val loss: 0.7585   Test loss: 0.0983   Train acc: 0.8600   Val acc: 0.7426   Test acc: 0.9583\n",
      "Epoch: 8   Train loss: 0.2664   Val loss: 0.7655   Test loss: 0.0988   Train acc: 0.9000   Val acc: 0.7079   Test acc: 0.9618\n",
      "Epoch: 9   Train loss: 0.1936   Val loss: 0.7682   Test loss: 0.0889   Train acc: 0.9800   Val acc: 0.7178   Test acc: 0.9583\n",
      "Epoch: 10   Train loss: 0.2894   Val loss: 0.7659   Test loss: 0.0856   Train acc: 0.8400   Val acc: 0.7129   Test acc: 0.9618\n",
      "Epoch: 11   Train loss: 0.3007   Val loss: 0.7363   Test loss: 0.0976   Train acc: 0.8600   Val acc: 0.7129   Test acc: 0.9514\n",
      "Epoch: 12   Train loss: 0.1972   Val loss: 0.7570   Test loss: 0.1157   Train acc: 0.9200   Val acc: 0.7376   Test acc: 0.9549\n",
      "Epoch: 13   Train loss: 0.1054   Val loss: 0.7662   Test loss: 0.1035   Train acc: 0.9800   Val acc: 0.7178   Test acc: 0.9549\n",
      "Epoch: 14   Train loss: 0.1860   Val loss: 0.7799   Test loss: 0.1290   Train acc: 0.9200   Val acc: 0.7327   Test acc: 0.9444\n",
      "Epoch: 15   Train loss: 0.2042   Val loss: 0.7775   Test loss: 0.0941   Train acc: 0.9200   Val acc: 0.7178   Test acc: 0.9653\n",
      "Epoch: 16   Train loss: 0.1584   Val loss: 0.7535   Test loss: 0.0994   Train acc: 0.9800   Val acc: 0.7624   Test acc: 0.9549\n",
      "Epoch: 17   Train loss: 0.2223   Val loss: 0.7643   Test loss: 0.1088   Train acc: 0.9000   Val acc: 0.7277   Test acc: 0.9583\n",
      "Epoch: 18   Train loss: 0.1616   Val loss: 0.8339   Test loss: 0.1412   Train acc: 0.9400   Val acc: 0.7129   Test acc: 0.9549\n",
      "Epoch: 19   Train loss: 0.2703   Val loss: 0.8045   Test loss: 0.1224   Train acc: 0.8800   Val acc: 0.7376   Test acc: 0.9410\n",
      "Epoch: 20   Train loss: 0.1056   Val loss: 0.7788   Test loss: 0.1197   Train acc: 0.9800   Val acc: 0.7376   Test acc: 0.9549\n",
      "Epoch: 21   Train loss: 0.1820   Val loss: 0.8195   Test loss: 0.1039   Train acc: 0.9600   Val acc: 0.7228   Test acc: 0.9583\n",
      "Epoch: 22   Train loss: 0.2267   Val loss: 0.8269   Test loss: 0.1179   Train acc: 0.9200   Val acc: 0.7228   Test acc: 0.9479\n",
      "Epoch: 23   Train loss: 0.2645   Val loss: 0.7940   Test loss: 0.1414   Train acc: 0.8800   Val acc: 0.7277   Test acc: 0.9340\n",
      "Epoch: 24   Train loss: 0.2053   Val loss: 0.8400   Test loss: 0.1498   Train acc: 0.9400   Val acc: 0.7426   Test acc: 0.9375\n",
      "The average accuracy is: 0.9572222222222222\n",
      "The best accuracy is: 0.9791666666666666\n",
      "THE BEST ACCURACY IS 0.9791666666666666\n",
      "subject 3 duration: 0:01:57.498192\n",
      "seed is 422\n",
      "Subject 4\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1685   Val loss: 0.7110   Test loss: 0.1023   Train acc: 0.9000   Val acc: 0.7624   Test acc: 0.9583\n",
      "Epoch: 1   Train loss: 0.1846   Val loss: 0.7084   Test loss: 0.1050   Train acc: 0.9400   Val acc: 0.7772   Test acc: 0.9549\n",
      "Epoch: 2   Train loss: 0.1566   Val loss: 0.7459   Test loss: 0.0982   Train acc: 0.9200   Val acc: 0.7673   Test acc: 0.9583\n",
      "Epoch: 3   Train loss: 0.1840   Val loss: 0.7709   Test loss: 0.1708   Train acc: 0.9000   Val acc: 0.7525   Test acc: 0.9410\n",
      "Epoch: 4   Train loss: 0.2074   Val loss: 0.7625   Test loss: 0.1164   Train acc: 0.9400   Val acc: 0.7525   Test acc: 0.9583\n",
      "Epoch: 5   Train loss: 0.2053   Val loss: 0.7619   Test loss: 0.1550   Train acc: 0.9000   Val acc: 0.7772   Test acc: 0.9514\n",
      "Epoch: 6   Train loss: 0.0971   Val loss: 0.7289   Test loss: 0.1268   Train acc: 0.9600   Val acc: 0.7574   Test acc: 0.9583\n",
      "Epoch: 7   Train loss: 0.1547   Val loss: 0.6968   Test loss: 0.1385   Train acc: 0.9200   Val acc: 0.7574   Test acc: 0.9549\n",
      "Epoch: 8   Train loss: 0.1528   Val loss: 0.7731   Test loss: 0.1594   Train acc: 0.9200   Val acc: 0.7574   Test acc: 0.9479\n",
      "Epoch: 9   Train loss: 0.0547   Val loss: 0.7891   Test loss: 0.1955   Train acc: 1.0000   Val acc: 0.7574   Test acc: 0.9236\n",
      "Epoch: 10   Train loss: 0.1038   Val loss: 0.7683   Test loss: 0.1803   Train acc: 0.9400   Val acc: 0.7525   Test acc: 0.9306\n",
      "Epoch: 11   Train loss: 0.2618   Val loss: 0.7683   Test loss: 0.1847   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.9375\n",
      "Epoch: 12   Train loss: 0.0949   Val loss: 0.7541   Test loss: 0.1544   Train acc: 1.0000   Val acc: 0.7723   Test acc: 0.9340\n",
      "Epoch: 13   Train loss: 0.1964   Val loss: 0.7660   Test loss: 0.1571   Train acc: 0.9600   Val acc: 0.7673   Test acc: 0.9549\n",
      "Epoch: 14   Train loss: 0.0688   Val loss: 0.7068   Test loss: 0.2334   Train acc: 0.9800   Val acc: 0.7871   Test acc: 0.8993\n",
      "Epoch: 15   Train loss: 0.3669   Val loss: 0.7602   Test loss: 0.2146   Train acc: 0.8800   Val acc: 0.7673   Test acc: 0.9062\n",
      "Epoch: 16   Train loss: 0.2168   Val loss: 0.7421   Test loss: 0.1652   Train acc: 0.9000   Val acc: 0.7772   Test acc: 0.9306\n",
      "Epoch: 17   Train loss: 0.1635   Val loss: 0.7074   Test loss: 0.1639   Train acc: 0.9400   Val acc: 0.7970   Test acc: 0.9375\n",
      "Epoch: 18   Train loss: 0.1101   Val loss: 0.7949   Test loss: 0.1986   Train acc: 0.9400   Val acc: 0.7376   Test acc: 0.9167\n",
      "Epoch: 19   Train loss: 0.1046   Val loss: 0.7526   Test loss: 0.1718   Train acc: 0.9600   Val acc: 0.7574   Test acc: 0.9340\n",
      "Epoch: 20   Train loss: 0.2265   Val loss: 0.6897   Test loss: 0.1621   Train acc: 0.9200   Val acc: 0.7673   Test acc: 0.9271\n",
      "Epoch: 21   Train loss: 0.0613   Val loss: 0.7871   Test loss: 0.1831   Train acc: 0.9800   Val acc: 0.7525   Test acc: 0.9271\n",
      "Epoch: 22   Train loss: 0.2356   Val loss: 0.8195   Test loss: 0.2327   Train acc: 0.9200   Val acc: 0.7525   Test acc: 0.9097\n",
      "Epoch: 23   Train loss: 0.1712   Val loss: 0.8152   Test loss: 0.2046   Train acc: 0.9000   Val acc: 0.7772   Test acc: 0.9167\n",
      "Epoch: 24   Train loss: 0.0848   Val loss: 0.7343   Test loss: 0.1895   Train acc: 0.9800   Val acc: 0.7822   Test acc: 0.9306\n",
      "The average accuracy is: 0.9359722222222223\n",
      "The best accuracy is: 0.9583333333333334\n",
      "THE BEST ACCURACY IS 0.9583333333333334\n",
      "subject 4 duration: 0:01:56.909065\n",
      "seed is 592\n",
      "Subject 5\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1465   Val loss: 0.4730   Test loss: 0.1849   Train acc: 0.9400   Val acc: 0.8614   Test acc: 0.9514\n",
      "Epoch: 1   Train loss: 0.2121   Val loss: 0.5002   Test loss: 0.1920   Train acc: 0.9200   Val acc: 0.8317   Test acc: 0.9479\n",
      "Epoch: 2   Train loss: 0.2134   Val loss: 0.5250   Test loss: 0.1880   Train acc: 0.9400   Val acc: 0.8267   Test acc: 0.9514\n",
      "Epoch: 3   Train loss: 0.0704   Val loss: 0.4999   Test loss: 0.1944   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9479\n",
      "Epoch: 4   Train loss: 0.0329   Val loss: 0.4594   Test loss: 0.1987   Train acc: 1.0000   Val acc: 0.8713   Test acc: 0.9514\n",
      "Epoch: 5   Train loss: 0.0254   Val loss: 0.5335   Test loss: 0.2209   Train acc: 1.0000   Val acc: 0.8515   Test acc: 0.9479\n",
      "Epoch: 6   Train loss: 0.0937   Val loss: 0.5035   Test loss: 0.2247   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9375\n",
      "Epoch: 7   Train loss: 0.2922   Val loss: 0.5101   Test loss: 0.2440   Train acc: 0.8800   Val acc: 0.8564   Test acc: 0.9514\n",
      "Epoch: 8   Train loss: 0.0603   Val loss: 0.4967   Test loss: 0.2140   Train acc: 1.0000   Val acc: 0.8465   Test acc: 0.9444\n",
      "Epoch: 9   Train loss: 0.0525   Val loss: 0.5193   Test loss: 0.2558   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9375\n",
      "Epoch: 10   Train loss: 0.2419   Val loss: 0.4851   Test loss: 0.2438   Train acc: 0.8600   Val acc: 0.8366   Test acc: 0.9410\n",
      "Epoch: 11   Train loss: 0.2129   Val loss: 0.4902   Test loss: 0.2603   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9340\n",
      "Epoch: 12   Train loss: 0.1095   Val loss: 0.5957   Test loss: 0.2881   Train acc: 0.9600   Val acc: 0.7871   Test acc: 0.8958\n",
      "Epoch: 13   Train loss: 0.1442   Val loss: 0.4838   Test loss: 0.2325   Train acc: 0.9600   Val acc: 0.8515   Test acc: 0.9340\n",
      "Epoch: 14   Train loss: 0.0878   Val loss: 0.5298   Test loss: 0.2160   Train acc: 0.9600   Val acc: 0.8168   Test acc: 0.9444\n",
      "Epoch: 15   Train loss: 0.2368   Val loss: 0.5416   Test loss: 0.2920   Train acc: 0.9000   Val acc: 0.8366   Test acc: 0.9167\n",
      "Epoch: 16   Train loss: 0.2074   Val loss: 0.5441   Test loss: 0.2434   Train acc: 0.9400   Val acc: 0.8218   Test acc: 0.9375\n",
      "Epoch: 17   Train loss: 0.0226   Val loss: 0.5300   Test loss: 0.2654   Train acc: 1.0000   Val acc: 0.8465   Test acc: 0.9375\n",
      "Epoch: 18   Train loss: 0.0799   Val loss: 0.6001   Test loss: 0.2956   Train acc: 0.9600   Val acc: 0.8119   Test acc: 0.9097\n",
      "Epoch: 19   Train loss: 0.2147   Val loss: 0.5781   Test loss: 0.2851   Train acc: 0.9000   Val acc: 0.8218   Test acc: 0.9201\n",
      "Epoch: 20   Train loss: 0.0642   Val loss: 0.6027   Test loss: 0.2707   Train acc: 0.9800   Val acc: 0.8020   Test acc: 0.9340\n",
      "Epoch: 21   Train loss: 0.1662   Val loss: 0.5894   Test loss: 0.2800   Train acc: 0.9200   Val acc: 0.8168   Test acc: 0.9236\n",
      "Epoch: 22   Train loss: 0.1479   Val loss: 0.5884   Test loss: 0.3183   Train acc: 0.9200   Val acc: 0.8119   Test acc: 0.9167\n",
      "Epoch: 23   Train loss: 0.2194   Val loss: 0.6115   Test loss: 0.3084   Train acc: 0.9000   Val acc: 0.8218   Test acc: 0.9097\n",
      "Epoch: 24   Train loss: 0.1251   Val loss: 0.5977   Test loss: 0.2735   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9271\n",
      "The average accuracy is: 0.9340277777777777\n",
      "The best accuracy is: 0.9513888888888888\n",
      "THE BEST ACCURACY IS 0.9513888888888888\n",
      "subject 5 duration: 0:01:56.958383\n",
      "seed is 674\n",
      "Subject 6\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1734   Val loss: 0.4440   Test loss: 0.1362   Train acc: 0.9200   Val acc: 0.8713   Test acc: 0.9618\n",
      "Epoch: 1   Train loss: 0.3385   Val loss: 0.5077   Test loss: 0.1649   Train acc: 0.9000   Val acc: 0.8416   Test acc: 0.9618\n",
      "Epoch: 2   Train loss: 0.1792   Val loss: 0.4874   Test loss: 0.1484   Train acc: 0.9400   Val acc: 0.8366   Test acc: 0.9688\n",
      "Epoch: 3   Train loss: 0.2896   Val loss: 0.5306   Test loss: 0.1928   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9479\n",
      "Epoch: 4   Train loss: 0.1491   Val loss: 0.4851   Test loss: 0.1612   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9549\n",
      "Epoch: 5   Train loss: 0.1578   Val loss: 0.4749   Test loss: 0.1654   Train acc: 0.9600   Val acc: 0.8713   Test acc: 0.9514\n",
      "Epoch: 6   Train loss: 0.1022   Val loss: 0.4785   Test loss: 0.2319   Train acc: 0.9600   Val acc: 0.8614   Test acc: 0.9375\n",
      "Epoch: 7   Train loss: 0.0182   Val loss: 0.5503   Test loss: 0.2351   Train acc: 1.0000   Val acc: 0.8317   Test acc: 0.9271\n",
      "Epoch: 8   Train loss: 0.2660   Val loss: 0.5143   Test loss: 0.1829   Train acc: 0.8800   Val acc: 0.8416   Test acc: 0.9479\n",
      "Epoch: 9   Train loss: 0.1715   Val loss: 0.4681   Test loss: 0.2164   Train acc: 0.9200   Val acc: 0.8713   Test acc: 0.9375\n",
      "Epoch: 10   Train loss: 0.1553   Val loss: 0.6053   Test loss: 0.2385   Train acc: 0.9800   Val acc: 0.8218   Test acc: 0.9201\n",
      "Epoch: 11   Train loss: 0.1099   Val loss: 0.5048   Test loss: 0.1911   Train acc: 0.9600   Val acc: 0.8614   Test acc: 0.9444\n",
      "Epoch: 12   Train loss: 0.1133   Val loss: 0.5141   Test loss: 0.2691   Train acc: 0.9400   Val acc: 0.8416   Test acc: 0.9236\n",
      "Epoch: 13   Train loss: 0.0731   Val loss: 0.4789   Test loss: 0.2136   Train acc: 0.9600   Val acc: 0.8762   Test acc: 0.9410\n",
      "Epoch: 14   Train loss: 0.0513   Val loss: 0.4442   Test loss: 0.1824   Train acc: 1.0000   Val acc: 0.8762   Test acc: 0.9444\n",
      "Epoch: 15   Train loss: 0.0341   Val loss: 0.5159   Test loss: 0.2242   Train acc: 1.0000   Val acc: 0.8366   Test acc: 0.9306\n",
      "Epoch: 16   Train loss: 0.0270   Val loss: 0.5238   Test loss: 0.2250   Train acc: 1.0000   Val acc: 0.8465   Test acc: 0.9410\n",
      "Epoch: 17   Train loss: 0.0741   Val loss: 0.5163   Test loss: 0.2102   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9410\n",
      "Epoch: 18   Train loss: 0.1035   Val loss: 0.5444   Test loss: 0.2101   Train acc: 0.9600   Val acc: 0.8465   Test acc: 0.9340\n",
      "Epoch: 19   Train loss: 0.0518   Val loss: 0.4443   Test loss: 0.2092   Train acc: 1.0000   Val acc: 0.8465   Test acc: 0.9410\n",
      "Epoch: 20   Train loss: 0.2083   Val loss: 0.4981   Test loss: 0.2317   Train acc: 0.9000   Val acc: 0.8465   Test acc: 0.9236\n",
      "Epoch: 21   Train loss: 0.1061   Val loss: 0.5491   Test loss: 0.2451   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9271\n",
      "Epoch: 22   Train loss: 0.0316   Val loss: 0.4770   Test loss: 0.2041   Train acc: 1.0000   Val acc: 0.8515   Test acc: 0.9479\n",
      "Epoch: 23   Train loss: 0.1219   Val loss: 0.4837   Test loss: 0.2689   Train acc: 0.9600   Val acc: 0.8812   Test acc: 0.9201\n",
      "Epoch: 24   Train loss: 0.1356   Val loss: 0.4497   Test loss: 0.2125   Train acc: 0.9400   Val acc: 0.8614   Test acc: 0.9410\n",
      "The average accuracy is: 0.9406944444444444\n",
      "The best accuracy is: 0.96875\n",
      "THE BEST ACCURACY IS 0.96875\n",
      "subject 6 duration: 0:01:56.767918\n",
      "seed is 1779\n",
      "Subject 7\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0673   Val loss: 0.3978   Test loss: 0.0974   Train acc: 0.9600   Val acc: 0.8762   Test acc: 0.9688\n",
      "Epoch: 1   Train loss: 0.1361   Val loss: 0.3659   Test loss: 0.0893   Train acc: 0.9200   Val acc: 0.8861   Test acc: 0.9757\n",
      "Epoch: 2   Train loss: 0.2197   Val loss: 0.3754   Test loss: 0.0755   Train acc: 0.9000   Val acc: 0.8911   Test acc: 0.9722\n",
      "Epoch: 3   Train loss: 0.1035   Val loss: 0.3388   Test loss: 0.0760   Train acc: 0.9600   Val acc: 0.9010   Test acc: 0.9653\n",
      "Epoch: 4   Train loss: 0.0864   Val loss: 0.3910   Test loss: 0.0817   Train acc: 0.9400   Val acc: 0.9059   Test acc: 0.9688\n",
      "Epoch: 5   Train loss: 0.0872   Val loss: 0.3610   Test loss: 0.0722   Train acc: 0.9600   Val acc: 0.8960   Test acc: 0.9757\n",
      "Epoch: 6   Train loss: 0.0747   Val loss: 0.4256   Test loss: 0.0813   Train acc: 0.9800   Val acc: 0.8812   Test acc: 0.9757\n",
      "Epoch: 7   Train loss: 0.1492   Val loss: 0.4173   Test loss: 0.0943   Train acc: 0.9400   Val acc: 0.8663   Test acc: 0.9688\n",
      "Epoch: 8   Train loss: 0.0975   Val loss: 0.4170   Test loss: 0.0790   Train acc: 0.9600   Val acc: 0.8911   Test acc: 0.9757\n",
      "Epoch: 9   Train loss: 0.0533   Val loss: 0.4520   Test loss: 0.0915   Train acc: 0.9800   Val acc: 0.8861   Test acc: 0.9722\n",
      "Epoch: 10   Train loss: 0.0747   Val loss: 0.4328   Test loss: 0.1001   Train acc: 0.9800   Val acc: 0.8663   Test acc: 0.9653\n",
      "Epoch: 11   Train loss: 0.0237   Val loss: 0.4155   Test loss: 0.0894   Train acc: 1.0000   Val acc: 0.8713   Test acc: 0.9688\n",
      "Epoch: 12   Train loss: 0.2332   Val loss: 0.4221   Test loss: 0.0928   Train acc: 0.9200   Val acc: 0.8762   Test acc: 0.9688\n",
      "Epoch: 13   Train loss: 0.0220   Val loss: 0.3868   Test loss: 0.0887   Train acc: 1.0000   Val acc: 0.8960   Test acc: 0.9722\n",
      "Epoch: 14   Train loss: 0.1006   Val loss: 0.3860   Test loss: 0.1008   Train acc: 0.9400   Val acc: 0.8861   Test acc: 0.9618\n",
      "Epoch: 15   Train loss: 0.0675   Val loss: 0.4185   Test loss: 0.0769   Train acc: 0.9800   Val acc: 0.8762   Test acc: 0.9722\n",
      "Epoch: 16   Train loss: 0.0886   Val loss: 0.4462   Test loss: 0.0837   Train acc: 0.9600   Val acc: 0.8713   Test acc: 0.9792\n",
      "Epoch: 17   Train loss: 0.0272   Val loss: 0.5725   Test loss: 0.1266   Train acc: 1.0000   Val acc: 0.8465   Test acc: 0.9688\n",
      "Epoch: 18   Train loss: 0.0669   Val loss: 0.4776   Test loss: 0.0986   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9688\n",
      "Epoch: 19   Train loss: 0.1033   Val loss: 0.4504   Test loss: 0.0926   Train acc: 0.9600   Val acc: 0.8713   Test acc: 0.9757\n",
      "Epoch: 20   Train loss: 0.0555   Val loss: 0.4485   Test loss: 0.0962   Train acc: 1.0000   Val acc: 0.8663   Test acc: 0.9688\n",
      "Epoch: 21   Train loss: 0.0333   Val loss: 0.6052   Test loss: 0.1368   Train acc: 1.0000   Val acc: 0.8366   Test acc: 0.9618\n",
      "Epoch: 22   Train loss: 0.1764   Val loss: 0.4079   Test loss: 0.0850   Train acc: 0.9400   Val acc: 0.8713   Test acc: 0.9757\n",
      "Epoch: 23   Train loss: 0.0531   Val loss: 0.5008   Test loss: 0.0886   Train acc: 0.9800   Val acc: 0.8663   Test acc: 0.9722\n",
      "Epoch: 24   Train loss: 0.1230   Val loss: 0.4216   Test loss: 0.0917   Train acc: 0.9600   Val acc: 0.8812   Test acc: 0.9653\n",
      "The average accuracy is: 0.9705555555555554\n",
      "The best accuracy is: 0.9791666666666666\n",
      "THE BEST ACCURACY IS 0.9791666666666666\n",
      "subject 7 duration: 0:01:56.631754\n",
      "seed is 458\n",
      "Subject 8\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1152   Val loss: 0.3729   Test loss: 0.0371   Train acc: 0.9400   Val acc: 0.9109   Test acc: 0.9931\n",
      "Epoch: 1   Train loss: 0.1191   Val loss: 0.3621   Test loss: 0.0484   Train acc: 0.9400   Val acc: 0.9010   Test acc: 0.9896\n",
      "Epoch: 2   Train loss: 0.1636   Val loss: 0.4502   Test loss: 0.0493   Train acc: 0.9400   Val acc: 0.8663   Test acc: 0.9896\n",
      "Epoch: 3   Train loss: 0.1201   Val loss: 0.4977   Test loss: 0.0325   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9965\n",
      "Epoch: 4   Train loss: 0.0440   Val loss: 0.4063   Test loss: 0.0456   Train acc: 0.9800   Val acc: 0.8960   Test acc: 0.9896\n",
      "Epoch: 5   Train loss: 0.1420   Val loss: 0.4250   Test loss: 0.0339   Train acc: 0.9600   Val acc: 0.8465   Test acc: 0.9931\n",
      "Epoch: 6   Train loss: 0.1553   Val loss: 0.4804   Test loss: 0.0315   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9965\n",
      "Epoch: 7   Train loss: 0.0623   Val loss: 0.4422   Test loss: 0.0497   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9931\n",
      "Epoch: 8   Train loss: 0.1316   Val loss: 0.4447   Test loss: 0.0403   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9931\n",
      "Epoch: 9   Train loss: 0.0709   Val loss: 0.4823   Test loss: 0.0341   Train acc: 0.9800   Val acc: 0.8218   Test acc: 0.9965\n",
      "Epoch: 10   Train loss: 0.0624   Val loss: 0.4569   Test loss: 0.0536   Train acc: 0.9800   Val acc: 0.8713   Test acc: 0.9861\n",
      "Epoch: 11   Train loss: 0.1770   Val loss: 0.4850   Test loss: 0.0339   Train acc: 0.9600   Val acc: 0.8564   Test acc: 0.9931\n",
      "Epoch: 12   Train loss: 0.1104   Val loss: 0.4801   Test loss: 0.0386   Train acc: 0.9600   Val acc: 0.8614   Test acc: 0.9931\n",
      "Epoch: 13   Train loss: 0.2246   Val loss: 0.5301   Test loss: 0.0344   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9931\n",
      "Epoch: 14   Train loss: 0.0223   Val loss: 0.4294   Test loss: 0.0435   Train acc: 1.0000   Val acc: 0.8663   Test acc: 0.9931\n",
      "Epoch: 15   Train loss: 0.1417   Val loss: 0.5066   Test loss: 0.0344   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9931\n",
      "Epoch: 16   Train loss: 0.1077   Val loss: 0.5015   Test loss: 0.0433   Train acc: 0.9600   Val acc: 0.8564   Test acc: 0.9861\n",
      "Epoch: 17   Train loss: 0.2095   Val loss: 0.4585   Test loss: 0.0367   Train acc: 0.9200   Val acc: 0.8515   Test acc: 0.9931\n",
      "Epoch: 18   Train loss: 0.1014   Val loss: 0.4959   Test loss: 0.0370   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9931\n",
      "Epoch: 19   Train loss: 0.0947   Val loss: 0.5411   Test loss: 0.0345   Train acc: 0.9400   Val acc: 0.8416   Test acc: 0.9965\n",
      "Epoch: 20   Train loss: 0.1133   Val loss: 0.4739   Test loss: 0.0375   Train acc: 0.9600   Val acc: 0.8465   Test acc: 0.9931\n",
      "Epoch: 21   Train loss: 0.1369   Val loss: 0.4685   Test loss: 0.0455   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9931\n",
      "Epoch: 22   Train loss: 0.0528   Val loss: 0.5335   Test loss: 0.0356   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9965\n",
      "Epoch: 23   Train loss: 0.0336   Val loss: 0.5101   Test loss: 0.0349   Train acc: 1.0000   Val acc: 0.8267   Test acc: 0.9965\n",
      "Epoch: 24   Train loss: 0.0987   Val loss: 0.3785   Test loss: 0.0384   Train acc: 0.9600   Val acc: 0.8762   Test acc: 0.9965\n",
      "The average accuracy is: 0.9930555555555558\n",
      "The best accuracy is: 0.9965277777777778\n",
      "THE BEST ACCURACY IS 0.9965277777777778\n",
      "subject 8 duration: 0:01:56.699383\n",
      "seed is 18\n",
      "Subject 9\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0160   Val loss: 0.0646   Test loss: 2.1448   Train acc: 1.0000   Val acc: 0.9870   Test acc: 0.5799\n",
      "Epoch: 1   Train loss: 0.0494   Val loss: 0.0622   Test loss: 2.1086   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6042\n",
      "Epoch: 2   Train loss: 0.0898   Val loss: 0.0728   Test loss: 2.0391   Train acc: 0.9649   Val acc: 0.9827   Test acc: 0.5868\n",
      "Epoch: 3   Train loss: 0.0826   Val loss: 0.0777   Test loss: 2.0629   Train acc: 0.9825   Val acc: 0.9913   Test acc: 0.6007\n",
      "Epoch: 4   Train loss: 0.0927   Val loss: 0.0751   Test loss: 2.0726   Train acc: 0.9649   Val acc: 0.9913   Test acc: 0.6007\n",
      "Epoch: 5   Train loss: 0.0824   Val loss: 0.0766   Test loss: 1.9512   Train acc: 0.9649   Val acc: 0.9913   Test acc: 0.6111\n",
      "Epoch: 6   Train loss: 0.2541   Val loss: 0.0712   Test loss: 2.0155   Train acc: 0.9298   Val acc: 0.9913   Test acc: 0.6007\n",
      "Epoch: 7   Train loss: 0.2143   Val loss: 0.0685   Test loss: 1.9918   Train acc: 0.8947   Val acc: 0.9784   Test acc: 0.6076\n",
      "Epoch: 8   Train loss: 0.0805   Val loss: 0.0755   Test loss: 2.0216   Train acc: 0.9474   Val acc: 0.9870   Test acc: 0.6076\n",
      "Epoch: 9   Train loss: 0.0695   Val loss: 0.1000   Test loss: 2.0367   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.5972\n",
      "Epoch: 10   Train loss: 0.0574   Val loss: 0.0782   Test loss: 2.0112   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6007\n",
      "Epoch: 11   Train loss: 0.0924   Val loss: 0.0986   Test loss: 2.0485   Train acc: 0.9474   Val acc: 0.9827   Test acc: 0.5972\n",
      "Epoch: 12   Train loss: 0.0781   Val loss: 0.0909   Test loss: 2.0543   Train acc: 0.9649   Val acc: 0.9697   Test acc: 0.5938\n",
      "Epoch: 13   Train loss: 0.0637   Val loss: 0.0846   Test loss: 2.2380   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.5868\n",
      "Epoch: 14   Train loss: 0.1179   Val loss: 0.0768   Test loss: 2.0379   Train acc: 0.9298   Val acc: 0.9740   Test acc: 0.6042\n",
      "Epoch: 15   Train loss: 0.1525   Val loss: 0.0786   Test loss: 2.0253   Train acc: 0.9474   Val acc: 0.9784   Test acc: 0.6181\n",
      "Epoch: 16   Train loss: 0.0641   Val loss: 0.0782   Test loss: 1.9859   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6146\n",
      "Epoch: 17   Train loss: 0.0885   Val loss: 0.0665   Test loss: 2.0577   Train acc: 0.9649   Val acc: 0.9870   Test acc: 0.5938\n",
      "Epoch: 18   Train loss: 0.0326   Val loss: 0.0677   Test loss: 2.1485   Train acc: 1.0000   Val acc: 0.9913   Test acc: 0.5868\n",
      "Epoch: 19   Train loss: 0.0749   Val loss: 0.0725   Test loss: 2.1684   Train acc: 0.9649   Val acc: 0.9913   Test acc: 0.6111\n",
      "Epoch: 20   Train loss: 0.1596   Val loss: 0.1134   Test loss: 2.2735   Train acc: 0.9474   Val acc: 0.9697   Test acc: 0.5938\n",
      "Epoch: 21   Train loss: 0.0325   Val loss: 0.0773   Test loss: 2.1176   Train acc: 1.0000   Val acc: 0.9870   Test acc: 0.6146\n",
      "Epoch: 22   Train loss: 0.0826   Val loss: 0.0787   Test loss: 2.0839   Train acc: 0.9474   Val acc: 0.9870   Test acc: 0.6042\n",
      "Epoch: 23   Train loss: 0.0362   Val loss: 0.0883   Test loss: 2.2089   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6076\n",
      "Epoch: 24   Train loss: 0.0394   Val loss: 0.0908   Test loss: 2.2094   Train acc: 0.9825   Val acc: 0.9784   Test acc: 0.5833\n",
      "The average accuracy is: 0.6002777777777778\n",
      "The best accuracy is: 0.6180555555555556\n",
      "THE BEST ACCURACY IS 0.6180555555555556\n",
      "subject 9 duration: 0:03:16.994240\n",
      "Mean of best is 0.8954475308641976\n",
      "Mean of average is 0.8698148148148149\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
