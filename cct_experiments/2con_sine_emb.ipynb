{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.cct import CCT\n",
    "from torchinfo import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCT(kernel_sizes=[(22, 1), (1, 24)], stride=(1, 1), padding=(0, 0),\n",
    "            pooling_kernel_size=(3, 3), pooling_stride=(1, 1), pooling_padding=(0, 0),\n",
    "            n_conv_layers=2, n_input_channels=1,\n",
    "            in_planes=64, activation=None, # ReLU\n",
    "            max_pool=False, conv_bias=False,\n",
    "            dim=64, num_layers=3,\n",
    "            num_heads=4, num_classes=2, \n",
    "            attn_dropout=0.1, dropout=0.1, \n",
    "            mlp_size=64, positional_emb=\"sine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "CCT (CCT)                                          [64, 1, 22, 321]     [64, 2]              --                   Partial\n",
       "├─Tokenizer (tokenizer)                            [64, 1, 22, 321]     [64, 298, 64]        --                   True\n",
       "│    └─Sequential (conv_layers)                    [64, 1, 22, 321]     [64, 64, 1, 298]     --                   True\n",
       "│    │    └─Sequential (0)                         [64, 1, 22, 321]     [64, 64, 1, 321]     1,408                True\n",
       "│    │    └─Sequential (1)                         [64, 64, 1, 321]     [64, 64, 1, 298]     98,304               True\n",
       "│    └─Flatten (flattener)                         [64, 64, 1, 298]     [64, 64, 298]        --                   --\n",
       "├─Transformer (transformer)                        [64, 298, 64]        [64, 2]              19,072               Partial\n",
       "│    └─Dropout (dropout)                           [64, 298, 64]        [64, 298, 64]        --                   --\n",
       "│    └─ModuleList (blocks)                         --                   --                   --                   True\n",
       "│    │    └─EncoderLayer (0)                       [64, 298, 64]        [64, 298, 64]        24,896               True\n",
       "│    │    └─EncoderLayer (1)                       [64, 298, 64]        [64, 298, 64]        24,896               True\n",
       "│    │    └─EncoderLayer (2)                       [64, 298, 64]        [64, 298, 64]        24,896               True\n",
       "│    └─LayerNorm (norm)                            [64, 298, 64]        [64, 298, 64]        128                  True\n",
       "│    └─Linear (attention_pool)                     [64, 298, 64]        [64, 298, 1]         65                   True\n",
       "│    └─Linear (fc)                                 [64, 64]             [64, 2]              130                  True\n",
       "==================================================================================================================================\n",
       "Total params: 193,795\n",
       "Trainable params: 174,723\n",
       "Non-trainable params: 19,072\n",
       "Total mult-adds (G): 1.91\n",
       "==================================================================================================================================\n",
       "Input size (MB): 1.81\n",
       "Forward/backward pass size (MB): 235.26\n",
       "Params size (MB): 0.70\n",
       "Estimated Total Size (MB): 237.77\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(64, 1, 22, 321),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['datasets/aBNCI2014001R.pickle', 'datasets/aBNCI2014004R.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "data = load_data(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 321)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = ['left_hand', 'right_hand']\n",
    "subject = 0\n",
    "s1 = data[subject]\n",
    "s1.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU device name : NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dev.type == 'cuda':\n",
    "    print('Your GPU device name :', torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCCT():\n",
    "    def __init__(self, nsub, n_subj=9):\n",
    "        super(ExP, self).__init__()\n",
    "        self.batch_size = 36\n",
    "        self.n_epochs = 25  #2000\n",
    "        self.c_dim = 4\n",
    "        self.lr = 3e-5\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.dimension = (190, 50)\n",
    "        self.nSub = nsub\n",
    "        self.n_subjects = 8 # total?\n",
    "        self.start_epoch = 0\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "        self.FloatTensor = torch.cuda.FloatTensor\n",
    "\n",
    "        self.criterion_l1 = torch.nn.L1Loss().cuda()\n",
    "        self.criterion_l2 = torch.nn.MSELoss().cuda()\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = model.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to(\"cuda\")\n",
    "            \n",
    "        self.total_params = sum(param.numel() for param in self.model.parameters())\n",
    "        print(\"Number of parameters: \", self.total_params)\n",
    "\n",
    "        #self.model = self.model.cuda()\n",
    "        # summary(self.model, (1, 22, 1000))\n",
    "\n",
    "\n",
    "    # Segmentation and Reconstruction (S&R) data augmentation\n",
    "    def interaug(self, timg, label):  \n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "        for cls4aug in range(2):\n",
    "            cls_idx = np.where(label == cls4aug + 1)\n",
    "            tmp_data = timg[cls_idx]\n",
    "            tmp_label = label[cls_idx]\n",
    "\n",
    "            tmp_aug_data = np.zeros((int(self.batch_size / 2), 1, 22, 321))\n",
    "            for ri in range(int(self.batch_size / 2)):\n",
    "                for rj in range(3):\n",
    "                    rand_idx = np.random.randint(0, tmp_data.shape[0], 3)\n",
    "                    tmp_aug_data[ri, :, :, rj * 107:(rj + 1) * 107] = tmp_data[rand_idx[rj], :, :,\n",
    "                                                                      rj * 107:(rj + 1) * 107]\n",
    "\n",
    "            aug_data.append(tmp_aug_data)\n",
    "            aug_label.append(tmp_label[:int(self.batch_size / 2)])\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        aug_data = aug_data[aug_shuffle, :, :]\n",
    "        aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        aug_data = torch.from_numpy(aug_data).cuda()\n",
    "        aug_data = aug_data.float()\n",
    "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
    "        aug_label = aug_label.long()\n",
    "        return aug_data, aug_label\n",
    "\n",
    "    def get_source_data(self):\n",
    "        \n",
    "        self.test_subject = self.nSub\n",
    "\n",
    "        # Get the data from the epochs object\n",
    "        self.data = load_data(datasets[0])\n",
    "        print('Dataset: ', datasets[0])\n",
    "\n",
    "        self.train_subjects = [i for i in range(self.n_subjects) if i != self.test_subject]\n",
    "\n",
    "        # Prepare test data\n",
    "        self.X_test = self.data[self.test_subject].get_data()\n",
    "        self.y_test = self.data[self.test_subject].events[:, -1]\n",
    "\n",
    "        # Prepare training data\n",
    "        self.X_train = np.concatenate([self.data[i].get_data() for i in self.train_subjects], axis=0)\n",
    "        self.y_train = np.concatenate([self.data[i].events[:, -1] for i in self.train_subjects], axis=0)\n",
    "\n",
    "        # train and val data\n",
    "        self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(self.X_train, self.y_train, test_size=0.1, random_state=42)\n",
    "        \n",
    "        self.allData = np.expand_dims(self.train_data, axis=1)\n",
    "        self.allLabel = self.train_label\n",
    "        \n",
    "        self.valData = np.expand_dims(self.val_data, axis=1)\n",
    "        self.valLabel = self.val_label\n",
    "\n",
    "        shuffle_num = np.random.permutation(len(self.allData))\n",
    "        self.allData = self.allData[shuffle_num, :, :, :]\n",
    "        self.allLabel = self.allLabel[shuffle_num]\n",
    "\n",
    "        # test data  \n",
    "        self.testData = np.expand_dims(self.X_test, axis=1)\n",
    "        self.testLabel = self.y_test\n",
    "        \n",
    "        # standardize\n",
    "        target_mean = np.mean(self.allData)\n",
    "        target_std = np.std(self.allData)\n",
    "        self.allData = (self.allData - target_mean) / target_std\n",
    "        self.testData = (self.testData - target_mean) / target_std\n",
    "        self.valData = (self.valData - target_mean) / target_std\n",
    "\n",
    "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
    "        return self.allData, self.allLabel, self.valData, self.valLabel, self.testData, self.testLabel\n",
    "\n",
    "    def train(self):\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        #img, label, test_data, test_label = self.get_source_data()\n",
    "        img, label, val_data, val_label, test_data, test_label = self.get_source_data()\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label - 1)\n",
    "        dataset = torch.utils.data.TensorDataset(img, label)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        val_data = torch.from_numpy(val_data)\n",
    "        val_label = torch.from_numpy(val_label - 1)\n",
    "        val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label - 1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(test_label.type(self.LongTensor))\n",
    "        \n",
    "        val_data = Variable(val_data.type(self.Tensor))\n",
    "        val_label = Variable(val_label.type(self.LongTensor))\n",
    "        \n",
    "        bestAcc = 0\n",
    "        averAcc = 0\n",
    "        num = 0\n",
    "        Y_true = 0\n",
    "        Y_pred = 0\n",
    "\n",
    "        # Train the cnn model\n",
    "        total_step = len(self.dataloader)\n",
    "        curr_lr = self.lr\n",
    "\n",
    "        for e in range(self.n_epochs):\n",
    "            # in_epoch = time.time()\n",
    "            self.model.train()\n",
    "            for i, (img, label) in enumerate(self.dataloader):\n",
    "\n",
    "                img = Variable(img.cuda().type(self.Tensor))\n",
    "                label = Variable(label.cuda().type(self.LongTensor)) #FloatTensor\n",
    "\n",
    "                # data augmentation\n",
    "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "                img = torch.cat((img, aug_data))\n",
    "                label = torch.cat((label, aug_label))\n",
    "\n",
    "                outputs = self.model(img)\n",
    "\n",
    "                loss = self.criterion_cls(outputs, label) \n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # test process\n",
    "            if (e + 1) % 1 == 0:\n",
    "                self.model.eval()\n",
    "                Cls = self.model(test_data)\n",
    "                probs = softmax(Cls, dim=1).cpu().detach().numpy()\n",
    "                loss_test = self.criterion_cls(Cls, test_label)\n",
    "                y_pred = torch.max(Cls, 1)[1]\n",
    "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
    "\n",
    "                #self.model.eval()\n",
    "                ValCls = self.model(val_data)\n",
    "                loss_val = self.criterion_cls(ValCls, val_label)\n",
    "                val_pred = torch.max(ValCls, 1)[1]\n",
    "                val_acc = float((val_pred == val_label).cpu().numpy().astype(int).sum()) / float(val_label.size(0))\n",
    "                \n",
    "                train_pred = torch.max(outputs, 1)[1]\n",
    "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
    "                \n",
    "                print('Epoch:', e,\n",
    "                      '  Train loss: %.4f' % loss.detach().cpu().numpy(),\n",
    "                      '  Val loss: %.4f' % loss_val.detach().cpu().numpy(),\n",
    "                      '  Test loss: %.4f' % loss_test.detach().cpu().numpy(),\n",
    "                      '  Train acc: %.4f' % train_acc,\n",
    "                      '  Val acc: %.4f' % val_acc,\n",
    "                      '  Test acc: %.4f' % acc)\n",
    "\n",
    "                num = num + 1\n",
    "                averAcc = averAcc + acc\n",
    "                if acc > bestAcc:\n",
    "                    bestAcc = acc\n",
    "                    Y_true = test_label\n",
    "                    Y_pred = y_pred\n",
    "            \n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            train_losses.append(loss.detach().cpu().numpy())\n",
    "            val_losses.append(loss_val.detach().cpu().numpy())\n",
    "\n",
    "        #torch.save(self.model.module.state_dict(), 'model.pth')\n",
    "        averAcc = averAcc / num\n",
    "        print('The average accuracy is:', averAcc)\n",
    "        print('The best accuracy is:', bestAcc)\n",
    "        \n",
    "        return bestAcc, averAcc, Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    best = 0\n",
    "    aver = 0\n",
    "\n",
    "    for i in range(9):\n",
    "        starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "        seed_n = np.random.randint(2021)\n",
    "        print('seed is ' + str(seed_n))\n",
    "        random.seed(seed_n)\n",
    "        np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "\n",
    "        print('Subject %d' % (i+1))\n",
    "        exp = EEGCCT(i)\n",
    "\n",
    "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
    "        print('THE BEST ACCURACY IS ' + str(bestAcc))\n",
    "\n",
    "        endtime = datetime.datetime.now()\n",
    "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
    "        best = best + bestAcc\n",
    "        aver = aver + averAcc\n",
    "        if i == 0:\n",
    "            yt = Y_true\n",
    "            yp = Y_pred\n",
    "        else:\n",
    "            yt = torch.cat((yt, Y_true))\n",
    "            yp = torch.cat((yp, Y_pred))\n",
    "\n",
    "\n",
    "    best = best / 9\n",
    "    aver = aver / 9\n",
    "    \n",
    "    print(f\"Mean of best is {best}\")\n",
    "    print(f\"Mean of average is {aver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 1327\n",
      "Subject 1\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.6851   Val loss: 0.6918   Test loss: 0.6935   Train acc: 0.6000   Val acc: 0.5347   Test acc: 0.5069\n",
      "Epoch: 1   Train loss: 0.6744   Val loss: 0.6867   Test loss: 0.6931   Train acc: 0.6200   Val acc: 0.5495   Test acc: 0.5208\n",
      "Epoch: 2   Train loss: 0.6521   Val loss: 0.6723   Test loss: 0.6822   Train acc: 0.6800   Val acc: 0.5693   Test acc: 0.5556\n",
      "Epoch: 3   Train loss: 0.6286   Val loss: 0.6530   Test loss: 0.6682   Train acc: 0.6800   Val acc: 0.5990   Test acc: 0.5625\n",
      "Epoch: 4   Train loss: 0.6763   Val loss: 0.6276   Test loss: 0.6406   Train acc: 0.5400   Val acc: 0.6386   Test acc: 0.6701\n",
      "Epoch: 5   Train loss: 0.5823   Val loss: 0.5999   Test loss: 0.6253   Train acc: 0.7400   Val acc: 0.6436   Test acc: 0.6146\n",
      "Epoch: 6   Train loss: 0.5821   Val loss: 0.5840   Test loss: 0.5950   Train acc: 0.7000   Val acc: 0.6634   Test acc: 0.6597\n",
      "Epoch: 7   Train loss: 0.5508   Val loss: 0.5615   Test loss: 0.5704   Train acc: 0.7600   Val acc: 0.6782   Test acc: 0.6875\n",
      "Epoch: 8   Train loss: 0.5803   Val loss: 0.5533   Test loss: 0.5537   Train acc: 0.6200   Val acc: 0.6832   Test acc: 0.7049\n",
      "Epoch: 9   Train loss: 0.4557   Val loss: 0.5536   Test loss: 0.5535   Train acc: 0.7400   Val acc: 0.7030   Test acc: 0.6944\n",
      "Epoch: 10   Train loss: 0.6423   Val loss: 0.5413   Test loss: 0.5344   Train acc: 0.6200   Val acc: 0.7129   Test acc: 0.7292\n",
      "Epoch: 11   Train loss: 0.6316   Val loss: 0.5400   Test loss: 0.5419   Train acc: 0.6000   Val acc: 0.7228   Test acc: 0.6736\n",
      "Epoch: 12   Train loss: 0.4841   Val loss: 0.5446   Test loss: 0.5075   Train acc: 0.7600   Val acc: 0.6881   Test acc: 0.7708\n",
      "Epoch: 13   Train loss: 0.5602   Val loss: 0.5300   Test loss: 0.5215   Train acc: 0.7000   Val acc: 0.7129   Test acc: 0.6979\n",
      "Epoch: 14   Train loss: 0.4197   Val loss: 0.5304   Test loss: 0.5085   Train acc: 0.7200   Val acc: 0.7178   Test acc: 0.7153\n",
      "Epoch: 15   Train loss: 0.5179   Val loss: 0.5310   Test loss: 0.5082   Train acc: 0.7400   Val acc: 0.7228   Test acc: 0.7257\n",
      "Epoch: 16   Train loss: 0.6169   Val loss: 0.5256   Test loss: 0.5034   Train acc: 0.6800   Val acc: 0.7129   Test acc: 0.7153\n",
      "Epoch: 17   Train loss: 0.5959   Val loss: 0.5450   Test loss: 0.5320   Train acc: 0.6400   Val acc: 0.7327   Test acc: 0.6597\n",
      "Epoch: 18   Train loss: 0.4445   Val loss: 0.5387   Test loss: 0.4915   Train acc: 0.8200   Val acc: 0.6980   Test acc: 0.7292\n",
      "Epoch: 19   Train loss: 0.4371   Val loss: 0.5294   Test loss: 0.4934   Train acc: 0.7800   Val acc: 0.7228   Test acc: 0.7188\n",
      "Epoch: 20   Train loss: 0.4244   Val loss: 0.5243   Test loss: 0.5002   Train acc: 0.7600   Val acc: 0.7178   Test acc: 0.7222\n",
      "Epoch: 21   Train loss: 0.5601   Val loss: 0.5453   Test loss: 0.4756   Train acc: 0.7600   Val acc: 0.7277   Test acc: 0.7431\n",
      "Epoch: 22   Train loss: 0.3495   Val loss: 0.5592   Test loss: 0.5532   Train acc: 0.8000   Val acc: 0.7129   Test acc: 0.6528\n",
      "Epoch: 23   Train loss: 0.4468   Val loss: 0.5334   Test loss: 0.5065   Train acc: 0.7200   Val acc: 0.7228   Test acc: 0.7222\n",
      "Epoch: 24   Train loss: 0.4601   Val loss: 0.5440   Test loss: 0.5065   Train acc: 0.7600   Val acc: 0.7228   Test acc: 0.7049\n",
      "The average accuracy is: 0.6743055555555556\n",
      "The best accuracy is: 0.7708333333333334\n",
      "THE BEST ACCURACY IS 0.7708333333333334\n",
      "subject 1 duration: 0:01:59.718649\n",
      "seed is 1402\n",
      "Subject 2\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.3833   Val loss: 0.5142   Test loss: 0.5795   Train acc: 0.8200   Val acc: 0.7426   Test acc: 0.7014\n",
      "Epoch: 1   Train loss: 0.2708   Val loss: 0.5131   Test loss: 0.5821   Train acc: 0.9000   Val acc: 0.7475   Test acc: 0.6979\n",
      "Epoch: 2   Train loss: 0.4180   Val loss: 0.5167   Test loss: 0.5775   Train acc: 0.7600   Val acc: 0.7475   Test acc: 0.7049\n",
      "Epoch: 3   Train loss: 0.3448   Val loss: 0.5103   Test loss: 0.5819   Train acc: 0.7800   Val acc: 0.7475   Test acc: 0.6979\n",
      "Epoch: 4   Train loss: 0.3913   Val loss: 0.5218   Test loss: 0.6198   Train acc: 0.8200   Val acc: 0.7525   Test acc: 0.6806\n",
      "Epoch: 5   Train loss: 0.4185   Val loss: 0.5189   Test loss: 0.6007   Train acc: 0.7800   Val acc: 0.7376   Test acc: 0.6840\n",
      "Epoch: 6   Train loss: 0.4770   Val loss: 0.5287   Test loss: 0.6388   Train acc: 0.8000   Val acc: 0.7475   Test acc: 0.6424\n",
      "Epoch: 7   Train loss: 0.4637   Val loss: 0.5242   Test loss: 0.6170   Train acc: 0.7800   Val acc: 0.7525   Test acc: 0.6667\n",
      "Epoch: 8   Train loss: 0.4539   Val loss: 0.5265   Test loss: 0.6110   Train acc: 0.7400   Val acc: 0.7475   Test acc: 0.6736\n",
      "Epoch: 9   Train loss: 0.3522   Val loss: 0.5291   Test loss: 0.6351   Train acc: 0.8600   Val acc: 0.7376   Test acc: 0.6667\n",
      "Epoch: 10   Train loss: 0.2835   Val loss: 0.5368   Test loss: 0.6410   Train acc: 0.9000   Val acc: 0.7376   Test acc: 0.6667\n",
      "Epoch: 11   Train loss: 0.4719   Val loss: 0.5303   Test loss: 0.6405   Train acc: 0.7400   Val acc: 0.7426   Test acc: 0.6597\n",
      "Epoch: 12   Train loss: 0.2799   Val loss: 0.5265   Test loss: 0.6539   Train acc: 0.8600   Val acc: 0.7475   Test acc: 0.6562\n",
      "Epoch: 13   Train loss: 0.3577   Val loss: 0.5526   Test loss: 0.6594   Train acc: 0.8600   Val acc: 0.7525   Test acc: 0.6493\n",
      "Epoch: 14   Train loss: 0.4356   Val loss: 0.5404   Test loss: 0.6773   Train acc: 0.7400   Val acc: 0.7426   Test acc: 0.6285\n",
      "Epoch: 15   Train loss: 0.2839   Val loss: 0.5422   Test loss: 0.6807   Train acc: 0.8400   Val acc: 0.7327   Test acc: 0.6528\n",
      "Epoch: 16   Train loss: 0.4318   Val loss: 0.5450   Test loss: 0.6698   Train acc: 0.8200   Val acc: 0.7228   Test acc: 0.6701\n",
      "Epoch: 17   Train loss: 0.3317   Val loss: 0.5460   Test loss: 0.6875   Train acc: 0.9000   Val acc: 0.7426   Test acc: 0.6424\n",
      "Epoch: 18   Train loss: 0.2570   Val loss: 0.5382   Test loss: 0.7028   Train acc: 0.9200   Val acc: 0.7525   Test acc: 0.6146\n",
      "Epoch: 19   Train loss: 0.2866   Val loss: 0.5541   Test loss: 0.6983   Train acc: 0.8600   Val acc: 0.7426   Test acc: 0.6424\n",
      "Epoch: 20   Train loss: 0.3550   Val loss: 0.5470   Test loss: 0.7009   Train acc: 0.8600   Val acc: 0.7475   Test acc: 0.6319\n",
      "Epoch: 21   Train loss: 0.2754   Val loss: 0.5808   Test loss: 0.7198   Train acc: 0.8800   Val acc: 0.7376   Test acc: 0.6389\n",
      "Epoch: 22   Train loss: 0.3662   Val loss: 0.5546   Test loss: 0.7086   Train acc: 0.8200   Val acc: 0.7525   Test acc: 0.6528\n",
      "Epoch: 23   Train loss: 0.3699   Val loss: 0.5453   Test loss: 0.7258   Train acc: 0.7800   Val acc: 0.7574   Test acc: 0.6111\n",
      "Epoch: 24   Train loss: 0.3414   Val loss: 0.5472   Test loss: 0.7292   Train acc: 0.8200   Val acc: 0.7624   Test acc: 0.6285\n",
      "The average accuracy is: 0.6584722222222222\n",
      "The best accuracy is: 0.7048611111111112\n",
      "THE BEST ACCURACY IS 0.7048611111111112\n",
      "subject 2 duration: 0:01:57.940293\n",
      "seed is 1815\n",
      "Subject 3\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.3425   Val loss: 0.6537   Test loss: 0.1350   Train acc: 0.8600   Val acc: 0.6683   Test acc: 0.9618\n",
      "Epoch: 1   Train loss: 0.3149   Val loss: 0.6412   Test loss: 0.1227   Train acc: 0.8600   Val acc: 0.6683   Test acc: 0.9618\n",
      "Epoch: 2   Train loss: 0.3700   Val loss: 0.6216   Test loss: 0.1242   Train acc: 0.8200   Val acc: 0.7030   Test acc: 0.9618\n",
      "Epoch: 3   Train loss: 0.3976   Val loss: 0.6327   Test loss: 0.1203   Train acc: 0.8000   Val acc: 0.6634   Test acc: 0.9583\n",
      "Epoch: 4   Train loss: 0.3341   Val loss: 0.6186   Test loss: 0.1152   Train acc: 0.9000   Val acc: 0.6881   Test acc: 0.9688\n",
      "Epoch: 5   Train loss: 0.4334   Val loss: 0.6365   Test loss: 0.1336   Train acc: 0.8400   Val acc: 0.6634   Test acc: 0.9583\n",
      "Epoch: 6   Train loss: 0.2470   Val loss: 0.6339   Test loss: 0.1226   Train acc: 0.9000   Val acc: 0.6584   Test acc: 0.9618\n",
      "Epoch: 7   Train loss: 0.4453   Val loss: 0.6491   Test loss: 0.1391   Train acc: 0.8000   Val acc: 0.7129   Test acc: 0.9549\n",
      "Epoch: 8   Train loss: 0.4587   Val loss: 0.6556   Test loss: 0.1287   Train acc: 0.8200   Val acc: 0.6683   Test acc: 0.9549\n",
      "Epoch: 9   Train loss: 0.3635   Val loss: 0.6625   Test loss: 0.1440   Train acc: 0.8000   Val acc: 0.6683   Test acc: 0.9410\n",
      "Epoch: 10   Train loss: 0.4314   Val loss: 0.6343   Test loss: 0.1366   Train acc: 0.7200   Val acc: 0.6634   Test acc: 0.9583\n",
      "Epoch: 11   Train loss: 0.5182   Val loss: 0.6582   Test loss: 0.1394   Train acc: 0.7200   Val acc: 0.6634   Test acc: 0.9549\n",
      "Epoch: 12   Train loss: 0.2904   Val loss: 0.6279   Test loss: 0.1265   Train acc: 0.8800   Val acc: 0.6832   Test acc: 0.9618\n",
      "Epoch: 13   Train loss: 0.3436   Val loss: 0.6271   Test loss: 0.1322   Train acc: 0.8400   Val acc: 0.7030   Test acc: 0.9618\n",
      "Epoch: 14   Train loss: 0.2689   Val loss: 0.6674   Test loss: 0.1595   Train acc: 0.9200   Val acc: 0.6980   Test acc: 0.9340\n",
      "Epoch: 15   Train loss: 0.2917   Val loss: 0.6425   Test loss: 0.1471   Train acc: 0.9200   Val acc: 0.6782   Test acc: 0.9583\n",
      "Epoch: 16   Train loss: 0.3369   Val loss: 0.6396   Test loss: 0.1409   Train acc: 0.8600   Val acc: 0.6832   Test acc: 0.9583\n",
      "Epoch: 17   Train loss: 0.3001   Val loss: 0.6369   Test loss: 0.1803   Train acc: 0.9000   Val acc: 0.7030   Test acc: 0.9167\n",
      "Epoch: 18   Train loss: 0.3748   Val loss: 0.6459   Test loss: 0.1645   Train acc: 0.8200   Val acc: 0.6931   Test acc: 0.9201\n",
      "Epoch: 19   Train loss: 0.2199   Val loss: 0.6378   Test loss: 0.1368   Train acc: 0.8800   Val acc: 0.6881   Test acc: 0.9549\n",
      "Epoch: 20   Train loss: 0.2678   Val loss: 0.6326   Test loss: 0.1443   Train acc: 0.8800   Val acc: 0.6881   Test acc: 0.9549\n",
      "Epoch: 21   Train loss: 0.3034   Val loss: 0.6403   Test loss: 0.1507   Train acc: 0.8600   Val acc: 0.6980   Test acc: 0.9444\n",
      "Epoch: 22   Train loss: 0.3550   Val loss: 0.6446   Test loss: 0.1531   Train acc: 0.8800   Val acc: 0.6782   Test acc: 0.9410\n",
      "Epoch: 23   Train loss: 0.3964   Val loss: 0.6765   Test loss: 0.1668   Train acc: 0.7600   Val acc: 0.6881   Test acc: 0.9201\n",
      "Epoch: 24   Train loss: 0.2400   Val loss: 0.6356   Test loss: 0.1580   Train acc: 0.9000   Val acc: 0.6782   Test acc: 0.9410\n",
      "The average accuracy is: 0.9505555555555554\n",
      "The best accuracy is: 0.96875\n",
      "THE BEST ACCURACY IS 0.96875\n",
      "subject 3 duration: 0:01:58.641697\n",
      "seed is 534\n",
      "Subject 4\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.4371   Val loss: 0.5269   Test loss: 0.3919   Train acc: 0.8400   Val acc: 0.7376   Test acc: 0.8403\n",
      "Epoch: 1   Train loss: 0.2386   Val loss: 0.5285   Test loss: 0.3992   Train acc: 0.8800   Val acc: 0.7525   Test acc: 0.8333\n",
      "Epoch: 2   Train loss: 0.3638   Val loss: 0.5280   Test loss: 0.4094   Train acc: 0.8400   Val acc: 0.7426   Test acc: 0.8368\n",
      "Epoch: 3   Train loss: 0.3581   Val loss: 0.5603   Test loss: 0.3977   Train acc: 0.8400   Val acc: 0.7426   Test acc: 0.8299\n",
      "Epoch: 4   Train loss: 0.1639   Val loss: 0.5407   Test loss: 0.4254   Train acc: 0.9600   Val acc: 0.7376   Test acc: 0.8299\n",
      "Epoch: 5   Train loss: 0.2981   Val loss: 0.5694   Test loss: 0.3966   Train acc: 0.9000   Val acc: 0.7525   Test acc: 0.8507\n",
      "Epoch: 6   Train loss: 0.1961   Val loss: 0.5692   Test loss: 0.4327   Train acc: 0.9600   Val acc: 0.7327   Test acc: 0.8194\n",
      "Epoch: 7   Train loss: 0.2064   Val loss: 0.5550   Test loss: 0.4705   Train acc: 0.9600   Val acc: 0.7376   Test acc: 0.7986\n",
      "Epoch: 8   Train loss: 0.1853   Val loss: 0.5424   Test loss: 0.4798   Train acc: 0.9000   Val acc: 0.7277   Test acc: 0.7951\n",
      "Epoch: 9   Train loss: 0.4455   Val loss: 0.5470   Test loss: 0.4299   Train acc: 0.8400   Val acc: 0.7277   Test acc: 0.8368\n",
      "Epoch: 10   Train loss: 0.1968   Val loss: 0.5822   Test loss: 0.6046   Train acc: 0.9400   Val acc: 0.7426   Test acc: 0.7569\n",
      "Epoch: 11   Train loss: 0.2183   Val loss: 0.5645   Test loss: 0.4361   Train acc: 0.9200   Val acc: 0.7327   Test acc: 0.8333\n",
      "Epoch: 12   Train loss: 0.2781   Val loss: 0.5622   Test loss: 0.4722   Train acc: 0.8800   Val acc: 0.7376   Test acc: 0.7986\n",
      "Epoch: 13   Train loss: 0.2486   Val loss: 0.5685   Test loss: 0.4564   Train acc: 0.8800   Val acc: 0.7376   Test acc: 0.8264\n",
      "Epoch: 14   Train loss: 0.2255   Val loss: 0.5498   Test loss: 0.5249   Train acc: 0.8800   Val acc: 0.7277   Test acc: 0.7708\n",
      "Epoch: 15   Train loss: 0.3515   Val loss: 0.5545   Test loss: 0.4540   Train acc: 0.8600   Val acc: 0.7327   Test acc: 0.8264\n",
      "Epoch: 16   Train loss: 0.2821   Val loss: 0.5686   Test loss: 0.4577   Train acc: 0.8400   Val acc: 0.7376   Test acc: 0.8125\n",
      "Epoch: 17   Train loss: 0.2790   Val loss: 0.5858   Test loss: 0.4875   Train acc: 0.8600   Val acc: 0.7327   Test acc: 0.8125\n",
      "Epoch: 18   Train loss: 0.1552   Val loss: 0.5984   Test loss: 0.4786   Train acc: 0.9600   Val acc: 0.7426   Test acc: 0.8021\n",
      "Epoch: 19   Train loss: 0.1140   Val loss: 0.5376   Test loss: 0.4870   Train acc: 0.9800   Val acc: 0.7673   Test acc: 0.8021\n",
      "Epoch: 20   Train loss: 0.3270   Val loss: 0.5776   Test loss: 0.4758   Train acc: 0.9200   Val acc: 0.7327   Test acc: 0.8125\n",
      "Epoch: 21   Train loss: 0.2389   Val loss: 0.5665   Test loss: 0.5439   Train acc: 0.9000   Val acc: 0.7475   Test acc: 0.7778\n",
      "Epoch: 22   Train loss: 0.1739   Val loss: 0.5797   Test loss: 0.5239   Train acc: 0.9400   Val acc: 0.7327   Test acc: 0.7882\n",
      "Epoch: 23   Train loss: 0.1822   Val loss: 0.5735   Test loss: 0.5401   Train acc: 0.9400   Val acc: 0.7327   Test acc: 0.7986\n",
      "Epoch: 24   Train loss: 0.2932   Val loss: 0.6217   Test loss: 0.4926   Train acc: 0.8800   Val acc: 0.7426   Test acc: 0.8056\n",
      "The average accuracy is: 0.8118055555555557\n",
      "The best accuracy is: 0.8506944444444444\n",
      "THE BEST ACCURACY IS 0.8506944444444444\n",
      "subject 4 duration: 0:01:58.030304\n",
      "seed is 1597\n",
      "Subject 5\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2109   Val loss: 0.5385   Test loss: 0.3598   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.8333\n",
      "Epoch: 1   Train loss: 0.3956   Val loss: 0.5369   Test loss: 0.3863   Train acc: 0.8400   Val acc: 0.7871   Test acc: 0.8160\n",
      "Epoch: 2   Train loss: 0.2069   Val loss: 0.5222   Test loss: 0.3656   Train acc: 0.9000   Val acc: 0.7871   Test acc: 0.8333\n",
      "Epoch: 3   Train loss: 0.2420   Val loss: 0.5583   Test loss: 0.4043   Train acc: 0.9200   Val acc: 0.7921   Test acc: 0.8194\n",
      "Epoch: 4   Train loss: 0.2517   Val loss: 0.5283   Test loss: 0.4046   Train acc: 0.8800   Val acc: 0.7970   Test acc: 0.8090\n",
      "Epoch: 5   Train loss: 0.1251   Val loss: 0.5538   Test loss: 0.3967   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.8299\n",
      "Epoch: 6   Train loss: 0.1860   Val loss: 0.5531   Test loss: 0.4462   Train acc: 0.9200   Val acc: 0.7970   Test acc: 0.7951\n",
      "Epoch: 7   Train loss: 0.1537   Val loss: 0.5361   Test loss: 0.4311   Train acc: 0.9400   Val acc: 0.8069   Test acc: 0.7882\n",
      "Epoch: 8   Train loss: 0.2235   Val loss: 0.5364   Test loss: 0.4141   Train acc: 0.9200   Val acc: 0.8020   Test acc: 0.8160\n",
      "Epoch: 9   Train loss: 0.2211   Val loss: 0.5252   Test loss: 0.4668   Train acc: 0.8800   Val acc: 0.8168   Test acc: 0.7812\n",
      "Epoch: 10   Train loss: 0.2022   Val loss: 0.5214   Test loss: 0.4645   Train acc: 0.8800   Val acc: 0.7970   Test acc: 0.7882\n",
      "Epoch: 11   Train loss: 0.1969   Val loss: 0.5531   Test loss: 0.4265   Train acc: 0.9200   Val acc: 0.8020   Test acc: 0.8125\n",
      "Epoch: 12   Train loss: 0.2643   Val loss: 0.5526   Test loss: 0.4583   Train acc: 0.9000   Val acc: 0.8020   Test acc: 0.7917\n",
      "Epoch: 13   Train loss: 0.2821   Val loss: 0.5745   Test loss: 0.4651   Train acc: 0.8600   Val acc: 0.7871   Test acc: 0.7847\n",
      "Epoch: 14   Train loss: 0.2234   Val loss: 0.5786   Test loss: 0.4292   Train acc: 0.8400   Val acc: 0.7772   Test acc: 0.8021\n",
      "Epoch: 15   Train loss: 0.1053   Val loss: 0.6271   Test loss: 0.4492   Train acc: 1.0000   Val acc: 0.7822   Test acc: 0.8125\n",
      "Epoch: 16   Train loss: 0.2392   Val loss: 0.5643   Test loss: 0.5384   Train acc: 0.8600   Val acc: 0.8020   Test acc: 0.7604\n",
      "Epoch: 17   Train loss: 0.1276   Val loss: 0.5706   Test loss: 0.4739   Train acc: 0.9400   Val acc: 0.8119   Test acc: 0.7951\n",
      "Epoch: 18   Train loss: 0.1801   Val loss: 0.5271   Test loss: 0.4462   Train acc: 0.9200   Val acc: 0.8119   Test acc: 0.7847\n",
      "Epoch: 19   Train loss: 0.2305   Val loss: 0.5536   Test loss: 0.4854   Train acc: 0.8600   Val acc: 0.8168   Test acc: 0.7674\n",
      "Epoch: 20   Train loss: 0.2235   Val loss: 0.5429   Test loss: 0.4973   Train acc: 0.9000   Val acc: 0.8119   Test acc: 0.7743\n",
      "Epoch: 21   Train loss: 0.1313   Val loss: 0.5729   Test loss: 0.4777   Train acc: 0.9400   Val acc: 0.8020   Test acc: 0.7812\n",
      "Epoch: 22   Train loss: 0.1025   Val loss: 0.5742   Test loss: 0.5299   Train acc: 0.9600   Val acc: 0.7970   Test acc: 0.7743\n",
      "Epoch: 23   Train loss: 0.1093   Val loss: 0.5855   Test loss: 0.5170   Train acc: 0.9800   Val acc: 0.7921   Test acc: 0.7708\n",
      "Epoch: 24   Train loss: 0.1796   Val loss: 0.5475   Test loss: 0.5104   Train acc: 0.9400   Val acc: 0.8119   Test acc: 0.7847\n",
      "The average accuracy is: 0.79625\n",
      "The best accuracy is: 0.8333333333333334\n",
      "THE BEST ACCURACY IS 0.8333333333333334\n",
      "subject 5 duration: 0:01:57.632241\n",
      "seed is 554\n",
      "Subject 6\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.3116   Val loss: 0.5175   Test loss: 0.1764   Train acc: 0.8400   Val acc: 0.8119   Test acc: 0.9514\n",
      "Epoch: 1   Train loss: 0.1872   Val loss: 0.4402   Test loss: 0.1745   Train acc: 0.9000   Val acc: 0.8218   Test acc: 0.9514\n",
      "Epoch: 2   Train loss: 0.1173   Val loss: 0.4575   Test loss: 0.1949   Train acc: 0.9800   Val acc: 0.8267   Test acc: 0.9479\n",
      "Epoch: 3   Train loss: 0.1809   Val loss: 0.4885   Test loss: 0.2137   Train acc: 0.9200   Val acc: 0.8119   Test acc: 0.9479\n",
      "Epoch: 4   Train loss: 0.1906   Val loss: 0.4945   Test loss: 0.2060   Train acc: 0.9000   Val acc: 0.8218   Test acc: 0.9340\n",
      "Epoch: 5   Train loss: 0.1780   Val loss: 0.4579   Test loss: 0.2030   Train acc: 0.9000   Val acc: 0.8416   Test acc: 0.9375\n",
      "Epoch: 6   Train loss: 0.1199   Val loss: 0.4512   Test loss: 0.2031   Train acc: 0.9600   Val acc: 0.8168   Test acc: 0.9514\n",
      "Epoch: 7   Train loss: 0.2355   Val loss: 0.4670   Test loss: 0.2102   Train acc: 0.9200   Val acc: 0.8317   Test acc: 0.9479\n",
      "Epoch: 8   Train loss: 0.0895   Val loss: 0.5219   Test loss: 0.2212   Train acc: 0.9800   Val acc: 0.8317   Test acc: 0.9375\n",
      "Epoch: 9   Train loss: 0.2200   Val loss: 0.5242   Test loss: 0.2131   Train acc: 0.8800   Val acc: 0.8267   Test acc: 0.9410\n",
      "Epoch: 10   Train loss: 0.2004   Val loss: 0.4699   Test loss: 0.2456   Train acc: 0.9200   Val acc: 0.8218   Test acc: 0.9236\n",
      "Epoch: 11   Train loss: 0.2575   Val loss: 0.4931   Test loss: 0.2378   Train acc: 0.8600   Val acc: 0.8218   Test acc: 0.9306\n",
      "Epoch: 12   Train loss: 0.1274   Val loss: 0.5266   Test loss: 0.2536   Train acc: 0.9600   Val acc: 0.8218   Test acc: 0.9271\n",
      "Epoch: 13   Train loss: 0.2288   Val loss: 0.4755   Test loss: 0.2479   Train acc: 0.9200   Val acc: 0.8366   Test acc: 0.9236\n",
      "Epoch: 14   Train loss: 0.1192   Val loss: 0.4983   Test loss: 0.2571   Train acc: 0.9400   Val acc: 0.8218   Test acc: 0.9201\n",
      "Epoch: 15   Train loss: 0.1841   Val loss: 0.5204   Test loss: 0.3020   Train acc: 0.9000   Val acc: 0.8218   Test acc: 0.8958\n",
      "Epoch: 16   Train loss: 0.3004   Val loss: 0.4901   Test loss: 0.3239   Train acc: 0.8600   Val acc: 0.8267   Test acc: 0.8854\n",
      "Epoch: 17   Train loss: 0.0962   Val loss: 0.4603   Test loss: 0.3537   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.8924\n",
      "Epoch: 18   Train loss: 0.2610   Val loss: 0.4583   Test loss: 0.3069   Train acc: 0.8800   Val acc: 0.8465   Test acc: 0.8993\n",
      "Epoch: 19   Train loss: 0.2332   Val loss: 0.4837   Test loss: 0.3085   Train acc: 0.9400   Val acc: 0.8317   Test acc: 0.8924\n",
      "Epoch: 20   Train loss: 0.1002   Val loss: 0.4606   Test loss: 0.4056   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.8854\n",
      "Epoch: 21   Train loss: 0.1626   Val loss: 0.4150   Test loss: 0.4057   Train acc: 0.9600   Val acc: 0.8515   Test acc: 0.8785\n",
      "Epoch: 22   Train loss: 0.2670   Val loss: 0.4804   Test loss: 0.3783   Train acc: 0.8600   Val acc: 0.8218   Test acc: 0.8785\n",
      "Epoch: 23   Train loss: 0.1663   Val loss: 0.4765   Test loss: 0.4101   Train acc: 0.9200   Val acc: 0.8416   Test acc: 0.8750\n",
      "Epoch: 24   Train loss: 0.1455   Val loss: 0.4959   Test loss: 0.3698   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.8889\n",
      "The average accuracy is: 0.9177777777777777\n",
      "The best accuracy is: 0.9513888888888888\n",
      "THE BEST ACCURACY IS 0.9513888888888888\n",
      "subject 6 duration: 0:01:57.566994\n",
      "seed is 1157\n",
      "Subject 7\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2081   Val loss: 0.4390   Test loss: 0.1477   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9618\n",
      "Epoch: 1   Train loss: 0.2860   Val loss: 0.4244   Test loss: 0.1416   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9583\n",
      "Epoch: 2   Train loss: 0.1287   Val loss: 0.4473   Test loss: 0.1802   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9410\n",
      "Epoch: 3   Train loss: 0.0699   Val loss: 0.4552   Test loss: 0.1534   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9479\n",
      "Epoch: 4   Train loss: 0.1181   Val loss: 0.4247   Test loss: 0.1521   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9444\n",
      "Epoch: 5   Train loss: 0.0864   Val loss: 0.4265   Test loss: 0.1561   Train acc: 0.9600   Val acc: 0.8465   Test acc: 0.9375\n",
      "Epoch: 6   Train loss: 0.1718   Val loss: 0.4142   Test loss: 0.1584   Train acc: 0.9200   Val acc: 0.8515   Test acc: 0.9410\n",
      "Epoch: 7   Train loss: 0.1185   Val loss: 0.4018   Test loss: 0.1885   Train acc: 0.9600   Val acc: 0.8515   Test acc: 0.9340\n",
      "Epoch: 8   Train loss: 0.3591   Val loss: 0.4602   Test loss: 0.1895   Train acc: 0.8600   Val acc: 0.8366   Test acc: 0.9271\n",
      "Epoch: 9   Train loss: 0.1587   Val loss: 0.4087   Test loss: 0.2280   Train acc: 0.9400   Val acc: 0.8465   Test acc: 0.9028\n",
      "Epoch: 10   Train loss: 0.1436   Val loss: 0.4455   Test loss: 0.2310   Train acc: 0.9000   Val acc: 0.8317   Test acc: 0.9028\n",
      "Epoch: 11   Train loss: 0.3749   Val loss: 0.4148   Test loss: 0.1877   Train acc: 0.8600   Val acc: 0.8515   Test acc: 0.9340\n",
      "Epoch: 12   Train loss: 0.1992   Val loss: 0.4652   Test loss: 0.2361   Train acc: 0.9200   Val acc: 0.8465   Test acc: 0.9097\n",
      "Epoch: 13   Train loss: 0.0872   Val loss: 0.4839   Test loss: 0.2049   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9236\n",
      "Epoch: 14   Train loss: 0.0879   Val loss: 0.4380   Test loss: 0.2278   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9097\n",
      "Epoch: 15   Train loss: 0.0825   Val loss: 0.4603   Test loss: 0.2397   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9062\n",
      "Epoch: 16   Train loss: 0.0922   Val loss: 0.4637   Test loss: 0.2186   Train acc: 0.9600   Val acc: 0.8515   Test acc: 0.9375\n",
      "Epoch: 17   Train loss: 0.1267   Val loss: 0.4276   Test loss: 0.2069   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9236\n",
      "Epoch: 18   Train loss: 0.1146   Val loss: 0.4557   Test loss: 0.1938   Train acc: 0.9400   Val acc: 0.8465   Test acc: 0.9201\n",
      "Epoch: 19   Train loss: 0.1966   Val loss: 0.4232   Test loss: 0.2246   Train acc: 0.9600   Val acc: 0.8564   Test acc: 0.9201\n",
      "Epoch: 20   Train loss: 0.1854   Val loss: 0.4911   Test loss: 0.2153   Train acc: 0.9400   Val acc: 0.8218   Test acc: 0.9028\n",
      "Epoch: 21   Train loss: 0.2027   Val loss: 0.4551   Test loss: 0.2244   Train acc: 0.9200   Val acc: 0.8515   Test acc: 0.9167\n",
      "Epoch: 22   Train loss: 0.1464   Val loss: 0.4584   Test loss: 0.2134   Train acc: 0.9200   Val acc: 0.8366   Test acc: 0.9132\n",
      "Epoch: 23   Train loss: 0.1883   Val loss: 0.4525   Test loss: 0.2297   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9097\n",
      "Epoch: 24   Train loss: 0.0925   Val loss: 0.4432   Test loss: 0.2258   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9028\n",
      "The average accuracy is: 0.925138888888889\n",
      "The best accuracy is: 0.9618055555555556\n",
      "THE BEST ACCURACY IS 0.9618055555555556\n",
      "subject 7 duration: 0:01:57.507545\n",
      "seed is 361\n",
      "Subject 8\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1434   Val loss: 0.3756   Test loss: 0.0262   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9896\n",
      "Epoch: 1   Train loss: 0.1217   Val loss: 0.4056   Test loss: 0.0228   Train acc: 0.9800   Val acc: 0.8762   Test acc: 0.9896\n",
      "Epoch: 2   Train loss: 0.1331   Val loss: 0.3819   Test loss: 0.0228   Train acc: 0.9400   Val acc: 0.8713   Test acc: 0.9931\n",
      "Epoch: 3   Train loss: 0.1782   Val loss: 0.3896   Test loss: 0.0526   Train acc: 0.8800   Val acc: 0.8515   Test acc: 0.9861\n",
      "Epoch: 4   Train loss: 0.1941   Val loss: 0.3741   Test loss: 0.0338   Train acc: 0.9200   Val acc: 0.8614   Test acc: 0.9896\n",
      "Epoch: 5   Train loss: 0.1108   Val loss: 0.4012   Test loss: 0.0323   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9896\n",
      "Epoch: 6   Train loss: 0.2203   Val loss: 0.3852   Test loss: 0.0341   Train acc: 0.9000   Val acc: 0.8663   Test acc: 0.9931\n",
      "Epoch: 7   Train loss: 0.1415   Val loss: 0.4158   Test loss: 0.0404   Train acc: 0.9600   Val acc: 0.8614   Test acc: 0.9896\n",
      "Epoch: 8   Train loss: 0.1460   Val loss: 0.4008   Test loss: 0.0468   Train acc: 0.9200   Val acc: 0.8614   Test acc: 0.9896\n",
      "Epoch: 9   Train loss: 0.1203   Val loss: 0.3995   Test loss: 0.0376   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9931\n",
      "Epoch: 10   Train loss: 0.1253   Val loss: 0.3876   Test loss: 0.0313   Train acc: 0.9600   Val acc: 0.8614   Test acc: 0.9931\n",
      "Epoch: 11   Train loss: 0.2504   Val loss: 0.3925   Test loss: 0.0227   Train acc: 0.9000   Val acc: 0.8564   Test acc: 0.9931\n",
      "Epoch: 12   Train loss: 0.0653   Val loss: 0.4252   Test loss: 0.0290   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9931\n",
      "Epoch: 13   Train loss: 0.1611   Val loss: 0.4062   Test loss: 0.0300   Train acc: 0.9400   Val acc: 0.8713   Test acc: 0.9931\n",
      "Epoch: 14   Train loss: 0.0838   Val loss: 0.3989   Test loss: 0.0413   Train acc: 1.0000   Val acc: 0.8614   Test acc: 0.9931\n",
      "Epoch: 15   Train loss: 0.2033   Val loss: 0.3970   Test loss: 0.0456   Train acc: 0.8800   Val acc: 0.8564   Test acc: 0.9896\n",
      "Epoch: 16   Train loss: 0.1835   Val loss: 0.4013   Test loss: 0.0398   Train acc: 0.9200   Val acc: 0.8564   Test acc: 0.9931\n",
      "Epoch: 17   Train loss: 0.0957   Val loss: 0.4239   Test loss: 0.0161   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9931\n",
      "Epoch: 18   Train loss: 0.1528   Val loss: 0.4068   Test loss: 0.0342   Train acc: 0.9400   Val acc: 0.8713   Test acc: 0.9931\n",
      "Epoch: 19   Train loss: 0.2850   Val loss: 0.4170   Test loss: 0.0584   Train acc: 0.9200   Val acc: 0.8416   Test acc: 0.9861\n",
      "Epoch: 20   Train loss: 0.1427   Val loss: 0.3948   Test loss: 0.0226   Train acc: 0.9400   Val acc: 0.8614   Test acc: 0.9896\n",
      "Epoch: 21   Train loss: 0.1477   Val loss: 0.4013   Test loss: 0.0199   Train acc: 0.9600   Val acc: 0.8713   Test acc: 0.9931\n",
      "Epoch: 22   Train loss: 0.1573   Val loss: 0.4030   Test loss: 0.0259   Train acc: 0.9200   Val acc: 0.8663   Test acc: 0.9896\n",
      "Epoch: 23   Train loss: 0.2542   Val loss: 0.4092   Test loss: 0.0263   Train acc: 0.9000   Val acc: 0.8515   Test acc: 0.9931\n",
      "Epoch: 24   Train loss: 0.1198   Val loss: 0.3933   Test loss: 0.0338   Train acc: 0.9200   Val acc: 0.8614   Test acc: 0.9896\n",
      "The average accuracy is: 0.9911111111111112\n",
      "The best accuracy is: 0.9930555555555556\n",
      "THE BEST ACCURACY IS 0.9930555555555556\n",
      "subject 8 duration: 0:01:57.547476\n",
      "seed is 999\n",
      "Subject 9\n",
      "Number of parameters:  193795\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0574   Val loss: 0.1668   Test loss: 1.1542   Train acc: 1.0000   Val acc: 0.9524   Test acc: 0.7569\n",
      "Epoch: 1   Train loss: 0.1597   Val loss: 0.1822   Test loss: 1.1237   Train acc: 0.9474   Val acc: 0.9524   Test acc: 0.7500\n",
      "Epoch: 2   Train loss: 0.0855   Val loss: 0.1663   Test loss: 1.1212   Train acc: 0.9825   Val acc: 0.9524   Test acc: 0.7361\n",
      "Epoch: 3   Train loss: 0.1285   Val loss: 0.1728   Test loss: 1.1176   Train acc: 0.9474   Val acc: 0.9481   Test acc: 0.7604\n",
      "Epoch: 4   Train loss: 0.1578   Val loss: 0.1738   Test loss: 1.1173   Train acc: 0.9474   Val acc: 0.9437   Test acc: 0.7465\n",
      "Epoch: 5   Train loss: 0.0608   Val loss: 0.1706   Test loss: 1.1372   Train acc: 0.9649   Val acc: 0.9481   Test acc: 0.7396\n",
      "Epoch: 6   Train loss: 0.1749   Val loss: 0.1648   Test loss: 1.1263   Train acc: 0.9474   Val acc: 0.9481   Test acc: 0.7535\n",
      "Epoch: 7   Train loss: 0.1966   Val loss: 0.1737   Test loss: 1.1172   Train acc: 0.9123   Val acc: 0.9437   Test acc: 0.7639\n",
      "Epoch: 8   Train loss: 0.1823   Val loss: 0.1659   Test loss: 1.0995   Train acc: 0.9123   Val acc: 0.9481   Test acc: 0.7708\n",
      "Epoch: 9   Train loss: 0.0912   Val loss: 0.1703   Test loss: 1.2753   Train acc: 0.9474   Val acc: 0.9524   Test acc: 0.7396\n",
      "Epoch: 10   Train loss: 0.1917   Val loss: 0.1878   Test loss: 1.2572   Train acc: 0.9474   Val acc: 0.9394   Test acc: 0.7257\n",
      "Epoch: 11   Train loss: 0.0957   Val loss: 0.1689   Test loss: 1.1672   Train acc: 0.9649   Val acc: 0.9524   Test acc: 0.7500\n",
      "Epoch: 12   Train loss: 0.1245   Val loss: 0.1723   Test loss: 1.2527   Train acc: 0.9298   Val acc: 0.9524   Test acc: 0.7465\n",
      "Epoch: 13   Train loss: 0.1694   Val loss: 0.1759   Test loss: 1.1424   Train acc: 0.9474   Val acc: 0.9437   Test acc: 0.7396\n",
      "Epoch: 14   Train loss: 0.1279   Val loss: 0.1718   Test loss: 1.1872   Train acc: 0.9474   Val acc: 0.9437   Test acc: 0.7500\n",
      "Epoch: 15   Train loss: 0.0956   Val loss: 0.1930   Test loss: 1.2801   Train acc: 0.9649   Val acc: 0.9394   Test acc: 0.7361\n",
      "Epoch: 16   Train loss: 0.1216   Val loss: 0.1722   Test loss: 1.1843   Train acc: 0.9474   Val acc: 0.9481   Test acc: 0.7535\n",
      "Epoch: 17   Train loss: 0.2190   Val loss: 0.1710   Test loss: 1.3053   Train acc: 0.9474   Val acc: 0.9394   Test acc: 0.7257\n",
      "Epoch: 18   Train loss: 0.1661   Val loss: 0.1889   Test loss: 1.2473   Train acc: 0.9123   Val acc: 0.9351   Test acc: 0.7500\n",
      "Epoch: 19   Train loss: 0.1394   Val loss: 0.1869   Test loss: 1.3020   Train acc: 0.9474   Val acc: 0.9351   Test acc: 0.7257\n",
      "Epoch: 20   Train loss: 0.0718   Val loss: 0.2070   Test loss: 1.3287   Train acc: 0.9649   Val acc: 0.9307   Test acc: 0.7118\n",
      "Epoch: 21   Train loss: 0.0714   Val loss: 0.1874   Test loss: 1.2610   Train acc: 0.9649   Val acc: 0.9394   Test acc: 0.7257\n",
      "Epoch: 22   Train loss: 0.1128   Val loss: 0.1790   Test loss: 1.2603   Train acc: 0.9298   Val acc: 0.9351   Test acc: 0.7361\n",
      "Epoch: 23   Train loss: 0.0864   Val loss: 0.1960   Test loss: 1.3585   Train acc: 0.9825   Val acc: 0.9264   Test acc: 0.7326\n",
      "Epoch: 24   Train loss: 0.1924   Val loss: 0.1950   Test loss: 1.3350   Train acc: 0.9474   Val acc: 0.9307   Test acc: 0.7257\n",
      "The average accuracy is: 0.7420833333333333\n",
      "The best accuracy is: 0.7708333333333334\n",
      "THE BEST ACCURACY IS 0.7708333333333334\n",
      "subject 9 duration: 0:03:19.249636\n",
      "Mean of best is 0.8672839506172838\n",
      "Mean of average is 0.8297222222222224\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
