{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.cct import CCT\n",
    "from torchinfo import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCT(kernel_sizes=[(22, 1), (1, 24), (1, 24)], stride=(1, 1), padding=(0, 0),\n",
    "            pooling_kernel_size=(3, 3), pooling_stride=(1, 1), pooling_padding=(0, 0),\n",
    "            n_conv_layers=3, n_input_channels=1,\n",
    "            in_planes=64, activation=None, # ReLU\n",
    "            max_pool=False, conv_bias=False,\n",
    "            dim=64, num_layers=3,\n",
    "            num_heads=4, num_classes=2, \n",
    "            attn_dropout=0.1, dropout=0.1, \n",
    "            mlp_size=64, positional_emb=\"learnable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "CCT (CCT)                                          [64, 1, 22, 321]     [64, 2]              --                   True\n",
       "├─Tokenizer (tokenizer)                            [64, 1, 22, 321]     [64, 275, 64]        --                   True\n",
       "│    └─Sequential (conv_layers)                    [64, 1, 22, 321]     [64, 64, 1, 275]     --                   True\n",
       "│    │    └─Sequential (0)                         [64, 1, 22, 321]     [64, 64, 1, 321]     1,408                True\n",
       "│    │    └─Sequential (1)                         [64, 64, 1, 321]     [64, 64, 1, 298]     98,304               True\n",
       "│    │    └─Sequential (2)                         [64, 64, 1, 298]     [64, 64, 1, 275]     98,304               True\n",
       "│    └─Flatten (flattener)                         [64, 64, 1, 275]     [64, 64, 275]        --                   --\n",
       "├─Transformer (transformer)                        [64, 275, 64]        [64, 2]              17,600               True\n",
       "│    └─Dropout (dropout)                           [64, 275, 64]        [64, 275, 64]        --                   --\n",
       "│    └─ModuleList (blocks)                         --                   --                   --                   True\n",
       "│    │    └─EncoderLayer (0)                       [64, 275, 64]        [64, 275, 64]        24,896               True\n",
       "│    │    └─EncoderLayer (1)                       [64, 275, 64]        [64, 275, 64]        24,896               True\n",
       "│    │    └─EncoderLayer (2)                       [64, 275, 64]        [64, 275, 64]        24,896               True\n",
       "│    └─LayerNorm (norm)                            [64, 275, 64]        [64, 275, 64]        128                  True\n",
       "│    └─Linear (attention_pool)                     [64, 275, 64]        [64, 275, 1]         65                   True\n",
       "│    └─Linear (fc)                                 [64, 64]             [64, 2]              130                  True\n",
       "==================================================================================================================================\n",
       "Total params: 290,627\n",
       "Trainable params: 290,627\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.64\n",
       "==================================================================================================================================\n",
       "Input size (MB): 1.81\n",
       "Forward/backward pass size (MB): 227.68\n",
       "Params size (MB): 1.09\n",
       "Estimated Total Size (MB): 230.58\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(64, 1, 22, 321),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['datasets/aBNCI2014001R.pickle', 'datasets/aBNCI2014004R.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "data = load_data(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 321)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = ['left_hand', 'right_hand']\n",
    "subject = 0\n",
    "s1 = data[subject]\n",
    "s1.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU device name : NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dev.type == 'cuda':\n",
    "    print('Your GPU device name :', torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCCT():\n",
    "    def __init__(self, nsub, n_subj=9):\n",
    "        super(ExP, self).__init__()\n",
    "        self.batch_size = 36\n",
    "        self.n_epochs = 25  #2000\n",
    "        self.c_dim = 4\n",
    "        self.lr = 3e-5\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.dimension = (190, 50)\n",
    "        self.nSub = nsub\n",
    "        self.n_subjects = 8 # total?\n",
    "        self.start_epoch = 0\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "        self.FloatTensor = torch.cuda.FloatTensor\n",
    "\n",
    "        self.criterion_l1 = torch.nn.L1Loss().cuda()\n",
    "        self.criterion_l2 = torch.nn.MSELoss().cuda()\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = model.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to(\"cuda\")\n",
    "            \n",
    "        self.total_params = sum(param.numel() for param in self.model.parameters())\n",
    "        print(\"Number of parameters: \", self.total_params)\n",
    "\n",
    "        #self.model = self.model.cuda()\n",
    "        # summary(self.model, (1, 22, 1000))\n",
    "\n",
    "\n",
    "    # Segmentation and Reconstruction (S&R) data augmentation\n",
    "    def interaug(self, timg, label):  \n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "        for cls4aug in range(2):\n",
    "            cls_idx = np.where(label == cls4aug + 1)\n",
    "            tmp_data = timg[cls_idx]\n",
    "            tmp_label = label[cls_idx]\n",
    "\n",
    "            tmp_aug_data = np.zeros((int(self.batch_size / 2), 1, 22, 321))\n",
    "            for ri in range(int(self.batch_size / 2)):\n",
    "                for rj in range(3):\n",
    "                    rand_idx = np.random.randint(0, tmp_data.shape[0], 3)\n",
    "                    tmp_aug_data[ri, :, :, rj * 107:(rj + 1) * 107] = tmp_data[rand_idx[rj], :, :,\n",
    "                                                                      rj * 107:(rj + 1) * 107]\n",
    "\n",
    "            aug_data.append(tmp_aug_data)\n",
    "            aug_label.append(tmp_label[:int(self.batch_size / 2)])\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        aug_data = aug_data[aug_shuffle, :, :]\n",
    "        aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        aug_data = torch.from_numpy(aug_data).cuda()\n",
    "        aug_data = aug_data.float()\n",
    "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
    "        aug_label = aug_label.long()\n",
    "        return aug_data, aug_label\n",
    "\n",
    "    def get_source_data(self):\n",
    "        \n",
    "        self.test_subject = self.nSub\n",
    "\n",
    "        # Get the data from the epochs object\n",
    "        self.data = load_data(datasets[0])\n",
    "        print('Dataset: ', datasets[0])\n",
    "\n",
    "        self.train_subjects = [i for i in range(self.n_subjects) if i != self.test_subject]\n",
    "\n",
    "        # Prepare test data\n",
    "        self.X_test = self.data[self.test_subject].get_data()\n",
    "        self.y_test = self.data[self.test_subject].events[:, -1]\n",
    "\n",
    "        # Prepare training data\n",
    "        self.X_train = np.concatenate([self.data[i].get_data() for i in self.train_subjects], axis=0)\n",
    "        self.y_train = np.concatenate([self.data[i].events[:, -1] for i in self.train_subjects], axis=0)\n",
    "\n",
    "        # train and val data\n",
    "        self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(self.X_train, self.y_train, test_size=0.1, random_state=42)\n",
    "        \n",
    "        self.allData = np.expand_dims(self.train_data, axis=1)\n",
    "        self.allLabel = self.train_label\n",
    "        \n",
    "        self.valData = np.expand_dims(self.val_data, axis=1)\n",
    "        self.valLabel = self.val_label\n",
    "\n",
    "        shuffle_num = np.random.permutation(len(self.allData))\n",
    "        self.allData = self.allData[shuffle_num, :, :, :]\n",
    "        self.allLabel = self.allLabel[shuffle_num]\n",
    "\n",
    "        # test data  \n",
    "        self.testData = np.expand_dims(self.X_test, axis=1)\n",
    "        self.testLabel = self.y_test\n",
    "        \n",
    "        # standardize\n",
    "        target_mean = np.mean(self.allData)\n",
    "        target_std = np.std(self.allData)\n",
    "        self.allData = (self.allData - target_mean) / target_std\n",
    "        self.testData = (self.testData - target_mean) / target_std\n",
    "        self.valData = (self.valData - target_mean) / target_std\n",
    "\n",
    "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
    "        return self.allData, self.allLabel, self.valData, self.valLabel, self.testData, self.testLabel\n",
    "\n",
    "    def train(self):\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        #img, label, test_data, test_label = self.get_source_data()\n",
    "        img, label, val_data, val_label, test_data, test_label = self.get_source_data()\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label - 1)\n",
    "        dataset = torch.utils.data.TensorDataset(img, label)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        val_data = torch.from_numpy(val_data)\n",
    "        val_label = torch.from_numpy(val_label - 1)\n",
    "        val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label - 1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(test_label.type(self.LongTensor))\n",
    "        \n",
    "        val_data = Variable(val_data.type(self.Tensor))\n",
    "        val_label = Variable(val_label.type(self.LongTensor))\n",
    "        \n",
    "        bestAcc = 0\n",
    "        averAcc = 0\n",
    "        num = 0\n",
    "        Y_true = 0\n",
    "        Y_pred = 0\n",
    "\n",
    "        # Train the cnn model\n",
    "        total_step = len(self.dataloader)\n",
    "        curr_lr = self.lr\n",
    "\n",
    "        for e in range(self.n_epochs):\n",
    "            # in_epoch = time.time()\n",
    "            self.model.train()\n",
    "            for i, (img, label) in enumerate(self.dataloader):\n",
    "\n",
    "                img = Variable(img.cuda().type(self.Tensor))\n",
    "                label = Variable(label.cuda().type(self.LongTensor)) #FloatTensor\n",
    "\n",
    "                # data augmentation\n",
    "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "                img = torch.cat((img, aug_data))\n",
    "                label = torch.cat((label, aug_label))\n",
    "\n",
    "                outputs = self.model(img)\n",
    "\n",
    "                loss = self.criterion_cls(outputs, label) \n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # test process\n",
    "            if (e + 1) % 1 == 0:\n",
    "                self.model.eval()\n",
    "                Cls = self.model(test_data)\n",
    "                probs = softmax(Cls, dim=1).cpu().detach().numpy()\n",
    "                loss_test = self.criterion_cls(Cls, test_label)\n",
    "                y_pred = torch.max(Cls, 1)[1]\n",
    "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
    "\n",
    "                #self.model.eval()\n",
    "                ValCls = self.model(val_data)\n",
    "                loss_val = self.criterion_cls(ValCls, val_label)\n",
    "                val_pred = torch.max(ValCls, 1)[1]\n",
    "                val_acc = float((val_pred == val_label).cpu().numpy().astype(int).sum()) / float(val_label.size(0))\n",
    "                \n",
    "                train_pred = torch.max(outputs, 1)[1]\n",
    "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
    "                \n",
    "                print('Epoch:', e,\n",
    "                      '  Train loss: %.4f' % loss.detach().cpu().numpy(),\n",
    "                      '  Val loss: %.4f' % loss_val.detach().cpu().numpy(),\n",
    "                      '  Test loss: %.4f' % loss_test.detach().cpu().numpy(),\n",
    "                      '  Train acc: %.4f' % train_acc,\n",
    "                      '  Val acc: %.4f' % val_acc,\n",
    "                      '  Test acc: %.4f' % acc)\n",
    "\n",
    "                num = num + 1\n",
    "                averAcc = averAcc + acc\n",
    "                if acc > bestAcc:\n",
    "                    bestAcc = acc\n",
    "                    Y_true = test_label\n",
    "                    Y_pred = y_pred\n",
    "            \n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            train_losses.append(loss.detach().cpu().numpy())\n",
    "            val_losses.append(loss_val.detach().cpu().numpy())\n",
    "\n",
    "        #torch.save(self.model.module.state_dict(), 'model.pth')\n",
    "        averAcc = averAcc / num\n",
    "        print('The average accuracy is:', averAcc)\n",
    "        print('The best accuracy is:', bestAcc)\n",
    "        \n",
    "        return bestAcc, averAcc, Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    best = 0\n",
    "    aver = 0\n",
    "\n",
    "    for i in range(9):\n",
    "        starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "        seed_n = np.random.randint(2021)\n",
    "        print('seed is ' + str(seed_n))\n",
    "        random.seed(seed_n)\n",
    "        np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "\n",
    "        print('Subject %d' % (i+1))\n",
    "        exp = EEGCCT(i)\n",
    "\n",
    "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
    "        print('THE BEST ACCURACY IS ' + str(bestAcc))\n",
    "\n",
    "        endtime = datetime.datetime.now()\n",
    "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
    "        best = best + bestAcc\n",
    "        aver = aver + averAcc\n",
    "        if i == 0:\n",
    "            yt = Y_true\n",
    "            yp = Y_pred\n",
    "        else:\n",
    "            yt = torch.cat((yt, Y_true))\n",
    "            yp = torch.cat((yp, Y_pred))\n",
    "\n",
    "\n",
    "    best = best / 9\n",
    "    aver = aver / 9\n",
    "    \n",
    "    print(f\"Mean of best is {best}\")\n",
    "    print(f\"Mean of average is {aver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 1136\n",
      "Subject 1\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.6863   Val loss: 0.6850   Test loss: 0.6868   Train acc: 0.6000   Val acc: 0.5198   Test acc: 0.5382\n",
      "Epoch: 1   Train loss: 0.6318   Val loss: 0.6358   Test loss: 0.6390   Train acc: 0.7400   Val acc: 0.6584   Test acc: 0.6597\n",
      "Epoch: 2   Train loss: 0.5974   Val loss: 0.5799   Test loss: 0.5494   Train acc: 0.6600   Val acc: 0.6931   Test acc: 0.7118\n",
      "Epoch: 3   Train loss: 0.4945   Val loss: 0.5556   Test loss: 0.5290   Train acc: 0.7800   Val acc: 0.6931   Test acc: 0.6840\n",
      "Epoch: 4   Train loss: 0.4559   Val loss: 0.5494   Test loss: 0.4858   Train acc: 0.8600   Val acc: 0.7327   Test acc: 0.7465\n",
      "Epoch: 5   Train loss: 0.5249   Val loss: 0.5515   Test loss: 0.4798   Train acc: 0.7000   Val acc: 0.7228   Test acc: 0.7465\n",
      "Epoch: 6   Train loss: 0.4858   Val loss: 0.5513   Test loss: 0.4601   Train acc: 0.7400   Val acc: 0.7228   Test acc: 0.7569\n",
      "Epoch: 7   Train loss: 0.4063   Val loss: 0.5322   Test loss: 0.4443   Train acc: 0.8600   Val acc: 0.7525   Test acc: 0.7569\n",
      "Epoch: 8   Train loss: 0.4242   Val loss: 0.5613   Test loss: 0.4381   Train acc: 0.8000   Val acc: 0.7327   Test acc: 0.7639\n",
      "Epoch: 9   Train loss: 0.4374   Val loss: 0.5753   Test loss: 0.4318   Train acc: 0.7600   Val acc: 0.7030   Test acc: 0.7917\n",
      "Epoch: 10   Train loss: 0.5027   Val loss: 0.5340   Test loss: 0.4179   Train acc: 0.7000   Val acc: 0.7327   Test acc: 0.7986\n",
      "Epoch: 11   Train loss: 0.3283   Val loss: 0.5592   Test loss: 0.4195   Train acc: 0.9200   Val acc: 0.6931   Test acc: 0.7917\n",
      "Epoch: 12   Train loss: 0.4248   Val loss: 0.5461   Test loss: 0.4126   Train acc: 0.7800   Val acc: 0.7129   Test acc: 0.7882\n",
      "Epoch: 13   Train loss: 0.3737   Val loss: 0.5664   Test loss: 0.4064   Train acc: 0.8400   Val acc: 0.7178   Test acc: 0.7986\n",
      "Epoch: 14   Train loss: 0.3527   Val loss: 0.5522   Test loss: 0.4231   Train acc: 0.9200   Val acc: 0.7277   Test acc: 0.7882\n",
      "Epoch: 15   Train loss: 0.5433   Val loss: 0.5325   Test loss: 0.3952   Train acc: 0.6600   Val acc: 0.7178   Test acc: 0.7986\n",
      "Epoch: 16   Train loss: 0.4065   Val loss: 0.5810   Test loss: 0.4010   Train acc: 0.7600   Val acc: 0.6980   Test acc: 0.7847\n",
      "Epoch: 17   Train loss: 0.3656   Val loss: 0.6122   Test loss: 0.4158   Train acc: 0.7800   Val acc: 0.6980   Test acc: 0.8090\n",
      "Epoch: 18   Train loss: 0.4589   Val loss: 0.5832   Test loss: 0.4088   Train acc: 0.8000   Val acc: 0.6980   Test acc: 0.7951\n",
      "Epoch: 19   Train loss: 0.2588   Val loss: 0.5913   Test loss: 0.4061   Train acc: 0.9400   Val acc: 0.7178   Test acc: 0.7951\n",
      "Epoch: 20   Train loss: 0.3867   Val loss: 0.6024   Test loss: 0.4066   Train acc: 0.8200   Val acc: 0.7079   Test acc: 0.8160\n",
      "Epoch: 21   Train loss: 0.3472   Val loss: 0.5999   Test loss: 0.3973   Train acc: 0.8400   Val acc: 0.6980   Test acc: 0.8125\n",
      "Epoch: 22   Train loss: 0.3834   Val loss: 0.5717   Test loss: 0.3710   Train acc: 0.8000   Val acc: 0.7327   Test acc: 0.8160\n",
      "Epoch: 23   Train loss: 0.1843   Val loss: 0.6145   Test loss: 0.3975   Train acc: 0.9200   Val acc: 0.7079   Test acc: 0.8021\n",
      "Epoch: 24   Train loss: 0.3302   Val loss: 0.5948   Test loss: 0.3988   Train acc: 0.8600   Val acc: 0.7525   Test acc: 0.8125\n",
      "The average accuracy is: 0.7665277777777777\n",
      "The best accuracy is: 0.8159722222222222\n",
      "THE BEST ACCURACY IS 0.8159722222222222\n",
      "subject 1 duration: 0:01:39.688620\n",
      "seed is 1234\n",
      "Subject 2\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2028   Val loss: 0.5198   Test loss: 0.3586   Train acc: 0.9200   Val acc: 0.7574   Test acc: 0.8576\n",
      "Epoch: 1   Train loss: 0.2017   Val loss: 0.5247   Test loss: 0.4509   Train acc: 0.9200   Val acc: 0.7574   Test acc: 0.8090\n",
      "Epoch: 2   Train loss: 0.2459   Val loss: 0.5457   Test loss: 0.4532   Train acc: 0.9000   Val acc: 0.7376   Test acc: 0.7882\n",
      "Epoch: 3   Train loss: 0.1566   Val loss: 0.5663   Test loss: 0.4905   Train acc: 0.9600   Val acc: 0.7574   Test acc: 0.7708\n",
      "Epoch: 4   Train loss: 0.2871   Val loss: 0.5328   Test loss: 0.4830   Train acc: 0.9000   Val acc: 0.7772   Test acc: 0.7604\n",
      "Epoch: 5   Train loss: 0.2384   Val loss: 0.6090   Test loss: 0.6050   Train acc: 0.8800   Val acc: 0.7475   Test acc: 0.7361\n",
      "Epoch: 6   Train loss: 0.2847   Val loss: 0.5379   Test loss: 0.5361   Train acc: 0.9000   Val acc: 0.7723   Test acc: 0.7569\n",
      "Epoch: 7   Train loss: 0.2217   Val loss: 0.5744   Test loss: 0.6228   Train acc: 0.8800   Val acc: 0.7772   Test acc: 0.7396\n",
      "Epoch: 8   Train loss: 0.2123   Val loss: 0.5358   Test loss: 0.5491   Train acc: 0.9200   Val acc: 0.7871   Test acc: 0.7292\n",
      "Epoch: 9   Train loss: 0.2982   Val loss: 0.5893   Test loss: 0.6388   Train acc: 0.8600   Val acc: 0.7723   Test acc: 0.7083\n",
      "Epoch: 10   Train loss: 0.2461   Val loss: 0.5189   Test loss: 0.6376   Train acc: 0.9200   Val acc: 0.7970   Test acc: 0.7326\n",
      "Epoch: 11   Train loss: 0.3218   Val loss: 0.5695   Test loss: 0.6567   Train acc: 0.8400   Val acc: 0.7624   Test acc: 0.7257\n",
      "Epoch: 12   Train loss: 0.2579   Val loss: 0.5915   Test loss: 0.7158   Train acc: 0.8800   Val acc: 0.7822   Test acc: 0.7049\n",
      "Epoch: 13   Train loss: 0.2393   Val loss: 0.5691   Test loss: 0.6834   Train acc: 0.9000   Val acc: 0.8020   Test acc: 0.7188\n",
      "Epoch: 14   Train loss: 0.0919   Val loss: 0.5419   Test loss: 0.6470   Train acc: 0.9600   Val acc: 0.7772   Test acc: 0.7222\n",
      "Epoch: 15   Train loss: 0.1814   Val loss: 0.5902   Test loss: 0.6905   Train acc: 0.9400   Val acc: 0.7871   Test acc: 0.7118\n",
      "Epoch: 16   Train loss: 0.0980   Val loss: 0.5595   Test loss: 0.6529   Train acc: 0.9800   Val acc: 0.7921   Test acc: 0.7257\n",
      "Epoch: 17   Train loss: 0.2509   Val loss: 0.5113   Test loss: 0.6502   Train acc: 0.8800   Val acc: 0.8267   Test acc: 0.7188\n",
      "Epoch: 18   Train loss: 0.1227   Val loss: 0.5635   Test loss: 0.7823   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.7014\n",
      "Epoch: 19   Train loss: 0.2142   Val loss: 0.5097   Test loss: 0.8128   Train acc: 0.9000   Val acc: 0.8218   Test acc: 0.6771\n",
      "Epoch: 20   Train loss: 0.0776   Val loss: 0.6232   Test loss: 0.8040   Train acc: 0.9800   Val acc: 0.7921   Test acc: 0.6806\n",
      "Epoch: 21   Train loss: 0.0556   Val loss: 0.5900   Test loss: 0.7654   Train acc: 1.0000   Val acc: 0.8020   Test acc: 0.6910\n",
      "Epoch: 22   Train loss: 0.2875   Val loss: 0.5770   Test loss: 0.7575   Train acc: 0.8800   Val acc: 0.8069   Test acc: 0.7118\n",
      "Epoch: 23   Train loss: 0.1236   Val loss: 0.5308   Test loss: 0.7555   Train acc: 0.9600   Val acc: 0.8069   Test acc: 0.6979\n",
      "Epoch: 24   Train loss: 0.0962   Val loss: 0.5708   Test loss: 0.8029   Train acc: 0.9600   Val acc: 0.7871   Test acc: 0.6667\n",
      "The average accuracy is: 0.7297222222222223\n",
      "The best accuracy is: 0.8576388888888888\n",
      "THE BEST ACCURACY IS 0.8576388888888888\n",
      "subject 2 duration: 0:01:39.281138\n",
      "seed is 661\n",
      "Subject 3\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1498   Val loss: 0.6781   Test loss: 0.0363   Train acc: 0.9600   Val acc: 0.7327   Test acc: 0.9965\n",
      "Epoch: 1   Train loss: 0.2497   Val loss: 0.6475   Test loss: 0.0302   Train acc: 0.9000   Val acc: 0.7624   Test acc: 0.9965\n",
      "Epoch: 2   Train loss: 0.2286   Val loss: 0.6775   Test loss: 0.0445   Train acc: 0.8800   Val acc: 0.7624   Test acc: 0.9896\n",
      "Epoch: 3   Train loss: 0.2429   Val loss: 0.6501   Test loss: 0.0584   Train acc: 0.8800   Val acc: 0.7624   Test acc: 0.9792\n",
      "Epoch: 4   Train loss: 0.1889   Val loss: 0.7039   Test loss: 0.0458   Train acc: 0.9200   Val acc: 0.7426   Test acc: 0.9826\n",
      "Epoch: 5   Train loss: 0.1895   Val loss: 0.6692   Test loss: 0.0517   Train acc: 0.9400   Val acc: 0.7723   Test acc: 0.9826\n",
      "Epoch: 6   Train loss: 0.4435   Val loss: 0.6555   Test loss: 0.0472   Train acc: 0.8000   Val acc: 0.7673   Test acc: 0.9861\n",
      "Epoch: 7   Train loss: 0.1410   Val loss: 0.7063   Test loss: 0.0549   Train acc: 0.9200   Val acc: 0.7475   Test acc: 0.9861\n",
      "Epoch: 8   Train loss: 0.1507   Val loss: 0.7006   Test loss: 0.0506   Train acc: 0.9600   Val acc: 0.7574   Test acc: 0.9792\n",
      "Epoch: 9   Train loss: 0.1472   Val loss: 0.7223   Test loss: 0.0543   Train acc: 0.9400   Val acc: 0.7624   Test acc: 0.9861\n",
      "Epoch: 10   Train loss: 0.2142   Val loss: 0.7420   Test loss: 0.0607   Train acc: 0.8800   Val acc: 0.7475   Test acc: 0.9722\n",
      "Epoch: 11   Train loss: 0.2651   Val loss: 0.7792   Test loss: 0.0671   Train acc: 0.9200   Val acc: 0.7228   Test acc: 0.9722\n",
      "Epoch: 12   Train loss: 0.2737   Val loss: 0.7055   Test loss: 0.0560   Train acc: 0.9200   Val acc: 0.7624   Test acc: 0.9826\n",
      "Epoch: 13   Train loss: 0.1055   Val loss: 0.7097   Test loss: 0.0571   Train acc: 0.9400   Val acc: 0.7871   Test acc: 0.9792\n",
      "Epoch: 14   Train loss: 0.3367   Val loss: 0.7998   Test loss: 0.0820   Train acc: 0.9000   Val acc: 0.7475   Test acc: 0.9653\n",
      "Epoch: 15   Train loss: 0.2974   Val loss: 0.7299   Test loss: 0.0770   Train acc: 0.8600   Val acc: 0.7822   Test acc: 0.9688\n",
      "Epoch: 16   Train loss: 0.1462   Val loss: 0.7002   Test loss: 0.0500   Train acc: 0.9600   Val acc: 0.7624   Test acc: 0.9826\n",
      "Epoch: 17   Train loss: 0.1899   Val loss: 0.7929   Test loss: 0.0548   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.9792\n",
      "Epoch: 18   Train loss: 0.1917   Val loss: 0.7563   Test loss: 0.0557   Train acc: 0.9200   Val acc: 0.7574   Test acc: 0.9826\n",
      "Epoch: 19   Train loss: 0.1899   Val loss: 0.8089   Test loss: 0.0806   Train acc: 0.9400   Val acc: 0.7525   Test acc: 0.9549\n",
      "Epoch: 20   Train loss: 0.1695   Val loss: 0.7540   Test loss: 0.0477   Train acc: 0.9200   Val acc: 0.7772   Test acc: 0.9861\n",
      "Epoch: 21   Train loss: 0.2236   Val loss: 0.7748   Test loss: 0.0808   Train acc: 0.9400   Val acc: 0.7525   Test acc: 0.9757\n",
      "Epoch: 22   Train loss: 0.1959   Val loss: 0.8278   Test loss: 0.0961   Train acc: 0.9600   Val acc: 0.7673   Test acc: 0.9583\n",
      "Epoch: 23   Train loss: 0.1259   Val loss: 0.7667   Test loss: 0.0615   Train acc: 0.9600   Val acc: 0.7673   Test acc: 0.9792\n",
      "Epoch: 24   Train loss: 0.1738   Val loss: 0.7869   Test loss: 0.0696   Train acc: 0.9000   Val acc: 0.7624   Test acc: 0.9757\n",
      "The average accuracy is: 0.9791666666666664\n",
      "The best accuracy is: 0.9965277777777778\n",
      "THE BEST ACCURACY IS 0.9965277777777778\n",
      "subject 3 duration: 0:01:36.892593\n",
      "seed is 1597\n",
      "Subject 4\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1737   Val loss: 0.7364   Test loss: 0.1171   Train acc: 0.9200   Val acc: 0.7822   Test acc: 0.9722\n",
      "Epoch: 1   Train loss: 0.1533   Val loss: 0.7674   Test loss: 0.1381   Train acc: 0.9400   Val acc: 0.7772   Test acc: 0.9514\n",
      "Epoch: 2   Train loss: 0.0631   Val loss: 0.6647   Test loss: 0.0948   Train acc: 0.9600   Val acc: 0.7921   Test acc: 0.9757\n",
      "Epoch: 3   Train loss: 0.1685   Val loss: 0.6932   Test loss: 0.1205   Train acc: 0.9200   Val acc: 0.8119   Test acc: 0.9653\n",
      "Epoch: 4   Train loss: 0.0687   Val loss: 0.6896   Test loss: 0.1221   Train acc: 0.9800   Val acc: 0.7921   Test acc: 0.9583\n",
      "Epoch: 5   Train loss: 0.0941   Val loss: 0.6622   Test loss: 0.1018   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9688\n",
      "Epoch: 6   Train loss: 0.1276   Val loss: 0.7374   Test loss: 0.2016   Train acc: 0.9200   Val acc: 0.8069   Test acc: 0.9236\n",
      "Epoch: 7   Train loss: 0.0654   Val loss: 0.6652   Test loss: 0.1205   Train acc: 0.9600   Val acc: 0.7921   Test acc: 0.9653\n",
      "Epoch: 8   Train loss: 0.2084   Val loss: 0.6797   Test loss: 0.1169   Train acc: 0.9600   Val acc: 0.8020   Test acc: 0.9688\n",
      "Epoch: 9   Train loss: 0.1847   Val loss: 0.6557   Test loss: 0.1836   Train acc: 0.9200   Val acc: 0.7921   Test acc: 0.9236\n",
      "Epoch: 10   Train loss: 0.0772   Val loss: 0.6864   Test loss: 0.2770   Train acc: 0.9400   Val acc: 0.7871   Test acc: 0.8924\n",
      "Epoch: 11   Train loss: 0.1100   Val loss: 0.6757   Test loss: 0.2111   Train acc: 0.9400   Val acc: 0.8119   Test acc: 0.9271\n",
      "Epoch: 12   Train loss: 0.1902   Val loss: 0.5747   Test loss: 0.1411   Train acc: 0.9400   Val acc: 0.8416   Test acc: 0.9653\n",
      "Epoch: 13   Train loss: 0.1737   Val loss: 0.6056   Test loss: 0.1492   Train acc: 0.9200   Val acc: 0.8317   Test acc: 0.9410\n",
      "Epoch: 14   Train loss: 0.0551   Val loss: 0.6178   Test loss: 0.1515   Train acc: 0.9800   Val acc: 0.8267   Test acc: 0.9479\n",
      "Epoch: 15   Train loss: 0.1617   Val loss: 0.6915   Test loss: 0.1234   Train acc: 0.9200   Val acc: 0.8168   Test acc: 0.9618\n",
      "Epoch: 16   Train loss: 0.2317   Val loss: 0.6871   Test loss: 0.1879   Train acc: 0.8800   Val acc: 0.8119   Test acc: 0.9271\n",
      "Epoch: 17   Train loss: 0.0703   Val loss: 0.7183   Test loss: 0.2426   Train acc: 0.9600   Val acc: 0.8119   Test acc: 0.9132\n",
      "Epoch: 18   Train loss: 0.0673   Val loss: 0.7301   Test loss: 0.3212   Train acc: 0.9800   Val acc: 0.7723   Test acc: 0.8854\n",
      "Epoch: 19   Train loss: 0.1119   Val loss: 0.7043   Test loss: 0.2865   Train acc: 0.9600   Val acc: 0.7970   Test acc: 0.8854\n",
      "Epoch: 20   Train loss: 0.0650   Val loss: 0.8020   Test loss: 0.4204   Train acc: 0.9800   Val acc: 0.7871   Test acc: 0.8542\n",
      "Epoch: 21   Train loss: 0.0566   Val loss: 0.7116   Test loss: 0.2645   Train acc: 0.9600   Val acc: 0.7871   Test acc: 0.8993\n",
      "Epoch: 22   Train loss: 0.1503   Val loss: 0.7193   Test loss: 0.2299   Train acc: 0.9800   Val acc: 0.7921   Test acc: 0.9271\n",
      "Epoch: 23   Train loss: 0.1773   Val loss: 0.7220   Test loss: 0.3671   Train acc: 0.9000   Val acc: 0.7822   Test acc: 0.8854\n",
      "Epoch: 24   Train loss: 0.1833   Val loss: 0.6889   Test loss: 0.1972   Train acc: 0.9200   Val acc: 0.8168   Test acc: 0.9236\n",
      "The average accuracy is: 0.9323611111111112\n",
      "The best accuracy is: 0.9756944444444444\n",
      "THE BEST ACCURACY IS 0.9756944444444444\n",
      "subject 4 duration: 0:01:37.451079\n",
      "seed is 674\n",
      "Subject 5\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1392   Val loss: 0.5197   Test loss: 0.1608   Train acc: 0.9600   Val acc: 0.8614   Test acc: 0.9583\n",
      "Epoch: 1   Train loss: 0.0429   Val loss: 0.5358   Test loss: 0.1871   Train acc: 1.0000   Val acc: 0.8564   Test acc: 0.9444\n",
      "Epoch: 2   Train loss: 0.0588   Val loss: 0.5323   Test loss: 0.1769   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9583\n",
      "Epoch: 3   Train loss: 0.1512   Val loss: 0.5693   Test loss: 0.2457   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9201\n",
      "Epoch: 4   Train loss: 0.1124   Val loss: 0.5297   Test loss: 0.1785   Train acc: 0.9400   Val acc: 0.8762   Test acc: 0.9549\n",
      "Epoch: 5   Train loss: 0.0969   Val loss: 0.4870   Test loss: 0.1482   Train acc: 0.9600   Val acc: 0.8663   Test acc: 0.9618\n",
      "Epoch: 6   Train loss: 0.0472   Val loss: 0.5689   Test loss: 0.1681   Train acc: 1.0000   Val acc: 0.8564   Test acc: 0.9583\n",
      "Epoch: 7   Train loss: 0.0332   Val loss: 0.5247   Test loss: 0.2006   Train acc: 1.0000   Val acc: 0.8564   Test acc: 0.9410\n",
      "Epoch: 8   Train loss: 0.0631   Val loss: 0.5819   Test loss: 0.1820   Train acc: 0.9600   Val acc: 0.8564   Test acc: 0.9479\n",
      "Epoch: 9   Train loss: 0.1448   Val loss: 0.6021   Test loss: 0.1740   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9618\n",
      "Epoch: 10   Train loss: 0.1157   Val loss: 0.5572   Test loss: 0.1931   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9514\n",
      "Epoch: 11   Train loss: 0.1005   Val loss: 0.5788   Test loss: 0.1940   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9444\n",
      "Epoch: 12   Train loss: 0.0655   Val loss: 0.5633   Test loss: 0.2375   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9340\n",
      "Epoch: 13   Train loss: 0.0841   Val loss: 0.5962   Test loss: 0.2114   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9410\n",
      "Epoch: 14   Train loss: 0.1656   Val loss: 0.6214   Test loss: 0.1682   Train acc: 0.9400   Val acc: 0.8416   Test acc: 0.9583\n",
      "Epoch: 15   Train loss: 0.0466   Val loss: 0.6182   Test loss: 0.2443   Train acc: 1.0000   Val acc: 0.8416   Test acc: 0.9306\n",
      "Epoch: 16   Train loss: 0.0495   Val loss: 0.5863   Test loss: 0.1791   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9514\n",
      "Epoch: 17   Train loss: 0.2496   Val loss: 0.5651   Test loss: 0.2596   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9271\n",
      "Epoch: 18   Train loss: 0.2304   Val loss: 0.5037   Test loss: 0.2134   Train acc: 0.8800   Val acc: 0.8663   Test acc: 0.9479\n",
      "Epoch: 19   Train loss: 0.1068   Val loss: 0.5249   Test loss: 0.2133   Train acc: 0.9600   Val acc: 0.8564   Test acc: 0.9306\n",
      "Epoch: 20   Train loss: 0.0905   Val loss: 0.5583   Test loss: 0.2256   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9062\n",
      "Epoch: 21   Train loss: 0.1156   Val loss: 0.5295   Test loss: 0.2606   Train acc: 0.9600   Val acc: 0.8564   Test acc: 0.9132\n",
      "Epoch: 22   Train loss: 0.0204   Val loss: 0.5529   Test loss: 0.2485   Train acc: 1.0000   Val acc: 0.8614   Test acc: 0.9167\n",
      "Epoch: 23   Train loss: 0.0696   Val loss: 0.6004   Test loss: 0.2273   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9410\n",
      "Epoch: 24   Train loss: 0.0651   Val loss: 0.5233   Test loss: 0.2144   Train acc: 0.9600   Val acc: 0.8713   Test acc: 0.9444\n",
      "The average accuracy is: 0.9418055555555555\n",
      "The best accuracy is: 0.9618055555555556\n",
      "THE BEST ACCURACY IS 0.9618055555555556\n",
      "subject 5 duration: 0:01:38.089366\n",
      "seed is 239\n",
      "Subject 6\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0861   Val loss: 0.4587   Test loss: 0.1526   Train acc: 0.9600   Val acc: 0.8663   Test acc: 0.9653\n",
      "Epoch: 1   Train loss: 0.0778   Val loss: 0.3613   Test loss: 0.1586   Train acc: 0.9800   Val acc: 0.9010   Test acc: 0.9618\n",
      "Epoch: 2   Train loss: 0.0720   Val loss: 0.3892   Test loss: 0.1613   Train acc: 0.9800   Val acc: 0.8812   Test acc: 0.9653\n",
      "Epoch: 3   Train loss: 0.1753   Val loss: 0.3556   Test loss: 0.1682   Train acc: 0.9000   Val acc: 0.8911   Test acc: 0.9653\n",
      "Epoch: 4   Train loss: 0.0855   Val loss: 0.4553   Test loss: 0.1825   Train acc: 0.9600   Val acc: 0.8812   Test acc: 0.9549\n",
      "Epoch: 5   Train loss: 0.0952   Val loss: 0.3868   Test loss: 0.1661   Train acc: 0.9800   Val acc: 0.8713   Test acc: 0.9549\n",
      "Epoch: 6   Train loss: 0.0780   Val loss: 0.3482   Test loss: 0.1639   Train acc: 0.9600   Val acc: 0.9109   Test acc: 0.9653\n",
      "Epoch: 7   Train loss: 0.0455   Val loss: 0.3672   Test loss: 0.1723   Train acc: 0.9800   Val acc: 0.9059   Test acc: 0.9618\n",
      "Epoch: 8   Train loss: 0.0579   Val loss: 0.3840   Test loss: 0.1800   Train acc: 0.9600   Val acc: 0.8911   Test acc: 0.9618\n",
      "Epoch: 9   Train loss: 0.1306   Val loss: 0.3578   Test loss: 0.1773   Train acc: 0.9800   Val acc: 0.9257   Test acc: 0.9618\n",
      "Epoch: 10   Train loss: 0.0393   Val loss: 0.3866   Test loss: 0.1826   Train acc: 0.9800   Val acc: 0.9010   Test acc: 0.9618\n",
      "Epoch: 11   Train loss: 0.0299   Val loss: 0.3737   Test loss: 0.1944   Train acc: 1.0000   Val acc: 0.9010   Test acc: 0.9549\n",
      "Epoch: 12   Train loss: 0.0580   Val loss: 0.4547   Test loss: 0.2021   Train acc: 0.9600   Val acc: 0.8465   Test acc: 0.9410\n",
      "Epoch: 13   Train loss: 0.1873   Val loss: 0.4550   Test loss: 0.2370   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9271\n",
      "Epoch: 14   Train loss: 0.1480   Val loss: 0.3885   Test loss: 0.1950   Train acc: 0.9600   Val acc: 0.8911   Test acc: 0.9410\n",
      "Epoch: 15   Train loss: 0.1743   Val loss: 0.5305   Test loss: 0.2149   Train acc: 0.9400   Val acc: 0.8465   Test acc: 0.9444\n",
      "Epoch: 16   Train loss: 0.0861   Val loss: 0.4402   Test loss: 0.2093   Train acc: 0.9600   Val acc: 0.8911   Test acc: 0.9444\n",
      "Epoch: 17   Train loss: 0.0387   Val loss: 0.4421   Test loss: 0.2137   Train acc: 0.9800   Val acc: 0.8762   Test acc: 0.9549\n",
      "Epoch: 18   Train loss: 0.0968   Val loss: 0.4433   Test loss: 0.2600   Train acc: 0.9400   Val acc: 0.8663   Test acc: 0.9236\n",
      "Epoch: 19   Train loss: 0.0784   Val loss: 0.4021   Test loss: 0.1941   Train acc: 0.9800   Val acc: 0.8960   Test acc: 0.9444\n",
      "Epoch: 20   Train loss: 0.0118   Val loss: 0.4519   Test loss: 0.1955   Train acc: 1.0000   Val acc: 0.8762   Test acc: 0.9479\n",
      "Epoch: 21   Train loss: 0.0328   Val loss: 0.5460   Test loss: 0.2412   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9201\n",
      "Epoch: 22   Train loss: 0.1907   Val loss: 0.4205   Test loss: 0.2300   Train acc: 0.9400   Val acc: 0.8861   Test acc: 0.9271\n",
      "Epoch: 23   Train loss: 0.0359   Val loss: 0.4521   Test loss: 0.2183   Train acc: 0.9800   Val acc: 0.8713   Test acc: 0.9340\n",
      "Epoch: 24   Train loss: 0.0116   Val loss: 0.4298   Test loss: 0.2797   Train acc: 1.0000   Val acc: 0.8911   Test acc: 0.9236\n",
      "The average accuracy is: 0.9483333333333331\n",
      "The best accuracy is: 0.9652777777777778\n",
      "THE BEST ACCURACY IS 0.9652777777777778\n",
      "subject 6 duration: 0:01:43.024349\n",
      "seed is 860\n",
      "Subject 7\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0572   Val loss: 0.3341   Test loss: 0.0789   Train acc: 0.9800   Val acc: 0.9010   Test acc: 0.9757\n",
      "Epoch: 1   Train loss: 0.0152   Val loss: 0.2740   Test loss: 0.0932   Train acc: 1.0000   Val acc: 0.9455   Test acc: 0.9792\n",
      "Epoch: 2   Train loss: 0.0516   Val loss: 0.3356   Test loss: 0.0846   Train acc: 1.0000   Val acc: 0.9059   Test acc: 0.9826\n",
      "Epoch: 3   Train loss: 0.0954   Val loss: 0.3588   Test loss: 0.0610   Train acc: 0.9800   Val acc: 0.8911   Test acc: 0.9861\n",
      "Epoch: 4   Train loss: 0.3257   Val loss: 0.3657   Test loss: 0.0802   Train acc: 0.9400   Val acc: 0.9059   Test acc: 0.9757\n",
      "Epoch: 5   Train loss: 0.0127   Val loss: 0.3522   Test loss: 0.0694   Train acc: 1.0000   Val acc: 0.9010   Test acc: 0.9826\n",
      "Epoch: 6   Train loss: 0.0139   Val loss: 0.3147   Test loss: 0.0664   Train acc: 1.0000   Val acc: 0.9109   Test acc: 0.9861\n",
      "Epoch: 7   Train loss: 0.0816   Val loss: 0.3302   Test loss: 0.0704   Train acc: 0.9400   Val acc: 0.9158   Test acc: 0.9826\n",
      "Epoch: 8   Train loss: 0.0343   Val loss: 0.3469   Test loss: 0.0722   Train acc: 1.0000   Val acc: 0.9059   Test acc: 0.9792\n",
      "Epoch: 9   Train loss: 0.0262   Val loss: 0.3491   Test loss: 0.0628   Train acc: 1.0000   Val acc: 0.9010   Test acc: 0.9826\n",
      "Epoch: 10   Train loss: 0.0214   Val loss: 0.3614   Test loss: 0.0750   Train acc: 1.0000   Val acc: 0.8861   Test acc: 0.9792\n",
      "Epoch: 11   Train loss: 0.0230   Val loss: 0.3931   Test loss: 0.0890   Train acc: 0.9800   Val acc: 0.8960   Test acc: 0.9792\n",
      "Epoch: 12   Train loss: 0.0342   Val loss: 0.3701   Test loss: 0.0817   Train acc: 1.0000   Val acc: 0.9109   Test acc: 0.9792\n",
      "Epoch: 13   Train loss: 0.0266   Val loss: 0.3159   Test loss: 0.0929   Train acc: 1.0000   Val acc: 0.9208   Test acc: 0.9757\n",
      "Epoch: 14   Train loss: 0.0256   Val loss: 0.3350   Test loss: 0.0910   Train acc: 1.0000   Val acc: 0.9158   Test acc: 0.9826\n",
      "Epoch: 15   Train loss: 0.1263   Val loss: 0.3877   Test loss: 0.1345   Train acc: 0.9400   Val acc: 0.8762   Test acc: 0.9653\n",
      "Epoch: 16   Train loss: 0.0848   Val loss: 0.3661   Test loss: 0.1241   Train acc: 0.9800   Val acc: 0.8812   Test acc: 0.9583\n",
      "Epoch: 17   Train loss: 0.0841   Val loss: 0.3906   Test loss: 0.1229   Train acc: 0.9600   Val acc: 0.8960   Test acc: 0.9722\n",
      "Epoch: 18   Train loss: 0.0998   Val loss: 0.3640   Test loss: 0.1024   Train acc: 0.9400   Val acc: 0.9109   Test acc: 0.9722\n",
      "Epoch: 19   Train loss: 0.0327   Val loss: 0.3543   Test loss: 0.1047   Train acc: 0.9800   Val acc: 0.9059   Test acc: 0.9688\n",
      "Epoch: 20   Train loss: 0.0789   Val loss: 0.3380   Test loss: 0.1005   Train acc: 0.9400   Val acc: 0.9109   Test acc: 0.9722\n",
      "Epoch: 21   Train loss: 0.1308   Val loss: 0.3496   Test loss: 0.1004   Train acc: 0.9000   Val acc: 0.9208   Test acc: 0.9722\n",
      "Epoch: 22   Train loss: 0.1582   Val loss: 0.3759   Test loss: 0.0923   Train acc: 0.9600   Val acc: 0.8960   Test acc: 0.9722\n",
      "Epoch: 23   Train loss: 0.0577   Val loss: 0.3406   Test loss: 0.1021   Train acc: 0.9800   Val acc: 0.9158   Test acc: 0.9792\n",
      "Epoch: 24   Train loss: 0.1077   Val loss: 0.3490   Test loss: 0.0938   Train acc: 0.9400   Val acc: 0.9109   Test acc: 0.9722\n",
      "The average accuracy is: 0.9765277777777776\n",
      "The best accuracy is: 0.9861111111111112\n",
      "THE BEST ACCURACY IS 0.9861111111111112\n",
      "subject 7 duration: 0:01:38.916875\n",
      "seed is 951\n",
      "Subject 8\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0799   Val loss: 0.4187   Test loss: 0.0254   Train acc: 0.9600   Val acc: 0.9059   Test acc: 0.9896\n",
      "Epoch: 1   Train loss: 0.1130   Val loss: 0.4295   Test loss: 0.0096   Train acc: 0.9400   Val acc: 0.8861   Test acc: 0.9965\n",
      "Epoch: 2   Train loss: 0.0226   Val loss: 0.3878   Test loss: 0.0127   Train acc: 1.0000   Val acc: 0.9059   Test acc: 0.9931\n",
      "Epoch: 3   Train loss: 0.0574   Val loss: 0.3898   Test loss: 0.0061   Train acc: 0.9800   Val acc: 0.9059   Test acc: 0.9965\n",
      "Epoch: 4   Train loss: 0.0963   Val loss: 0.3699   Test loss: 0.0293   Train acc: 0.9800   Val acc: 0.9208   Test acc: 0.9896\n",
      "Epoch: 5   Train loss: 0.0506   Val loss: 0.4497   Test loss: 0.0086   Train acc: 1.0000   Val acc: 0.8960   Test acc: 0.9965\n",
      "Epoch: 6   Train loss: 0.0552   Val loss: 0.4129   Test loss: 0.0084   Train acc: 0.9800   Val acc: 0.8960   Test acc: 0.9965\n",
      "Epoch: 7   Train loss: 0.0527   Val loss: 0.4361   Test loss: 0.0028   Train acc: 0.9800   Val acc: 0.8861   Test acc: 1.0000\n",
      "Epoch: 8   Train loss: 0.0223   Val loss: 0.5159   Test loss: 0.0056   Train acc: 1.0000   Val acc: 0.8812   Test acc: 0.9965\n",
      "Epoch: 9   Train loss: 0.0174   Val loss: 0.3973   Test loss: 0.0052   Train acc: 1.0000   Val acc: 0.9158   Test acc: 1.0000\n",
      "Epoch: 10   Train loss: 0.0668   Val loss: 0.4023   Test loss: 0.0298   Train acc: 0.9800   Val acc: 0.8812   Test acc: 0.9896\n",
      "Epoch: 11   Train loss: 0.0343   Val loss: 0.5397   Test loss: 0.0092   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9965\n",
      "Epoch: 12   Train loss: 0.0521   Val loss: 0.4034   Test loss: 0.0204   Train acc: 0.9800   Val acc: 0.9059   Test acc: 0.9931\n",
      "Epoch: 13   Train loss: 0.1975   Val loss: 0.3989   Test loss: 0.0086   Train acc: 0.9600   Val acc: 0.9010   Test acc: 0.9931\n",
      "Epoch: 14   Train loss: 0.0726   Val loss: 0.3756   Test loss: 0.0106   Train acc: 0.9600   Val acc: 0.9158   Test acc: 0.9931\n",
      "Epoch: 15   Train loss: 0.0167   Val loss: 0.4634   Test loss: 0.0066   Train acc: 1.0000   Val acc: 0.8663   Test acc: 1.0000\n",
      "Epoch: 16   Train loss: 0.0534   Val loss: 0.3891   Test loss: 0.0269   Train acc: 0.9800   Val acc: 0.9059   Test acc: 0.9896\n",
      "Epoch: 17   Train loss: 0.0466   Val loss: 0.3731   Test loss: 0.0062   Train acc: 1.0000   Val acc: 0.9109   Test acc: 0.9965\n",
      "Epoch: 18   Train loss: 0.1760   Val loss: 0.4237   Test loss: 0.0063   Train acc: 0.9400   Val acc: 0.8960   Test acc: 1.0000\n",
      "Epoch: 19   Train loss: 0.0254   Val loss: 0.3679   Test loss: 0.0216   Train acc: 1.0000   Val acc: 0.9059   Test acc: 0.9931\n",
      "Epoch: 20   Train loss: 0.0192   Val loss: 0.4107   Test loss: 0.0094   Train acc: 1.0000   Val acc: 0.8762   Test acc: 0.9931\n",
      "Epoch: 21   Train loss: 0.1046   Val loss: 0.4260   Test loss: 0.0140   Train acc: 0.9400   Val acc: 0.8861   Test acc: 0.9896\n",
      "Epoch: 22   Train loss: 0.0479   Val loss: 0.4512   Test loss: 0.0223   Train acc: 0.9800   Val acc: 0.8861   Test acc: 0.9931\n",
      "Epoch: 23   Train loss: 0.1501   Val loss: 0.4506   Test loss: 0.0096   Train acc: 0.9600   Val acc: 0.8911   Test acc: 0.9931\n",
      "Epoch: 24   Train loss: 0.0638   Val loss: 0.5438   Test loss: 0.0417   Train acc: 0.9800   Val acc: 0.8861   Test acc: 0.9896\n",
      "The average accuracy is: 0.9943055555555557\n",
      "The best accuracy is: 1.0\n",
      "THE BEST ACCURACY IS 1.0\n",
      "subject 8 duration: 0:01:38.458479\n",
      "seed is 240\n",
      "Subject 9\n",
      "Number of parameters:  290627\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0388   Val loss: 0.0742   Test loss: 1.9460   Train acc: 1.0000   Val acc: 0.9784   Test acc: 0.6493\n",
      "Epoch: 1   Train loss: 0.1569   Val loss: 0.0913   Test loss: 2.1801   Train acc: 0.9474   Val acc: 0.9654   Test acc: 0.6354\n",
      "Epoch: 2   Train loss: 0.0338   Val loss: 0.0764   Test loss: 1.8993   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6493\n",
      "Epoch: 3   Train loss: 0.0321   Val loss: 0.1090   Test loss: 1.9770   Train acc: 0.9825   Val acc: 0.9784   Test acc: 0.6597\n",
      "Epoch: 4   Train loss: 0.0189   Val loss: 0.0515   Test loss: 1.9916   Train acc: 0.9825   Val acc: 0.9870   Test acc: 0.6493\n",
      "Epoch: 5   Train loss: 0.0636   Val loss: 0.0626   Test loss: 1.9802   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6493\n",
      "Epoch: 6   Train loss: 0.0354   Val loss: 0.0839   Test loss: 2.3598   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6042\n",
      "Epoch: 7   Train loss: 0.1607   Val loss: 0.0427   Test loss: 1.9270   Train acc: 0.9649   Val acc: 0.9870   Test acc: 0.6285\n",
      "Epoch: 8   Train loss: 0.1280   Val loss: 0.0658   Test loss: 1.9990   Train acc: 0.9649   Val acc: 0.9784   Test acc: 0.6111\n",
      "Epoch: 9   Train loss: 0.0596   Val loss: 0.0445   Test loss: 1.8470   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6319\n",
      "Epoch: 10   Train loss: 0.0224   Val loss: 0.0406   Test loss: 1.9920   Train acc: 1.0000   Val acc: 0.9827   Test acc: 0.6111\n",
      "Epoch: 11   Train loss: 0.0916   Val loss: 0.0422   Test loss: 2.0399   Train acc: 0.9474   Val acc: 0.9827   Test acc: 0.6285\n",
      "Epoch: 12   Train loss: 0.0211   Val loss: 0.0631   Test loss: 2.1788   Train acc: 0.9825   Val acc: 0.9827   Test acc: 0.6215\n",
      "Epoch: 13   Train loss: 0.0273   Val loss: 0.0982   Test loss: 2.7179   Train acc: 1.0000   Val acc: 0.9784   Test acc: 0.5625\n",
      "Epoch: 14   Train loss: 0.0138   Val loss: 0.0754   Test loss: 2.3468   Train acc: 1.0000   Val acc: 0.9784   Test acc: 0.5625\n",
      "Epoch: 15   Train loss: 0.0427   Val loss: 0.1166   Test loss: 2.8106   Train acc: 0.9825   Val acc: 0.9697   Test acc: 0.5729\n",
      "Epoch: 16   Train loss: 0.0265   Val loss: 0.0576   Test loss: 1.8406   Train acc: 1.0000   Val acc: 0.9870   Test acc: 0.6389\n",
      "Epoch: 17   Train loss: 0.0507   Val loss: 0.0562   Test loss: 1.9541   Train acc: 0.9649   Val acc: 0.9784   Test acc: 0.6597\n",
      "Epoch: 18   Train loss: 0.0232   Val loss: 0.0740   Test loss: 1.8557   Train acc: 1.0000   Val acc: 0.9784   Test acc: 0.6389\n",
      "Epoch: 19   Train loss: 0.0550   Val loss: 0.0850   Test loss: 2.2996   Train acc: 0.9825   Val acc: 0.9697   Test acc: 0.6007\n",
      "Epoch: 20   Train loss: 0.0486   Val loss: 0.0743   Test loss: 2.2478   Train acc: 0.9649   Val acc: 0.9697   Test acc: 0.6111\n",
      "Epoch: 21   Train loss: 0.0084   Val loss: 0.0898   Test loss: 2.5394   Train acc: 1.0000   Val acc: 0.9740   Test acc: 0.5729\n",
      "Epoch: 22   Train loss: 0.0391   Val loss: 0.0709   Test loss: 2.1830   Train acc: 0.9825   Val acc: 0.9697   Test acc: 0.5833\n",
      "Epoch: 23   Train loss: 0.0633   Val loss: 0.0857   Test loss: 2.2854   Train acc: 0.9825   Val acc: 0.9697   Test acc: 0.6007\n",
      "Epoch: 24   Train loss: 0.0163   Val loss: 0.0875   Test loss: 2.2603   Train acc: 1.0000   Val acc: 0.9697   Test acc: 0.5764\n",
      "The average accuracy is: 0.6163888888888889\n",
      "The best accuracy is: 0.6597222222222222\n",
      "THE BEST ACCURACY IS 0.6597222222222222\n",
      "subject 9 duration: 0:01:57.828621\n",
      "Mean of best is 0.9131944444444442\n",
      "Mean of average is 0.8761265432098766\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
