{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.cct import CCT\n",
    "from torchinfo import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCT(kernel_sizes=[(22, 1), (1, 24), (1, 24)], stride=(1, 1), padding=(0, 0),\n",
    "            pooling_kernel_size=(3, 3), pooling_stride=(1, 1), pooling_padding=(0, 0),\n",
    "            n_conv_layers=3, n_input_channels=1,\n",
    "            in_planes=48, activation=None, # ReLU\n",
    "            max_pool=False, conv_bias=False,\n",
    "            dim=48, num_layers=3,\n",
    "            num_heads=3, num_classes=2, \n",
    "            attn_dropout=0.1, dropout=0.1, \n",
    "            mlp_size=48, positional_emb=\"learnable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "CCT (CCT)                                          [64, 1, 22, 321]     [64, 2]              --                   True\n",
       "├─Tokenizer (tokenizer)                            [64, 1, 22, 321]     [64, 275, 48]        --                   True\n",
       "│    └─Sequential (conv_layers)                    [64, 1, 22, 321]     [64, 48, 1, 275]     --                   True\n",
       "│    │    └─Sequential (0)                         [64, 1, 22, 321]     [64, 48, 1, 321]     1,056                True\n",
       "│    │    └─Sequential (1)                         [64, 48, 1, 321]     [64, 48, 1, 298]     55,296               True\n",
       "│    │    └─Sequential (2)                         [64, 48, 1, 298]     [64, 48, 1, 275]     55,296               True\n",
       "│    └─Flatten (flattener)                         [64, 48, 1, 275]     [64, 48, 275]        --                   --\n",
       "├─Transformer (transformer)                        [64, 275, 48]        [64, 2]              13,200               True\n",
       "│    └─Dropout (dropout)                           [64, 275, 48]        [64, 275, 48]        --                   --\n",
       "│    └─ModuleList (blocks)                         --                   --                   --                   True\n",
       "│    │    └─EncoderLayer (0)                       [64, 275, 48]        [64, 275, 48]        14,064               True\n",
       "│    │    └─EncoderLayer (1)                       [64, 275, 48]        [64, 275, 48]        14,064               True\n",
       "│    │    └─EncoderLayer (2)                       [64, 275, 48]        [64, 275, 48]        14,064               True\n",
       "│    └─LayerNorm (norm)                            [64, 275, 48]        [64, 275, 48]        96                   True\n",
       "│    └─Linear (attention_pool)                     [64, 275, 48]        [64, 275, 1]         49                   True\n",
       "│    └─Linear (fc)                                 [64, 48]             [64, 2]              98                   True\n",
       "==================================================================================================================================\n",
       "Total params: 167,283\n",
       "Trainable params: 167,283\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.05\n",
       "==================================================================================================================================\n",
       "Input size (MB): 1.81\n",
       "Forward/backward pass size (MB): 170.80\n",
       "Params size (MB): 0.62\n",
       "Estimated Total Size (MB): 173.22\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(64, 1, 22, 321),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['datasets/aBNCI2014001R.pickle', 'datasets/aBNCI2014004R.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "data = load_data(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 321)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = ['left_hand', 'right_hand']\n",
    "subject = 0\n",
    "s1 = data[subject]\n",
    "s1.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU device name : NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dev.type == 'cuda':\n",
    "    print('Your GPU device name :', torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCCT():\n",
    "    def __init__(self, nsub, n_subj=9):\n",
    "        super(ExP, self).__init__()\n",
    "        self.batch_size = 36\n",
    "        self.n_epochs = 25  #2000\n",
    "        self.c_dim = 4\n",
    "        self.lr = 3e-5\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.dimension = (190, 50)\n",
    "        self.nSub = nsub\n",
    "        self.n_subjects = 8 # total?\n",
    "        self.start_epoch = 0\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "        self.FloatTensor = torch.cuda.FloatTensor\n",
    "\n",
    "        self.criterion_l1 = torch.nn.L1Loss().cuda()\n",
    "        self.criterion_l2 = torch.nn.MSELoss().cuda()\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = model.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to(\"cuda\")\n",
    "            \n",
    "        self.total_params = sum(param.numel() for param in self.model.parameters())\n",
    "        print(\"Number of parameters: \", self.total_params)\n",
    "\n",
    "        #self.model = self.model.cuda()\n",
    "        # summary(self.model, (1, 22, 1000))\n",
    "\n",
    "\n",
    "    # Segmentation and Reconstruction (S&R) data augmentation\n",
    "    def interaug(self, timg, label):  \n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "        for cls4aug in range(2):\n",
    "            cls_idx = np.where(label == cls4aug + 1)\n",
    "            tmp_data = timg[cls_idx]\n",
    "            tmp_label = label[cls_idx]\n",
    "\n",
    "            tmp_aug_data = np.zeros((int(self.batch_size / 2), 1, 22, 321))\n",
    "            for ri in range(int(self.batch_size / 2)):\n",
    "                for rj in range(3):\n",
    "                    rand_idx = np.random.randint(0, tmp_data.shape[0], 3)\n",
    "                    tmp_aug_data[ri, :, :, rj * 107:(rj + 1) * 107] = tmp_data[rand_idx[rj], :, :,\n",
    "                                                                      rj * 107:(rj + 1) * 107]\n",
    "\n",
    "            aug_data.append(tmp_aug_data)\n",
    "            aug_label.append(tmp_label[:int(self.batch_size / 2)])\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        aug_data = aug_data[aug_shuffle, :, :]\n",
    "        aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        aug_data = torch.from_numpy(aug_data).cuda()\n",
    "        aug_data = aug_data.float()\n",
    "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
    "        aug_label = aug_label.long()\n",
    "        return aug_data, aug_label\n",
    "\n",
    "    def get_source_data(self):\n",
    "        \n",
    "        self.test_subject = self.nSub\n",
    "\n",
    "        # Get the data from the epochs object\n",
    "        self.data = load_data(datasets[0])\n",
    "        print('Dataset: ', datasets[0])\n",
    "\n",
    "        self.train_subjects = [i for i in range(self.n_subjects) if i != self.test_subject]\n",
    "\n",
    "        # Prepare test data\n",
    "        self.X_test = self.data[self.test_subject].get_data()\n",
    "        self.y_test = self.data[self.test_subject].events[:, -1]\n",
    "\n",
    "        # Prepare training data\n",
    "        self.X_train = np.concatenate([self.data[i].get_data() for i in self.train_subjects], axis=0)\n",
    "        self.y_train = np.concatenate([self.data[i].events[:, -1] for i in self.train_subjects], axis=0)\n",
    "\n",
    "        # train and val data\n",
    "        self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(self.X_train, self.y_train, test_size=0.1, random_state=42)\n",
    "        \n",
    "        self.allData = np.expand_dims(self.train_data, axis=1)\n",
    "        self.allLabel = self.train_label\n",
    "        \n",
    "        self.valData = np.expand_dims(self.val_data, axis=1)\n",
    "        self.valLabel = self.val_label\n",
    "\n",
    "        shuffle_num = np.random.permutation(len(self.allData))\n",
    "        self.allData = self.allData[shuffle_num, :, :, :]\n",
    "        self.allLabel = self.allLabel[shuffle_num]\n",
    "\n",
    "        # test data  \n",
    "        self.testData = np.expand_dims(self.X_test, axis=1)\n",
    "        self.testLabel = self.y_test\n",
    "        \n",
    "        # standardize\n",
    "        target_mean = np.mean(self.allData)\n",
    "        target_std = np.std(self.allData)\n",
    "        self.allData = (self.allData - target_mean) / target_std\n",
    "        self.testData = (self.testData - target_mean) / target_std\n",
    "        self.valData = (self.valData - target_mean) / target_std\n",
    "\n",
    "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
    "        return self.allData, self.allLabel, self.valData, self.valLabel, self.testData, self.testLabel\n",
    "\n",
    "    def train(self):\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        #img, label, test_data, test_label = self.get_source_data()\n",
    "        img, label, val_data, val_label, test_data, test_label = self.get_source_data()\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label - 1)\n",
    "        dataset = torch.utils.data.TensorDataset(img, label)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        val_data = torch.from_numpy(val_data)\n",
    "        val_label = torch.from_numpy(val_label - 1)\n",
    "        val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label - 1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(test_label.type(self.LongTensor))\n",
    "        \n",
    "        val_data = Variable(val_data.type(self.Tensor))\n",
    "        val_label = Variable(val_label.type(self.LongTensor))\n",
    "        \n",
    "        bestAcc = 0\n",
    "        averAcc = 0\n",
    "        num = 0\n",
    "        Y_true = 0\n",
    "        Y_pred = 0\n",
    "\n",
    "        # Train the cnn model\n",
    "        total_step = len(self.dataloader)\n",
    "        curr_lr = self.lr\n",
    "\n",
    "        for e in range(self.n_epochs):\n",
    "            # in_epoch = time.time()\n",
    "            self.model.train()\n",
    "            for i, (img, label) in enumerate(self.dataloader):\n",
    "\n",
    "                img = Variable(img.cuda().type(self.Tensor))\n",
    "                label = Variable(label.cuda().type(self.LongTensor)) #FloatTensor\n",
    "\n",
    "                # data augmentation\n",
    "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "                img = torch.cat((img, aug_data))\n",
    "                label = torch.cat((label, aug_label))\n",
    "\n",
    "                outputs = self.model(img)\n",
    "\n",
    "                loss = self.criterion_cls(outputs, label) \n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # test process\n",
    "            if (e + 1) % 1 == 0:\n",
    "                self.model.eval()\n",
    "                Cls = self.model(test_data)\n",
    "                probs = softmax(Cls, dim=1).cpu().detach().numpy()\n",
    "                loss_test = self.criterion_cls(Cls, test_label)\n",
    "                y_pred = torch.max(Cls, 1)[1]\n",
    "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
    "\n",
    "                #self.model.eval()\n",
    "                ValCls = self.model(val_data)\n",
    "                loss_val = self.criterion_cls(ValCls, val_label)\n",
    "                val_pred = torch.max(ValCls, 1)[1]\n",
    "                val_acc = float((val_pred == val_label).cpu().numpy().astype(int).sum()) / float(val_label.size(0))\n",
    "                \n",
    "                train_pred = torch.max(outputs, 1)[1]\n",
    "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
    "                \n",
    "                print('Epoch:', e,\n",
    "                      '  Train loss: %.4f' % loss.detach().cpu().numpy(),\n",
    "                      '  Val loss: %.4f' % loss_val.detach().cpu().numpy(),\n",
    "                      '  Test loss: %.4f' % loss_test.detach().cpu().numpy(),\n",
    "                      '  Train acc: %.4f' % train_acc,\n",
    "                      '  Val acc: %.4f' % val_acc,\n",
    "                      '  Test acc: %.4f' % acc)\n",
    "\n",
    "                num = num + 1\n",
    "                averAcc = averAcc + acc\n",
    "                if acc > bestAcc:\n",
    "                    bestAcc = acc\n",
    "                    Y_true = test_label\n",
    "                    Y_pred = y_pred\n",
    "            \n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            train_losses.append(loss.detach().cpu().numpy())\n",
    "            val_losses.append(loss_val.detach().cpu().numpy())\n",
    "\n",
    "        #torch.save(self.model.module.state_dict(), 'model.pth')\n",
    "        averAcc = averAcc / num\n",
    "        print('The average accuracy is:', averAcc)\n",
    "        print('The best accuracy is:', bestAcc)\n",
    "        \n",
    "        return bestAcc, averAcc, Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    best = 0\n",
    "    aver = 0\n",
    "\n",
    "    for i in range(9):\n",
    "        starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "        seed_n = np.random.randint(2021)\n",
    "        print('seed is ' + str(seed_n))\n",
    "        random.seed(seed_n)\n",
    "        np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "\n",
    "        print('Subject %d' % (i+1))\n",
    "        exp = EEGCCT(i)\n",
    "\n",
    "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
    "        print('THE BEST ACCURACY IS ' + str(bestAcc))\n",
    "\n",
    "        endtime = datetime.datetime.now()\n",
    "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
    "        best = best + bestAcc\n",
    "        aver = aver + averAcc\n",
    "        if i == 0:\n",
    "            yt = Y_true\n",
    "            yp = Y_pred\n",
    "        else:\n",
    "            yt = torch.cat((yt, Y_true))\n",
    "            yp = torch.cat((yp, Y_pred))\n",
    "\n",
    "\n",
    "    best = best / 9\n",
    "    aver = aver / 9\n",
    "    \n",
    "    print(f\"Mean of best is {best}\")\n",
    "    print(f\"Mean of average is {aver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 1089\n",
      "Subject 1\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.6868   Val loss: 0.6937   Test loss: 0.6934   Train acc: 0.5400   Val acc: 0.5099   Test acc: 0.4965\n",
      "Epoch: 1   Train loss: 0.6768   Val loss: 0.6814   Test loss: 0.6788   Train acc: 0.5400   Val acc: 0.5198   Test acc: 0.5278\n",
      "Epoch: 2   Train loss: 0.6481   Val loss: 0.6222   Test loss: 0.6151   Train acc: 0.6600   Val acc: 0.6980   Test acc: 0.7014\n",
      "Epoch: 3   Train loss: 0.5781   Val loss: 0.5678   Test loss: 0.5522   Train acc: 0.7200   Val acc: 0.7327   Test acc: 0.7118\n",
      "Epoch: 4   Train loss: 0.5341   Val loss: 0.5378   Test loss: 0.5156   Train acc: 0.7800   Val acc: 0.7475   Test acc: 0.7361\n",
      "Epoch: 5   Train loss: 0.5309   Val loss: 0.5173   Test loss: 0.5023   Train acc: 0.7200   Val acc: 0.7673   Test acc: 0.7431\n",
      "Epoch: 6   Train loss: 0.4549   Val loss: 0.5039   Test loss: 0.4857   Train acc: 0.8800   Val acc: 0.7772   Test acc: 0.7465\n",
      "Epoch: 7   Train loss: 0.4813   Val loss: 0.5164   Test loss: 0.4541   Train acc: 0.7200   Val acc: 0.7673   Test acc: 0.7674\n",
      "Epoch: 8   Train loss: 0.4380   Val loss: 0.5101   Test loss: 0.4719   Train acc: 0.7400   Val acc: 0.7475   Test acc: 0.7396\n",
      "Epoch: 9   Train loss: 0.4847   Val loss: 0.5120   Test loss: 0.4716   Train acc: 0.7600   Val acc: 0.7525   Test acc: 0.7500\n",
      "Epoch: 10   Train loss: 0.4337   Val loss: 0.4954   Test loss: 0.4456   Train acc: 0.8200   Val acc: 0.7277   Test acc: 0.7604\n",
      "Epoch: 11   Train loss: 0.4995   Val loss: 0.5063   Test loss: 0.4320   Train acc: 0.7200   Val acc: 0.7574   Test acc: 0.7708\n",
      "Epoch: 12   Train loss: 0.4483   Val loss: 0.5086   Test loss: 0.4517   Train acc: 0.7600   Val acc: 0.7327   Test acc: 0.7674\n",
      "Epoch: 13   Train loss: 0.4825   Val loss: 0.5282   Test loss: 0.5061   Train acc: 0.7600   Val acc: 0.7475   Test acc: 0.7257\n",
      "Epoch: 14   Train loss: 0.4387   Val loss: 0.5251   Test loss: 0.4401   Train acc: 0.7600   Val acc: 0.7178   Test acc: 0.7917\n",
      "Epoch: 15   Train loss: 0.4259   Val loss: 0.5233   Test loss: 0.4604   Train acc: 0.8200   Val acc: 0.7426   Test acc: 0.7812\n",
      "Epoch: 16   Train loss: 0.3494   Val loss: 0.4921   Test loss: 0.4286   Train acc: 0.9000   Val acc: 0.7376   Test acc: 0.8021\n",
      "Epoch: 17   Train loss: 0.3724   Val loss: 0.5041   Test loss: 0.4597   Train acc: 0.8000   Val acc: 0.7376   Test acc: 0.7569\n",
      "Epoch: 18   Train loss: 0.3381   Val loss: 0.5057   Test loss: 0.4668   Train acc: 0.8400   Val acc: 0.7525   Test acc: 0.7917\n",
      "Epoch: 19   Train loss: 0.3315   Val loss: 0.5136   Test loss: 0.4781   Train acc: 0.8400   Val acc: 0.7574   Test acc: 0.7465\n",
      "Epoch: 20   Train loss: 0.4498   Val loss: 0.5347   Test loss: 0.4937   Train acc: 0.8000   Val acc: 0.7079   Test acc: 0.7674\n",
      "Epoch: 21   Train loss: 0.4111   Val loss: 0.5230   Test loss: 0.4952   Train acc: 0.8400   Val acc: 0.7178   Test acc: 0.7812\n",
      "Epoch: 22   Train loss: 0.3399   Val loss: 0.5118   Test loss: 0.5209   Train acc: 0.8400   Val acc: 0.7772   Test acc: 0.7326\n",
      "Epoch: 23   Train loss: 0.2748   Val loss: 0.5706   Test loss: 0.5293   Train acc: 0.9000   Val acc: 0.7079   Test acc: 0.7431\n",
      "Epoch: 24   Train loss: 0.3440   Val loss: 0.5175   Test loss: 0.5029   Train acc: 0.8800   Val acc: 0.7228   Test acc: 0.7743\n",
      "The average accuracy is: 0.7365277777777779\n",
      "The best accuracy is: 0.8020833333333334\n",
      "THE BEST ACCURACY IS 0.8020833333333334\n",
      "subject 1 duration: 0:01:28.804244\n",
      "seed is 1235\n",
      "Subject 2\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2977   Val loss: 0.5057   Test loss: 0.4601   Train acc: 0.8600   Val acc: 0.7475   Test acc: 0.7882\n",
      "Epoch: 1   Train loss: 0.2483   Val loss: 0.4454   Test loss: 0.4428   Train acc: 0.9200   Val acc: 0.7723   Test acc: 0.8125\n",
      "Epoch: 2   Train loss: 0.3725   Val loss: 0.4366   Test loss: 0.4538   Train acc: 0.8000   Val acc: 0.7970   Test acc: 0.7986\n",
      "Epoch: 3   Train loss: 0.2908   Val loss: 0.4750   Test loss: 0.4494   Train acc: 0.8800   Val acc: 0.7822   Test acc: 0.8125\n",
      "Epoch: 4   Train loss: 0.2492   Val loss: 0.4643   Test loss: 0.4662   Train acc: 0.9000   Val acc: 0.7822   Test acc: 0.7812\n",
      "Epoch: 5   Train loss: 0.4772   Val loss: 0.4719   Test loss: 0.4940   Train acc: 0.8200   Val acc: 0.7574   Test acc: 0.7708\n",
      "Epoch: 6   Train loss: 0.3788   Val loss: 0.4673   Test loss: 0.5099   Train acc: 0.8200   Val acc: 0.7426   Test acc: 0.7604\n",
      "Epoch: 7   Train loss: 0.3727   Val loss: 0.4767   Test loss: 0.5594   Train acc: 0.8200   Val acc: 0.7723   Test acc: 0.7292\n",
      "Epoch: 8   Train loss: 0.3425   Val loss: 0.4535   Test loss: 0.5181   Train acc: 0.9000   Val acc: 0.7871   Test acc: 0.7639\n",
      "Epoch: 9   Train loss: 0.2233   Val loss: 0.4834   Test loss: 0.5447   Train acc: 0.9000   Val acc: 0.7772   Test acc: 0.7431\n",
      "Epoch: 10   Train loss: 0.1753   Val loss: 0.4530   Test loss: 0.5666   Train acc: 0.9200   Val acc: 0.7871   Test acc: 0.7465\n",
      "Epoch: 11   Train loss: 0.1508   Val loss: 0.4919   Test loss: 0.5649   Train acc: 0.9400   Val acc: 0.7723   Test acc: 0.7292\n",
      "Epoch: 12   Train loss: 0.2447   Val loss: 0.4812   Test loss: 0.6205   Train acc: 0.9000   Val acc: 0.7871   Test acc: 0.7257\n",
      "Epoch: 13   Train loss: 0.3023   Val loss: 0.4858   Test loss: 0.6015   Train acc: 0.8600   Val acc: 0.7822   Test acc: 0.7292\n",
      "Epoch: 14   Train loss: 0.3725   Val loss: 0.4853   Test loss: 0.6037   Train acc: 0.8600   Val acc: 0.7822   Test acc: 0.7361\n",
      "Epoch: 15   Train loss: 0.2469   Val loss: 0.5320   Test loss: 0.6501   Train acc: 0.8800   Val acc: 0.7772   Test acc: 0.7257\n",
      "Epoch: 16   Train loss: 0.1982   Val loss: 0.5093   Test loss: 0.6563   Train acc: 0.9600   Val acc: 0.7624   Test acc: 0.7188\n",
      "Epoch: 17   Train loss: 0.2179   Val loss: 0.5459   Test loss: 0.6259   Train acc: 0.9000   Val acc: 0.7525   Test acc: 0.7326\n",
      "Epoch: 18   Train loss: 0.2744   Val loss: 0.4870   Test loss: 0.6637   Train acc: 0.9200   Val acc: 0.7723   Test acc: 0.7326\n",
      "Epoch: 19   Train loss: 0.1836   Val loss: 0.5204   Test loss: 0.6485   Train acc: 0.9200   Val acc: 0.7525   Test acc: 0.6910\n",
      "Epoch: 20   Train loss: 0.3268   Val loss: 0.5728   Test loss: 0.6683   Train acc: 0.8800   Val acc: 0.7327   Test acc: 0.6771\n",
      "Epoch: 21   Train loss: 0.2285   Val loss: 0.5407   Test loss: 0.7015   Train acc: 0.9000   Val acc: 0.7673   Test acc: 0.7153\n",
      "Epoch: 22   Train loss: 0.2403   Val loss: 0.5407   Test loss: 0.6979   Train acc: 0.9400   Val acc: 0.7822   Test acc: 0.6840\n",
      "Epoch: 23   Train loss: 0.1785   Val loss: 0.5128   Test loss: 0.7021   Train acc: 0.9200   Val acc: 0.7822   Test acc: 0.7222\n",
      "Epoch: 24   Train loss: 0.3134   Val loss: 0.5259   Test loss: 0.7270   Train acc: 0.8600   Val acc: 0.7574   Test acc: 0.6979\n",
      "The average accuracy is: 0.7409722222222223\n",
      "The best accuracy is: 0.8125\n",
      "THE BEST ACCURACY IS 0.8125\n",
      "subject 2 duration: 0:01:23.038436\n",
      "seed is 363\n",
      "Subject 3\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2210   Val loss: 0.5790   Test loss: 0.0520   Train acc: 0.8800   Val acc: 0.7525   Test acc: 0.9861\n",
      "Epoch: 1   Train loss: 0.2926   Val loss: 0.5487   Test loss: 0.0720   Train acc: 0.9200   Val acc: 0.7525   Test acc: 0.9688\n",
      "Epoch: 2   Train loss: 0.2279   Val loss: 0.5865   Test loss: 0.0660   Train acc: 0.8800   Val acc: 0.7228   Test acc: 0.9792\n",
      "Epoch: 3   Train loss: 0.3166   Val loss: 0.6242   Test loss: 0.0628   Train acc: 0.8400   Val acc: 0.7574   Test acc: 0.9792\n",
      "Epoch: 4   Train loss: 0.3156   Val loss: 0.5896   Test loss: 0.0648   Train acc: 0.8200   Val acc: 0.7376   Test acc: 0.9792\n",
      "Epoch: 5   Train loss: 0.5190   Val loss: 0.5928   Test loss: 0.0695   Train acc: 0.7600   Val acc: 0.7525   Test acc: 0.9826\n",
      "Epoch: 6   Train loss: 0.2899   Val loss: 0.5832   Test loss: 0.0714   Train acc: 0.9000   Val acc: 0.7277   Test acc: 0.9826\n",
      "Epoch: 7   Train loss: 0.2299   Val loss: 0.6001   Test loss: 0.0793   Train acc: 0.9000   Val acc: 0.7376   Test acc: 0.9757\n",
      "Epoch: 8   Train loss: 0.2429   Val loss: 0.6106   Test loss: 0.0658   Train acc: 0.9000   Val acc: 0.7327   Test acc: 0.9757\n",
      "Epoch: 9   Train loss: 0.2463   Val loss: 0.5855   Test loss: 0.1061   Train acc: 0.9000   Val acc: 0.7673   Test acc: 0.9479\n",
      "Epoch: 10   Train loss: 0.2930   Val loss: 0.6438   Test loss: 0.0660   Train acc: 0.8600   Val acc: 0.7327   Test acc: 0.9792\n",
      "Epoch: 11   Train loss: 0.2674   Val loss: 0.5980   Test loss: 0.0827   Train acc: 0.9200   Val acc: 0.7426   Test acc: 0.9757\n",
      "Epoch: 12   Train loss: 0.3222   Val loss: 0.6378   Test loss: 0.1033   Train acc: 0.8200   Val acc: 0.7327   Test acc: 0.9514\n",
      "Epoch: 13   Train loss: 0.2608   Val loss: 0.6186   Test loss: 0.0868   Train acc: 0.8800   Val acc: 0.7475   Test acc: 0.9688\n",
      "Epoch: 14   Train loss: 0.2338   Val loss: 0.5939   Test loss: 0.0911   Train acc: 0.8600   Val acc: 0.7475   Test acc: 0.9618\n",
      "Epoch: 15   Train loss: 0.1910   Val loss: 0.5894   Test loss: 0.1251   Train acc: 0.9400   Val acc: 0.7673   Test acc: 0.9375\n",
      "Epoch: 16   Train loss: 0.2600   Val loss: 0.5976   Test loss: 0.1047   Train acc: 0.8800   Val acc: 0.7723   Test acc: 0.9444\n",
      "Epoch: 17   Train loss: 0.2369   Val loss: 0.6225   Test loss: 0.1072   Train acc: 0.8800   Val acc: 0.7376   Test acc: 0.9549\n",
      "Epoch: 18   Train loss: 0.2636   Val loss: 0.6226   Test loss: 0.1250   Train acc: 0.9400   Val acc: 0.7525   Test acc: 0.9271\n",
      "Epoch: 19   Train loss: 0.2808   Val loss: 0.5945   Test loss: 0.0921   Train acc: 0.8800   Val acc: 0.7673   Test acc: 0.9653\n",
      "Epoch: 20   Train loss: 0.2413   Val loss: 0.5967   Test loss: 0.1105   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.9340\n",
      "Epoch: 21   Train loss: 0.2008   Val loss: 0.6378   Test loss: 0.1039   Train acc: 0.9600   Val acc: 0.7475   Test acc: 0.9583\n",
      "Epoch: 22   Train loss: 0.1793   Val loss: 0.6600   Test loss: 0.1152   Train acc: 0.9400   Val acc: 0.7624   Test acc: 0.9514\n",
      "Epoch: 23   Train loss: 0.2425   Val loss: 0.6384   Test loss: 0.1348   Train acc: 0.9400   Val acc: 0.7426   Test acc: 0.9444\n",
      "Epoch: 24   Train loss: 0.1954   Val loss: 0.6473   Test loss: 0.1218   Train acc: 0.9400   Val acc: 0.7475   Test acc: 0.9444\n",
      "The average accuracy is: 0.962222222222222\n",
      "The best accuracy is: 0.9861111111111112\n",
      "THE BEST ACCURACY IS 0.9861111111111112\n",
      "subject 3 duration: 0:01:23.440524\n",
      "seed is 20\n",
      "Subject 4\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1702   Val loss: 0.5135   Test loss: 0.1221   Train acc: 0.9600   Val acc: 0.7921   Test acc: 0.9618\n",
      "Epoch: 1   Train loss: 0.0572   Val loss: 0.4927   Test loss: 0.1064   Train acc: 1.0000   Val acc: 0.8020   Test acc: 0.9757\n",
      "Epoch: 2   Train loss: 0.1066   Val loss: 0.5293   Test loss: 0.1058   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.9688\n",
      "Epoch: 3   Train loss: 0.2963   Val loss: 0.5084   Test loss: 0.1090   Train acc: 0.8800   Val acc: 0.8069   Test acc: 0.9722\n",
      "Epoch: 4   Train loss: 0.2819   Val loss: 0.5176   Test loss: 0.1403   Train acc: 0.9000   Val acc: 0.8069   Test acc: 0.9479\n",
      "Epoch: 5   Train loss: 0.1684   Val loss: 0.5066   Test loss: 0.1059   Train acc: 0.9400   Val acc: 0.7624   Test acc: 0.9757\n",
      "Epoch: 6   Train loss: 0.2888   Val loss: 0.5233   Test loss: 0.1145   Train acc: 0.9200   Val acc: 0.8069   Test acc: 0.9688\n",
      "Epoch: 7   Train loss: 0.2194   Val loss: 0.5590   Test loss: 0.1132   Train acc: 0.8800   Val acc: 0.7574   Test acc: 0.9722\n",
      "Epoch: 8   Train loss: 0.2355   Val loss: 0.5944   Test loss: 0.1779   Train acc: 0.9400   Val acc: 0.7871   Test acc: 0.9340\n",
      "Epoch: 9   Train loss: 0.2177   Val loss: 0.5526   Test loss: 0.1205   Train acc: 0.8800   Val acc: 0.7772   Test acc: 0.9618\n",
      "Epoch: 10   Train loss: 0.1537   Val loss: 0.5695   Test loss: 0.1330   Train acc: 0.9400   Val acc: 0.7822   Test acc: 0.9583\n",
      "Epoch: 11   Train loss: 0.1087   Val loss: 0.5613   Test loss: 0.1571   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.9514\n",
      "Epoch: 12   Train loss: 0.1508   Val loss: 0.5917   Test loss: 0.1372   Train acc: 0.9400   Val acc: 0.7723   Test acc: 0.9514\n",
      "Epoch: 13   Train loss: 0.1931   Val loss: 0.5947   Test loss: 0.1718   Train acc: 0.9400   Val acc: 0.7822   Test acc: 0.9444\n",
      "Epoch: 14   Train loss: 0.1859   Val loss: 0.5741   Test loss: 0.1643   Train acc: 0.9200   Val acc: 0.7871   Test acc: 0.9340\n",
      "Epoch: 15   Train loss: 0.0999   Val loss: 0.6650   Test loss: 0.1746   Train acc: 0.9800   Val acc: 0.7673   Test acc: 0.9340\n",
      "Epoch: 16   Train loss: 0.2520   Val loss: 0.5791   Test loss: 0.1517   Train acc: 0.9000   Val acc: 0.7921   Test acc: 0.9444\n",
      "Epoch: 17   Train loss: 0.0920   Val loss: 0.6429   Test loss: 0.1752   Train acc: 0.9600   Val acc: 0.7723   Test acc: 0.9410\n",
      "Epoch: 18   Train loss: 0.2177   Val loss: 0.6042   Test loss: 0.1754   Train acc: 0.9400   Val acc: 0.7772   Test acc: 0.9340\n",
      "Epoch: 19   Train loss: 0.1178   Val loss: 0.6388   Test loss: 0.1732   Train acc: 0.9400   Val acc: 0.7723   Test acc: 0.9236\n",
      "Epoch: 20   Train loss: 0.1201   Val loss: 0.6385   Test loss: 0.1582   Train acc: 0.9400   Val acc: 0.7574   Test acc: 0.9444\n",
      "Epoch: 21   Train loss: 0.1413   Val loss: 0.6224   Test loss: 0.1757   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.9271\n",
      "Epoch: 22   Train loss: 0.1472   Val loss: 0.5800   Test loss: 0.1649   Train acc: 0.9400   Val acc: 0.7970   Test acc: 0.9306\n",
      "Epoch: 23   Train loss: 0.1065   Val loss: 0.6197   Test loss: 0.1796   Train acc: 0.9400   Val acc: 0.7871   Test acc: 0.9340\n",
      "Epoch: 24   Train loss: 0.1419   Val loss: 0.6143   Test loss: 0.1628   Train acc: 0.9400   Val acc: 0.7772   Test acc: 0.9479\n",
      "The average accuracy is: 0.9495833333333334\n",
      "The best accuracy is: 0.9756944444444444\n",
      "THE BEST ACCURACY IS 0.9756944444444444\n",
      "subject 4 duration: 0:01:22.340918\n",
      "seed is 171\n",
      "Subject 5\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1391   Val loss: 0.4543   Test loss: 0.1710   Train acc: 0.9200   Val acc: 0.8168   Test acc: 0.9410\n",
      "Epoch: 1   Train loss: 0.1540   Val loss: 0.4714   Test loss: 0.1910   Train acc: 0.9400   Val acc: 0.8317   Test acc: 0.9306\n",
      "Epoch: 2   Train loss: 0.1652   Val loss: 0.5294   Test loss: 0.2057   Train acc: 0.9200   Val acc: 0.8069   Test acc: 0.9201\n",
      "Epoch: 3   Train loss: 0.0959   Val loss: 0.5255   Test loss: 0.1901   Train acc: 0.9600   Val acc: 0.8119   Test acc: 0.9167\n",
      "Epoch: 4   Train loss: 0.1125   Val loss: 0.5009   Test loss: 0.1609   Train acc: 0.9800   Val acc: 0.8119   Test acc: 0.9340\n",
      "Epoch: 5   Train loss: 0.1268   Val loss: 0.4839   Test loss: 0.1981   Train acc: 0.9400   Val acc: 0.8218   Test acc: 0.9306\n",
      "Epoch: 6   Train loss: 0.2166   Val loss: 0.5026   Test loss: 0.1659   Train acc: 0.8800   Val acc: 0.8168   Test acc: 0.9514\n",
      "Epoch: 7   Train loss: 0.0903   Val loss: 0.4983   Test loss: 0.2231   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9132\n",
      "Epoch: 8   Train loss: 0.2199   Val loss: 0.5190   Test loss: 0.2376   Train acc: 0.9200   Val acc: 0.8069   Test acc: 0.9028\n",
      "Epoch: 9   Train loss: 0.1359   Val loss: 0.5513   Test loss: 0.3037   Train acc: 0.9400   Val acc: 0.8168   Test acc: 0.8854\n",
      "Epoch: 10   Train loss: 0.1032   Val loss: 0.4931   Test loss: 0.3037   Train acc: 0.9600   Val acc: 0.8168   Test acc: 0.8889\n",
      "Epoch: 11   Train loss: 0.0679   Val loss: 0.5003   Test loss: 0.3392   Train acc: 0.9600   Val acc: 0.8218   Test acc: 0.8646\n",
      "Epoch: 12   Train loss: 0.1399   Val loss: 0.5396   Test loss: 0.2810   Train acc: 0.9600   Val acc: 0.8168   Test acc: 0.9028\n",
      "Epoch: 13   Train loss: 0.0942   Val loss: 0.5069   Test loss: 0.2138   Train acc: 0.9600   Val acc: 0.8218   Test acc: 0.9201\n",
      "Epoch: 14   Train loss: 0.1853   Val loss: 0.4761   Test loss: 0.2850   Train acc: 0.9200   Val acc: 0.8267   Test acc: 0.9028\n",
      "Epoch: 15   Train loss: 0.0608   Val loss: 0.5655   Test loss: 0.3050   Train acc: 0.9800   Val acc: 0.8119   Test acc: 0.9028\n",
      "Epoch: 16   Train loss: 0.1517   Val loss: 0.5317   Test loss: 0.3006   Train acc: 0.9400   Val acc: 0.8119   Test acc: 0.8854\n",
      "Epoch: 17   Train loss: 0.1619   Val loss: 0.5315   Test loss: 0.2449   Train acc: 0.9400   Val acc: 0.8020   Test acc: 0.9062\n",
      "Epoch: 18   Train loss: 0.1177   Val loss: 0.4994   Test loss: 0.2143   Train acc: 0.9400   Val acc: 0.8069   Test acc: 0.9201\n",
      "Epoch: 19   Train loss: 0.0842   Val loss: 0.5032   Test loss: 0.2576   Train acc: 0.9400   Val acc: 0.8069   Test acc: 0.9028\n",
      "Epoch: 20   Train loss: 0.1891   Val loss: 0.5339   Test loss: 0.2693   Train acc: 0.9400   Val acc: 0.8267   Test acc: 0.9132\n",
      "Epoch: 21   Train loss: 0.1640   Val loss: 0.5100   Test loss: 0.2599   Train acc: 0.9200   Val acc: 0.8119   Test acc: 0.9028\n",
      "Epoch: 22   Train loss: 0.1081   Val loss: 0.5155   Test loss: 0.2904   Train acc: 0.9400   Val acc: 0.8020   Test acc: 0.8993\n",
      "Epoch: 23   Train loss: 0.0930   Val loss: 0.5236   Test loss: 0.2656   Train acc: 0.9600   Val acc: 0.8069   Test acc: 0.9167\n",
      "Epoch: 24   Train loss: 0.2097   Val loss: 0.5433   Test loss: 0.4547   Train acc: 0.9200   Val acc: 0.8069   Test acc: 0.8368\n",
      "The average accuracy is: 0.9076388888888891\n",
      "The best accuracy is: 0.9513888888888888\n",
      "THE BEST ACCURACY IS 0.9513888888888888\n",
      "subject 5 duration: 0:01:22.848300\n",
      "seed is 528\n",
      "Subject 6\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1083   Val loss: 0.4459   Test loss: 0.1347   Train acc: 0.9400   Val acc: 0.8465   Test acc: 0.9514\n",
      "Epoch: 1   Train loss: 0.1209   Val loss: 0.4332   Test loss: 0.1515   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9479\n",
      "Epoch: 2   Train loss: 0.1228   Val loss: 0.3844   Test loss: 0.1398   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9618\n",
      "Epoch: 3   Train loss: 0.1236   Val loss: 0.4172   Test loss: 0.1518   Train acc: 0.9400   Val acc: 0.8465   Test acc: 0.9583\n",
      "Epoch: 4   Train loss: 0.0363   Val loss: 0.3930   Test loss: 0.1507   Train acc: 1.0000   Val acc: 0.8317   Test acc: 0.9514\n",
      "Epoch: 5   Train loss: 0.0629   Val loss: 0.4267   Test loss: 0.1564   Train acc: 0.9800   Val acc: 0.8218   Test acc: 0.9479\n",
      "Epoch: 6   Train loss: 0.1164   Val loss: 0.4416   Test loss: 0.1701   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9410\n",
      "Epoch: 7   Train loss: 0.2008   Val loss: 0.3872   Test loss: 0.1643   Train acc: 0.9200   Val acc: 0.8515   Test acc: 0.9479\n",
      "Epoch: 8   Train loss: 0.1167   Val loss: 0.4062   Test loss: 0.1599   Train acc: 0.9400   Val acc: 0.8465   Test acc: 0.9444\n",
      "Epoch: 9   Train loss: 0.0880   Val loss: 0.4508   Test loss: 0.1399   Train acc: 0.9800   Val acc: 0.8416   Test acc: 0.9549\n",
      "Epoch: 10   Train loss: 0.1478   Val loss: 0.4893   Test loss: 0.1516   Train acc: 0.9400   Val acc: 0.8366   Test acc: 0.9514\n",
      "Epoch: 11   Train loss: 0.1077   Val loss: 0.4391   Test loss: 0.1802   Train acc: 0.9400   Val acc: 0.8564   Test acc: 0.9444\n",
      "Epoch: 12   Train loss: 0.1644   Val loss: 0.4456   Test loss: 0.1542   Train acc: 0.9400   Val acc: 0.8465   Test acc: 0.9444\n",
      "Epoch: 13   Train loss: 0.0186   Val loss: 0.4308   Test loss: 0.1753   Train acc: 1.0000   Val acc: 0.8366   Test acc: 0.9410\n",
      "Epoch: 14   Train loss: 0.0720   Val loss: 0.4643   Test loss: 0.1757   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9410\n",
      "Epoch: 15   Train loss: 0.1641   Val loss: 0.4109   Test loss: 0.2064   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9375\n",
      "Epoch: 16   Train loss: 0.2045   Val loss: 0.4540   Test loss: 0.1913   Train acc: 0.8800   Val acc: 0.8416   Test acc: 0.9444\n",
      "Epoch: 17   Train loss: 0.0811   Val loss: 0.4442   Test loss: 0.1948   Train acc: 0.9400   Val acc: 0.8465   Test acc: 0.9514\n",
      "Epoch: 18   Train loss: 0.0479   Val loss: 0.4660   Test loss: 0.1965   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9410\n",
      "Epoch: 19   Train loss: 0.3326   Val loss: 0.4547   Test loss: 0.2111   Train acc: 0.9200   Val acc: 0.8465   Test acc: 0.9444\n",
      "Epoch: 20   Train loss: 0.0865   Val loss: 0.4895   Test loss: 0.2231   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9201\n",
      "Epoch: 21   Train loss: 0.0779   Val loss: 0.4029   Test loss: 0.2312   Train acc: 0.9800   Val acc: 0.8416   Test acc: 0.9410\n",
      "Epoch: 22   Train loss: 0.1888   Val loss: 0.4427   Test loss: 0.2147   Train acc: 0.9400   Val acc: 0.8267   Test acc: 0.9410\n",
      "Epoch: 23   Train loss: 0.0365   Val loss: 0.3920   Test loss: 0.2370   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9167\n",
      "Epoch: 24   Train loss: 0.3006   Val loss: 0.4663   Test loss: 0.2206   Train acc: 0.9000   Val acc: 0.8416   Test acc: 0.9340\n",
      "The average accuracy is: 0.9440277777777777\n",
      "The best accuracy is: 0.9618055555555556\n",
      "THE BEST ACCURACY IS 0.9618055555555556\n",
      "subject 6 duration: 0:01:25.593657\n",
      "seed is 1793\n",
      "Subject 7\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1099   Val loss: 0.3284   Test loss: 0.1101   Train acc: 0.9600   Val acc: 0.8762   Test acc: 0.9722\n",
      "Epoch: 1   Train loss: 0.1054   Val loss: 0.3461   Test loss: 0.0963   Train acc: 0.9200   Val acc: 0.8762   Test acc: 0.9653\n",
      "Epoch: 2   Train loss: 0.4012   Val loss: 0.3466   Test loss: 0.0855   Train acc: 0.8800   Val acc: 0.8762   Test acc: 0.9722\n",
      "Epoch: 3   Train loss: 0.1336   Val loss: 0.3500   Test loss: 0.0927   Train acc: 0.9600   Val acc: 0.8614   Test acc: 0.9688\n",
      "Epoch: 4   Train loss: 0.0578   Val loss: 0.3710   Test loss: 0.0921   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9757\n",
      "Epoch: 5   Train loss: 0.0713   Val loss: 0.3526   Test loss: 0.0984   Train acc: 0.9600   Val acc: 0.8812   Test acc: 0.9688\n",
      "Epoch: 6   Train loss: 0.1544   Val loss: 0.3685   Test loss: 0.0992   Train acc: 0.9600   Val acc: 0.8762   Test acc: 0.9722\n",
      "Epoch: 7   Train loss: 0.0542   Val loss: 0.3676   Test loss: 0.0934   Train acc: 0.9800   Val acc: 0.8713   Test acc: 0.9722\n",
      "Epoch: 8   Train loss: 0.2682   Val loss: 0.3542   Test loss: 0.1029   Train acc: 0.9200   Val acc: 0.8911   Test acc: 0.9722\n",
      "Epoch: 9   Train loss: 0.1153   Val loss: 0.3931   Test loss: 0.1122   Train acc: 0.9600   Val acc: 0.8713   Test acc: 0.9653\n",
      "Epoch: 10   Train loss: 0.0759   Val loss: 0.3813   Test loss: 0.1132   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9653\n",
      "Epoch: 11   Train loss: 0.1244   Val loss: 0.3467   Test loss: 0.1007   Train acc: 0.9800   Val acc: 0.8911   Test acc: 0.9688\n",
      "Epoch: 12   Train loss: 0.1322   Val loss: 0.3636   Test loss: 0.1085   Train acc: 0.9600   Val acc: 0.8911   Test acc: 0.9688\n",
      "Epoch: 13   Train loss: 0.0835   Val loss: 0.3650   Test loss: 0.1124   Train acc: 0.9800   Val acc: 0.8663   Test acc: 0.9653\n",
      "Epoch: 14   Train loss: 0.1088   Val loss: 0.3998   Test loss: 0.1195   Train acc: 0.9800   Val acc: 0.8713   Test acc: 0.9618\n",
      "Epoch: 15   Train loss: 0.1086   Val loss: 0.3673   Test loss: 0.0987   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9722\n",
      "Epoch: 16   Train loss: 0.1057   Val loss: 0.3424   Test loss: 0.0969   Train acc: 0.9600   Val acc: 0.8812   Test acc: 0.9688\n",
      "Epoch: 17   Train loss: 0.0366   Val loss: 0.3954   Test loss: 0.1080   Train acc: 0.9800   Val acc: 0.8713   Test acc: 0.9688\n",
      "Epoch: 18   Train loss: 0.1023   Val loss: 0.3909   Test loss: 0.1038   Train acc: 0.9800   Val acc: 0.8861   Test acc: 0.9653\n",
      "Epoch: 19   Train loss: 0.1885   Val loss: 0.3865   Test loss: 0.1041   Train acc: 0.9000   Val acc: 0.8762   Test acc: 0.9583\n",
      "Epoch: 20   Train loss: 0.1955   Val loss: 0.3996   Test loss: 0.1092   Train acc: 0.9400   Val acc: 0.8663   Test acc: 0.9653\n",
      "Epoch: 21   Train loss: 0.1824   Val loss: 0.3413   Test loss: 0.1015   Train acc: 0.9400   Val acc: 0.8861   Test acc: 0.9583\n",
      "Epoch: 22   Train loss: 0.1583   Val loss: 0.4131   Test loss: 0.1490   Train acc: 0.9200   Val acc: 0.8713   Test acc: 0.9549\n",
      "Epoch: 23   Train loss: 0.0331   Val loss: 0.4008   Test loss: 0.1114   Train acc: 1.0000   Val acc: 0.8713   Test acc: 0.9722\n",
      "Epoch: 24   Train loss: 0.0650   Val loss: 0.3632   Test loss: 0.1218   Train acc: 0.9600   Val acc: 0.8762   Test acc: 0.9583\n",
      "The average accuracy is: 0.9670833333333333\n",
      "The best accuracy is: 0.9756944444444444\n",
      "THE BEST ACCURACY IS 0.9756944444444444\n",
      "subject 7 duration: 0:01:23.047307\n",
      "seed is 1231\n",
      "Subject 8\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2027   Val loss: 0.4321   Test loss: 0.0462   Train acc: 0.9200   Val acc: 0.8515   Test acc: 0.9861\n",
      "Epoch: 1   Train loss: 0.1850   Val loss: 0.4185   Test loss: 0.0322   Train acc: 0.9400   Val acc: 0.8663   Test acc: 0.9896\n",
      "Epoch: 2   Train loss: 0.1148   Val loss: 0.3897   Test loss: 0.0314   Train acc: 0.9800   Val acc: 0.8713   Test acc: 0.9896\n",
      "Epoch: 3   Train loss: 0.2213   Val loss: 0.4298   Test loss: 0.0295   Train acc: 0.8800   Val acc: 0.8614   Test acc: 0.9896\n",
      "Epoch: 4   Train loss: 0.0359   Val loss: 0.4150   Test loss: 0.0245   Train acc: 1.0000   Val acc: 0.8614   Test acc: 0.9965\n",
      "Epoch: 5   Train loss: 0.1497   Val loss: 0.4072   Test loss: 0.0283   Train acc: 0.9800   Val acc: 0.8564   Test acc: 0.9931\n",
      "Epoch: 6   Train loss: 0.1674   Val loss: 0.4185   Test loss: 0.0410   Train acc: 0.9400   Val acc: 0.8614   Test acc: 0.9896\n",
      "Epoch: 7   Train loss: 0.0095   Val loss: 0.4263   Test loss: 0.0332   Train acc: 1.0000   Val acc: 0.8564   Test acc: 0.9896\n",
      "Epoch: 8   Train loss: 0.1060   Val loss: 0.4979   Test loss: 0.0517   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9896\n",
      "Epoch: 9   Train loss: 0.1586   Val loss: 0.4867   Test loss: 0.0238   Train acc: 0.9200   Val acc: 0.8366   Test acc: 0.9931\n",
      "Epoch: 10   Train loss: 0.0512   Val loss: 0.4520   Test loss: 0.0297   Train acc: 1.0000   Val acc: 0.8515   Test acc: 0.9896\n",
      "Epoch: 11   Train loss: 0.0249   Val loss: 0.4111   Test loss: 0.0393   Train acc: 1.0000   Val acc: 0.8812   Test acc: 0.9896\n",
      "Epoch: 12   Train loss: 0.0218   Val loss: 0.4424   Test loss: 0.0452   Train acc: 1.0000   Val acc: 0.8515   Test acc: 0.9896\n",
      "Epoch: 13   Train loss: 0.1055   Val loss: 0.4680   Test loss: 0.0358   Train acc: 0.9400   Val acc: 0.8366   Test acc: 0.9896\n",
      "Epoch: 14   Train loss: 0.1090   Val loss: 0.4365   Test loss: 0.0378   Train acc: 0.9400   Val acc: 0.8515   Test acc: 0.9896\n",
      "Epoch: 15   Train loss: 0.0777   Val loss: 0.4422   Test loss: 0.0448   Train acc: 0.9600   Val acc: 0.8564   Test acc: 0.9896\n",
      "Epoch: 16   Train loss: 0.1361   Val loss: 0.4454   Test loss: 0.0371   Train acc: 0.9200   Val acc: 0.8614   Test acc: 0.9896\n",
      "Epoch: 17   Train loss: 0.1947   Val loss: 0.4964   Test loss: 0.0471   Train acc: 0.9200   Val acc: 0.8515   Test acc: 0.9896\n",
      "Epoch: 18   Train loss: 0.0786   Val loss: 0.4380   Test loss: 0.0345   Train acc: 0.9600   Val acc: 0.8663   Test acc: 0.9896\n",
      "Epoch: 19   Train loss: 0.0636   Val loss: 0.4742   Test loss: 0.0354   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9896\n",
      "Epoch: 20   Train loss: 0.0612   Val loss: 0.4627   Test loss: 0.0361   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9861\n",
      "Epoch: 21   Train loss: 0.2046   Val loss: 0.4417   Test loss: 0.0416   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9861\n",
      "Epoch: 22   Train loss: 0.1124   Val loss: 0.4428   Test loss: 0.0420   Train acc: 0.9600   Val acc: 0.8614   Test acc: 0.9896\n",
      "Epoch: 23   Train loss: 0.0548   Val loss: 0.4408   Test loss: 0.0449   Train acc: 0.9600   Val acc: 0.8465   Test acc: 0.9896\n",
      "Epoch: 24   Train loss: 0.0706   Val loss: 0.4617   Test loss: 0.0696   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9826\n",
      "The average accuracy is: 0.9894444444444442\n",
      "The best accuracy is: 0.9965277777777778\n",
      "THE BEST ACCURACY IS 0.9965277777777778\n",
      "subject 8 duration: 0:01:23.002038\n",
      "seed is 1687\n",
      "Subject 9\n",
      "Number of parameters:  167283\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0151   Val loss: 0.0677   Test loss: 1.3626   Train acc: 1.0000   Val acc: 0.9610   Test acc: 0.6910\n",
      "Epoch: 1   Train loss: 0.0514   Val loss: 0.0810   Test loss: 1.3274   Train acc: 1.0000   Val acc: 0.9567   Test acc: 0.6840\n",
      "Epoch: 2   Train loss: 0.0238   Val loss: 0.0994   Test loss: 1.2372   Train acc: 1.0000   Val acc: 0.9567   Test acc: 0.7188\n",
      "Epoch: 3   Train loss: 0.1313   Val loss: 0.0618   Test loss: 1.4461   Train acc: 0.9474   Val acc: 0.9654   Test acc: 0.6875\n",
      "Epoch: 4   Train loss: 0.1496   Val loss: 0.0729   Test loss: 1.2905   Train acc: 0.9649   Val acc: 0.9610   Test acc: 0.7222\n",
      "Epoch: 5   Train loss: 0.0757   Val loss: 0.0850   Test loss: 1.3303   Train acc: 0.9649   Val acc: 0.9524   Test acc: 0.6771\n",
      "Epoch: 6   Train loss: 0.2549   Val loss: 0.0861   Test loss: 1.4133   Train acc: 0.9298   Val acc: 0.9567   Test acc: 0.6944\n",
      "Epoch: 7   Train loss: 0.1648   Val loss: 0.0975   Test loss: 1.5136   Train acc: 0.9298   Val acc: 0.9654   Test acc: 0.6806\n",
      "Epoch: 8   Train loss: 0.1217   Val loss: 0.0868   Test loss: 1.3131   Train acc: 0.9474   Val acc: 0.9567   Test acc: 0.7014\n",
      "Epoch: 9   Train loss: 0.2091   Val loss: 0.0902   Test loss: 1.4000   Train acc: 0.8947   Val acc: 0.9610   Test acc: 0.6944\n",
      "Epoch: 10   Train loss: 0.0640   Val loss: 0.0917   Test loss: 1.3865   Train acc: 0.9474   Val acc: 0.9524   Test acc: 0.6979\n",
      "Epoch: 11   Train loss: 0.1067   Val loss: 0.1052   Test loss: 1.3105   Train acc: 0.9649   Val acc: 0.9524   Test acc: 0.6944\n",
      "Epoch: 12   Train loss: 0.0376   Val loss: 0.0704   Test loss: 1.4614   Train acc: 0.9825   Val acc: 0.9740   Test acc: 0.7118\n",
      "Epoch: 13   Train loss: 0.0434   Val loss: 0.1081   Test loss: 1.3202   Train acc: 0.9825   Val acc: 0.9394   Test acc: 0.7049\n",
      "Epoch: 14   Train loss: 0.0258   Val loss: 0.1635   Test loss: 1.1574   Train acc: 1.0000   Val acc: 0.9394   Test acc: 0.7465\n",
      "Epoch: 15   Train loss: 0.0374   Val loss: 0.0981   Test loss: 1.4204   Train acc: 1.0000   Val acc: 0.9654   Test acc: 0.6979\n",
      "Epoch: 16   Train loss: 0.0296   Val loss: 0.0768   Test loss: 1.5518   Train acc: 0.9825   Val acc: 0.9697   Test acc: 0.6875\n",
      "Epoch: 17   Train loss: 0.0856   Val loss: 0.1180   Test loss: 1.3325   Train acc: 0.9825   Val acc: 0.9394   Test acc: 0.7014\n",
      "Epoch: 18   Train loss: 0.0885   Val loss: 0.1349   Test loss: 1.2095   Train acc: 0.9649   Val acc: 0.9394   Test acc: 0.7049\n",
      "Epoch: 19   Train loss: 0.1879   Val loss: 0.1091   Test loss: 1.3872   Train acc: 0.9825   Val acc: 0.9437   Test acc: 0.6875\n",
      "Epoch: 20   Train loss: 0.0401   Val loss: 0.1271   Test loss: 1.2586   Train acc: 0.9825   Val acc: 0.9524   Test acc: 0.7153\n",
      "Epoch: 21   Train loss: 0.0463   Val loss: 0.1335   Test loss: 1.2999   Train acc: 1.0000   Val acc: 0.9437   Test acc: 0.7014\n",
      "Epoch: 22   Train loss: 0.0449   Val loss: 0.1225   Test loss: 1.3740   Train acc: 1.0000   Val acc: 0.9351   Test acc: 0.6910\n",
      "Epoch: 23   Train loss: 0.0082   Val loss: 0.1236   Test loss: 1.4016   Train acc: 1.0000   Val acc: 0.9437   Test acc: 0.7049\n",
      "Epoch: 24   Train loss: 0.1157   Val loss: 0.1269   Test loss: 1.3440   Train acc: 0.9825   Val acc: 0.9481   Test acc: 0.7014\n",
      "The average accuracy is: 0.7\n",
      "The best accuracy is: 0.7465277777777778\n",
      "THE BEST ACCURACY IS 0.7465277777777778\n",
      "subject 9 duration: 0:01:41.880426\n",
      "Mean of best is 0.9120370370370371\n",
      "Mean of average is 0.8775\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
