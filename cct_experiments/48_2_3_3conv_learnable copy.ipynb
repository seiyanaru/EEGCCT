{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.cct import CCT\n",
    "from torchinfo import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCT(kernel_sizes=[(22, 1), (1, 24), (1, 24)], stride=(1, 1), padding=(0, 0),\n",
    "            pooling_kernel_size=(3, 3), pooling_stride=(1, 1), pooling_padding=(0, 0),\n",
    "            n_conv_layers=3, n_input_channels=1,\n",
    "            in_planes=48, activation=None, # ReLU\n",
    "            max_pool=False, conv_bias=False,\n",
    "            dim=48, num_layers=2,\n",
    "            num_heads=3, num_classes=2, \n",
    "            attn_dropout=0.1, dropout=0.1, \n",
    "            mlp_size=48, positional_emb=\"learnable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "CCT (CCT)                                          [64, 1, 22, 321]     [64, 2]              --                   True\n",
       "├─Tokenizer (tokenizer)                            [64, 1, 22, 321]     [64, 275, 48]        --                   True\n",
       "│    └─Sequential (conv_layers)                    [64, 1, 22, 321]     [64, 48, 1, 275]     --                   True\n",
       "│    │    └─Sequential (0)                         [64, 1, 22, 321]     [64, 48, 1, 321]     1,056                True\n",
       "│    │    └─Sequential (1)                         [64, 48, 1, 321]     [64, 48, 1, 298]     55,296               True\n",
       "│    │    └─Sequential (2)                         [64, 48, 1, 298]     [64, 48, 1, 275]     55,296               True\n",
       "│    └─Flatten (flattener)                         [64, 48, 1, 275]     [64, 48, 275]        --                   --\n",
       "├─Transformer (transformer)                        [64, 275, 48]        [64, 2]              13,200               True\n",
       "│    └─Dropout (dropout)                           [64, 275, 48]        [64, 275, 48]        --                   --\n",
       "│    └─ModuleList (blocks)                         --                   --                   --                   True\n",
       "│    │    └─EncoderLayer (0)                       [64, 275, 48]        [64, 275, 48]        14,064               True\n",
       "│    │    └─EncoderLayer (1)                       [64, 275, 48]        [64, 275, 48]        14,064               True\n",
       "│    └─LayerNorm (norm)                            [64, 275, 48]        [64, 275, 48]        96                   True\n",
       "│    └─Linear (attention_pool)                     [64, 275, 48]        [64, 275, 1]         49                   True\n",
       "│    └─Linear (fc)                                 [64, 48]             [64, 2]              98                   True\n",
       "==================================================================================================================================\n",
       "Total params: 153,219\n",
       "Trainable params: 153,219\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.05\n",
       "==================================================================================================================================\n",
       "Input size (MB): 1.81\n",
       "Forward/backward pass size (MB): 123.49\n",
       "Params size (MB): 0.56\n",
       "Estimated Total Size (MB): 125.86\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(64, 1, 22, 321),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['datasets/aBNCI2014001R.pickle', 'datasets/aBNCI2014004R.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import itertools\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "data = load_data(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 321)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = ['left_hand', 'right_hand']\n",
    "subject = 0\n",
    "s1 = data[subject]\n",
    "s1.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU device name : NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dev.type == 'cuda':\n",
    "    print('Your GPU device name :', torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCCT():\n",
    "    def __init__(self, nsub, n_subj=9):\n",
    "        super(ExP, self).__init__()\n",
    "        self.batch_size = 36\n",
    "        self.n_epochs = 25  #2000\n",
    "        self.c_dim = 4\n",
    "        self.lr = 3e-5\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.dimension = (190, 50)\n",
    "        self.nSub = nsub\n",
    "        self.n_subjects = 8 # total?\n",
    "        self.start_epoch = 0\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "        self.FloatTensor = torch.cuda.FloatTensor\n",
    "\n",
    "        self.criterion_l1 = torch.nn.L1Loss().cuda()\n",
    "        self.criterion_l2 = torch.nn.MSELoss().cuda()\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = model.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to(\"cuda\")\n",
    "            \n",
    "        self.total_params = sum(param.numel() for param in self.model.parameters())\n",
    "        print(\"Number of parameters: \", self.total_params)\n",
    "\n",
    "        #self.model = self.model.cuda()\n",
    "        # summary(self.model, (1, 22, 1000))\n",
    "\n",
    "\n",
    "    # Segmentation and Reconstruction (S&R) data augmentation\n",
    "    def interaug(self, timg, label):  \n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "        for cls4aug in range(2):\n",
    "            cls_idx = np.where(label == cls4aug + 1)\n",
    "            tmp_data = timg[cls_idx]\n",
    "            tmp_label = label[cls_idx]\n",
    "\n",
    "            tmp_aug_data = np.zeros((int(self.batch_size / 2), 1, 22, 321))\n",
    "            for ri in range(int(self.batch_size / 2)):\n",
    "                for rj in range(3):\n",
    "                    rand_idx = np.random.randint(0, tmp_data.shape[0], 3)\n",
    "                    tmp_aug_data[ri, :, :, rj * 107:(rj + 1) * 107] = tmp_data[rand_idx[rj], :, :,\n",
    "                                                                      rj * 107:(rj + 1) * 107]\n",
    "\n",
    "            aug_data.append(tmp_aug_data)\n",
    "            aug_label.append(tmp_label[:int(self.batch_size / 2)])\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        aug_data = aug_data[aug_shuffle, :, :]\n",
    "        aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        aug_data = torch.from_numpy(aug_data).cuda()\n",
    "        aug_data = aug_data.float()\n",
    "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
    "        aug_label = aug_label.long()\n",
    "        return aug_data, aug_label\n",
    "\n",
    "    def get_source_data(self):\n",
    "        \n",
    "        self.test_subject = self.nSub\n",
    "\n",
    "        # Get the data from the epochs object\n",
    "        self.data = load_data(datasets[0])\n",
    "        print('Dataset: ', datasets[0])\n",
    "\n",
    "        self.train_subjects = [i for i in range(self.n_subjects) if i != self.test_subject]\n",
    "\n",
    "        # Prepare test data\n",
    "        self.X_test = self.data[self.test_subject].get_data()\n",
    "        self.y_test = self.data[self.test_subject].events[:, -1]\n",
    "\n",
    "        # Prepare training data\n",
    "        self.X_train = np.concatenate([self.data[i].get_data() for i in self.train_subjects], axis=0)\n",
    "        self.y_train = np.concatenate([self.data[i].events[:, -1] for i in self.train_subjects], axis=0)\n",
    "\n",
    "        # train and val data\n",
    "        self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(self.X_train, self.y_train, test_size=0.1, random_state=42)\n",
    "        \n",
    "        self.allData = np.expand_dims(self.train_data, axis=1)\n",
    "        self.allLabel = self.train_label\n",
    "        \n",
    "        self.valData = np.expand_dims(self.val_data, axis=1)\n",
    "        self.valLabel = self.val_label\n",
    "\n",
    "        shuffle_num = np.random.permutation(len(self.allData))\n",
    "        self.allData = self.allData[shuffle_num, :, :, :]\n",
    "        self.allLabel = self.allLabel[shuffle_num]\n",
    "\n",
    "        # test data  \n",
    "        self.testData = np.expand_dims(self.X_test, axis=1)\n",
    "        self.testLabel = self.y_test\n",
    "        \n",
    "        # standardize\n",
    "        target_mean = np.mean(self.allData)\n",
    "        target_std = np.std(self.allData)\n",
    "        self.allData = (self.allData - target_mean) / target_std\n",
    "        self.testData = (self.testData - target_mean) / target_std\n",
    "        self.valData = (self.valData - target_mean) / target_std\n",
    "\n",
    "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
    "        return self.allData, self.allLabel, self.valData, self.valLabel, self.testData, self.testLabel\n",
    "\n",
    "    def train(self):\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        #img, label, test_data, test_label = self.get_source_data()\n",
    "        img, label, val_data, val_label, test_data, test_label = self.get_source_data()\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label - 1)\n",
    "        dataset = torch.utils.data.TensorDataset(img, label)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        val_data = torch.from_numpy(val_data)\n",
    "        val_label = torch.from_numpy(val_label - 1)\n",
    "        val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label - 1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(test_label.type(self.LongTensor))\n",
    "        \n",
    "        val_data = Variable(val_data.type(self.Tensor))\n",
    "        val_label = Variable(val_label.type(self.LongTensor))\n",
    "        \n",
    "        bestAcc = 0\n",
    "        averAcc = 0\n",
    "        num = 0\n",
    "        Y_true = 0\n",
    "        Y_pred = 0\n",
    "\n",
    "        # Train the cnn model\n",
    "        total_step = len(self.dataloader)\n",
    "        curr_lr = self.lr\n",
    "\n",
    "        for e in range(self.n_epochs):\n",
    "            # in_epoch = time.time()\n",
    "            self.model.train()\n",
    "            for i, (img, label) in enumerate(self.dataloader):\n",
    "\n",
    "                img = Variable(img.cuda().type(self.Tensor))\n",
    "                label = Variable(label.cuda().type(self.LongTensor)) #FloatTensor\n",
    "\n",
    "                # data augmentation\n",
    "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "                img = torch.cat((img, aug_data))\n",
    "                label = torch.cat((label, aug_label))\n",
    "\n",
    "                outputs = self.model(img)\n",
    "\n",
    "                loss = self.criterion_cls(outputs, label) \n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # test process\n",
    "            if (e + 1) % 1 == 0:\n",
    "                self.model.eval()\n",
    "                Cls = self.model(test_data)\n",
    "                probs = softmax(Cls, dim=1).cpu().detach().numpy()\n",
    "                loss_test = self.criterion_cls(Cls, test_label)\n",
    "                y_pred = torch.max(Cls, 1)[1]\n",
    "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
    "\n",
    "                #self.model.eval()\n",
    "                ValCls = self.model(val_data)\n",
    "                loss_val = self.criterion_cls(ValCls, val_label)\n",
    "                val_pred = torch.max(ValCls, 1)[1]\n",
    "                val_acc = float((val_pred == val_label).cpu().numpy().astype(int).sum()) / float(val_label.size(0))\n",
    "                \n",
    "                train_pred = torch.max(outputs, 1)[1]\n",
    "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
    "                \n",
    "                print('Epoch:', e,\n",
    "                      '  Train loss: %.4f' % loss.detach().cpu().numpy(),\n",
    "                      '  Val loss: %.4f' % loss_val.detach().cpu().numpy(),\n",
    "                      '  Test loss: %.4f' % loss_test.detach().cpu().numpy(),\n",
    "                      '  Train acc: %.4f' % train_acc,\n",
    "                      '  Val acc: %.4f' % val_acc,\n",
    "                      '  Test acc: %.4f' % acc)\n",
    "\n",
    "                num = num + 1\n",
    "                averAcc = averAcc + acc\n",
    "                if acc > bestAcc:\n",
    "                    bestAcc = acc\n",
    "                    Y_true = test_label\n",
    "                    Y_pred = y_pred\n",
    "            \n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            train_losses.append(loss.detach().cpu().numpy())\n",
    "            val_losses.append(loss_val.detach().cpu().numpy())\n",
    "\n",
    "        #torch.save(self.model.module.state_dict(), 'model.pth')\n",
    "        averAcc = averAcc / num\n",
    "        print('The average accuracy is:', averAcc)\n",
    "        print('The best accuracy is:', bestAcc)\n",
    "        \n",
    "        return bestAcc, averAcc, Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    best = 0\n",
    "    aver = 0\n",
    "\n",
    "    for i in range(9):\n",
    "        starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "        seed_n = np.random.randint(2021)\n",
    "        print('seed is ' + str(seed_n))\n",
    "        random.seed(seed_n)\n",
    "        np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "\n",
    "        print('Subject %d' % (i+1))\n",
    "        exp = EEGCCT(i)\n",
    "\n",
    "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
    "        print('THE BEST ACCURACY IS ' + str(bestAcc))\n",
    "\n",
    "        endtime = datetime.datetime.now()\n",
    "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
    "        best = best + bestAcc\n",
    "        aver = aver + averAcc\n",
    "        if i == 0:\n",
    "            yt = Y_true\n",
    "            yp = Y_pred\n",
    "        else:\n",
    "            yt = torch.cat((yt, Y_true))\n",
    "            yp = torch.cat((yp, Y_pred))\n",
    "\n",
    "\n",
    "    best = best / 9\n",
    "    aver = aver / 9\n",
    "    \n",
    "    print(f\"Mean of best is {best}\")\n",
    "    print(f\"Mean of average is {aver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 852\n",
      "Subject 1\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.6835   Val loss: 0.6844   Test loss: 0.6964   Train acc: 0.6000   Val acc: 0.5644   Test acc: 0.5139\n",
      "Epoch: 1   Train loss: 0.6580   Val loss: 0.6736   Test loss: 0.6846   Train acc: 0.6200   Val acc: 0.5099   Test acc: 0.5556\n",
      "Epoch: 2   Train loss: 0.6607   Val loss: 0.6634   Test loss: 0.6832   Train acc: 0.6000   Val acc: 0.5594   Test acc: 0.5556\n",
      "Epoch: 3   Train loss: 0.6079   Val loss: 0.6200   Test loss: 0.6605   Train acc: 0.6600   Val acc: 0.6782   Test acc: 0.5729\n",
      "Epoch: 4   Train loss: 0.5462   Val loss: 0.5887   Test loss: 0.6157   Train acc: 0.8000   Val acc: 0.6980   Test acc: 0.6146\n",
      "Epoch: 5   Train loss: 0.5464   Val loss: 0.5538   Test loss: 0.5749   Train acc: 0.7800   Val acc: 0.7277   Test acc: 0.6215\n",
      "Epoch: 6   Train loss: 0.4379   Val loss: 0.5406   Test loss: 0.5361   Train acc: 0.8200   Val acc: 0.7475   Test acc: 0.6806\n",
      "Epoch: 7   Train loss: 0.5841   Val loss: 0.5346   Test loss: 0.5180   Train acc: 0.7200   Val acc: 0.7178   Test acc: 0.7049\n",
      "Epoch: 8   Train loss: 0.5337   Val loss: 0.5282   Test loss: 0.5121   Train acc: 0.7200   Val acc: 0.7475   Test acc: 0.6979\n",
      "Epoch: 9   Train loss: 0.4934   Val loss: 0.5289   Test loss: 0.4989   Train acc: 0.7800   Val acc: 0.7475   Test acc: 0.7049\n",
      "Epoch: 10   Train loss: 0.5208   Val loss: 0.5394   Test loss: 0.5168   Train acc: 0.6800   Val acc: 0.7376   Test acc: 0.6944\n",
      "Epoch: 11   Train loss: 0.5961   Val loss: 0.5295   Test loss: 0.5028   Train acc: 0.6800   Val acc: 0.7228   Test acc: 0.7014\n",
      "Epoch: 12   Train loss: 0.5300   Val loss: 0.5324   Test loss: 0.4848   Train acc: 0.7200   Val acc: 0.7723   Test acc: 0.7326\n",
      "Epoch: 13   Train loss: 0.4285   Val loss: 0.5125   Test loss: 0.4767   Train acc: 0.8400   Val acc: 0.7673   Test acc: 0.7674\n",
      "Epoch: 14   Train loss: 0.3662   Val loss: 0.5198   Test loss: 0.5147   Train acc: 0.8800   Val acc: 0.7426   Test acc: 0.7222\n",
      "Epoch: 15   Train loss: 0.5061   Val loss: 0.5164   Test loss: 0.5164   Train acc: 0.7200   Val acc: 0.7228   Test acc: 0.7153\n",
      "Epoch: 16   Train loss: 0.4366   Val loss: 0.4916   Test loss: 0.4761   Train acc: 0.8000   Val acc: 0.7772   Test acc: 0.7639\n",
      "Epoch: 17   Train loss: 0.3121   Val loss: 0.4841   Test loss: 0.4741   Train acc: 0.8600   Val acc: 0.7673   Test acc: 0.7743\n",
      "Epoch: 18   Train loss: 0.4170   Val loss: 0.5022   Test loss: 0.5133   Train acc: 0.7800   Val acc: 0.7525   Test acc: 0.7465\n",
      "Epoch: 19   Train loss: 0.4096   Val loss: 0.5009   Test loss: 0.4710   Train acc: 0.8000   Val acc: 0.7426   Test acc: 0.7778\n",
      "Epoch: 20   Train loss: 0.3791   Val loss: 0.5126   Test loss: 0.4825   Train acc: 0.8400   Val acc: 0.7723   Test acc: 0.7778\n",
      "Epoch: 21   Train loss: 0.4211   Val loss: 0.4959   Test loss: 0.4497   Train acc: 0.7800   Val acc: 0.7574   Test acc: 0.7986\n",
      "Epoch: 22   Train loss: 0.4563   Val loss: 0.4997   Test loss: 0.4798   Train acc: 0.7800   Val acc: 0.7624   Test acc: 0.7674\n",
      "Epoch: 23   Train loss: 0.4476   Val loss: 0.4876   Test loss: 0.4912   Train acc: 0.7800   Val acc: 0.7723   Test acc: 0.7674\n",
      "Epoch: 24   Train loss: 0.3118   Val loss: 0.4952   Test loss: 0.4625   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.7847\n",
      "The average accuracy is: 0.7005555555555557\n",
      "The best accuracy is: 0.7986111111111112\n",
      "THE BEST ACCURACY IS 0.7986111111111112\n",
      "subject 1 duration: 0:01:10.683396\n",
      "seed is 922\n",
      "Subject 2\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.3348   Val loss: 0.4746   Test loss: 0.4768   Train acc: 0.8800   Val acc: 0.7921   Test acc: 0.7708\n",
      "Epoch: 1   Train loss: 0.3239   Val loss: 0.4628   Test loss: 0.4951   Train acc: 0.8400   Val acc: 0.7871   Test acc: 0.7604\n",
      "Epoch: 2   Train loss: 0.3536   Val loss: 0.4576   Test loss: 0.5170   Train acc: 0.8000   Val acc: 0.8069   Test acc: 0.7500\n",
      "Epoch: 3   Train loss: 0.2905   Val loss: 0.4763   Test loss: 0.5406   Train acc: 0.9000   Val acc: 0.7822   Test acc: 0.7396\n",
      "Epoch: 4   Train loss: 0.4327   Val loss: 0.4800   Test loss: 0.5455   Train acc: 0.8000   Val acc: 0.7772   Test acc: 0.7431\n",
      "Epoch: 5   Train loss: 0.2345   Val loss: 0.5036   Test loss: 0.5935   Train acc: 0.9200   Val acc: 0.7574   Test acc: 0.7014\n",
      "Epoch: 6   Train loss: 0.3374   Val loss: 0.4855   Test loss: 0.5635   Train acc: 0.8800   Val acc: 0.8069   Test acc: 0.7188\n",
      "Epoch: 7   Train loss: 0.3944   Val loss: 0.4860   Test loss: 0.5917   Train acc: 0.8000   Val acc: 0.7574   Test acc: 0.7014\n",
      "Epoch: 8   Train loss: 0.2420   Val loss: 0.4821   Test loss: 0.6021   Train acc: 0.9400   Val acc: 0.8020   Test acc: 0.6944\n",
      "Epoch: 9   Train loss: 0.2339   Val loss: 0.4876   Test loss: 0.6330   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.6840\n",
      "Epoch: 10   Train loss: 0.2945   Val loss: 0.5160   Test loss: 0.6514   Train acc: 0.8400   Val acc: 0.7723   Test acc: 0.6771\n",
      "Epoch: 11   Train loss: 0.3085   Val loss: 0.5012   Test loss: 0.6217   Train acc: 0.8600   Val acc: 0.7624   Test acc: 0.6944\n",
      "Epoch: 12   Train loss: 0.2328   Val loss: 0.5041   Test loss: 0.6434   Train acc: 0.9000   Val acc: 0.7772   Test acc: 0.6632\n",
      "Epoch: 13   Train loss: 0.2457   Val loss: 0.5312   Test loss: 0.6676   Train acc: 0.9400   Val acc: 0.7723   Test acc: 0.6840\n",
      "Epoch: 14   Train loss: 0.2902   Val loss: 0.5173   Test loss: 0.6817   Train acc: 0.8600   Val acc: 0.7772   Test acc: 0.6667\n",
      "Epoch: 15   Train loss: 0.3198   Val loss: 0.5303   Test loss: 0.6819   Train acc: 0.8600   Val acc: 0.7525   Test acc: 0.6771\n",
      "Epoch: 16   Train loss: 0.1991   Val loss: 0.5268   Test loss: 0.6749   Train acc: 0.9200   Val acc: 0.7574   Test acc: 0.6944\n",
      "Epoch: 17   Train loss: 0.3598   Val loss: 0.5236   Test loss: 0.6858   Train acc: 0.8000   Val acc: 0.7673   Test acc: 0.6806\n",
      "Epoch: 18   Train loss: 0.2731   Val loss: 0.5159   Test loss: 0.6846   Train acc: 0.9200   Val acc: 0.7673   Test acc: 0.6424\n",
      "Epoch: 19   Train loss: 0.2975   Val loss: 0.5318   Test loss: 0.7566   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.6528\n",
      "Epoch: 20   Train loss: 0.3877   Val loss: 0.5173   Test loss: 0.6945   Train acc: 0.8600   Val acc: 0.7723   Test acc: 0.6771\n",
      "Epoch: 21   Train loss: 0.2195   Val loss: 0.5268   Test loss: 0.6987   Train acc: 0.9200   Val acc: 0.7871   Test acc: 0.7049\n",
      "Epoch: 22   Train loss: 0.2135   Val loss: 0.5283   Test loss: 0.7135   Train acc: 0.9000   Val acc: 0.7723   Test acc: 0.6771\n",
      "Epoch: 23   Train loss: 0.2611   Val loss: 0.5731   Test loss: 0.7406   Train acc: 0.9000   Val acc: 0.7673   Test acc: 0.6806\n",
      "Epoch: 24   Train loss: 0.2339   Val loss: 0.5930   Test loss: 0.7713   Train acc: 0.9000   Val acc: 0.7426   Test acc: 0.6528\n",
      "The average accuracy is: 0.6955555555555557\n",
      "The best accuracy is: 0.7708333333333334\n",
      "THE BEST ACCURACY IS 0.7708333333333334\n",
      "subject 2 duration: 0:01:10.902630\n",
      "seed is 1056\n",
      "Subject 3\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2441   Val loss: 0.6112   Test loss: 0.0706   Train acc: 0.8800   Val acc: 0.7426   Test acc: 0.9757\n",
      "Epoch: 1   Train loss: 0.4550   Val loss: 0.6140   Test loss: 0.0704   Train acc: 0.8200   Val acc: 0.7475   Test acc: 0.9826\n",
      "Epoch: 2   Train loss: 0.3269   Val loss: 0.6243   Test loss: 0.0743   Train acc: 0.8800   Val acc: 0.7178   Test acc: 0.9757\n",
      "Epoch: 3   Train loss: 0.3458   Val loss: 0.6320   Test loss: 0.0751   Train acc: 0.8800   Val acc: 0.7327   Test acc: 0.9792\n",
      "Epoch: 4   Train loss: 0.2218   Val loss: 0.6368   Test loss: 0.0924   Train acc: 0.9000   Val acc: 0.7327   Test acc: 0.9688\n",
      "Epoch: 5   Train loss: 0.2776   Val loss: 0.6253   Test loss: 0.0879   Train acc: 0.9000   Val acc: 0.7475   Test acc: 0.9722\n",
      "Epoch: 6   Train loss: 0.3048   Val loss: 0.6253   Test loss: 0.0843   Train acc: 0.8600   Val acc: 0.7574   Test acc: 0.9722\n",
      "Epoch: 7   Train loss: 0.1989   Val loss: 0.6449   Test loss: 0.0883   Train acc: 0.9600   Val acc: 0.7228   Test acc: 0.9757\n",
      "Epoch: 8   Train loss: 0.1975   Val loss: 0.6414   Test loss: 0.0823   Train acc: 0.9200   Val acc: 0.7129   Test acc: 0.9688\n",
      "Epoch: 9   Train loss: 0.2136   Val loss: 0.6450   Test loss: 0.0749   Train acc: 0.9000   Val acc: 0.7030   Test acc: 0.9722\n",
      "Epoch: 10   Train loss: 0.3236   Val loss: 0.6327   Test loss: 0.1011   Train acc: 0.8200   Val acc: 0.7327   Test acc: 0.9618\n",
      "Epoch: 11   Train loss: 0.1948   Val loss: 0.6443   Test loss: 0.0951   Train acc: 0.9400   Val acc: 0.7327   Test acc: 0.9653\n",
      "Epoch: 12   Train loss: 0.3045   Val loss: 0.6586   Test loss: 0.0986   Train acc: 0.8600   Val acc: 0.7129   Test acc: 0.9618\n",
      "Epoch: 13   Train loss: 0.2848   Val loss: 0.6867   Test loss: 0.0893   Train acc: 0.9000   Val acc: 0.6931   Test acc: 0.9653\n",
      "Epoch: 14   Train loss: 0.3948   Val loss: 0.6436   Test loss: 0.0852   Train acc: 0.8200   Val acc: 0.7327   Test acc: 0.9722\n",
      "Epoch: 15   Train loss: 0.2872   Val loss: 0.6385   Test loss: 0.0978   Train acc: 0.9200   Val acc: 0.7475   Test acc: 0.9583\n",
      "Epoch: 16   Train loss: 0.2207   Val loss: 0.6484   Test loss: 0.0936   Train acc: 0.9200   Val acc: 0.7376   Test acc: 0.9583\n",
      "Epoch: 17   Train loss: 0.2292   Val loss: 0.6468   Test loss: 0.0924   Train acc: 0.8800   Val acc: 0.7228   Test acc: 0.9653\n",
      "Epoch: 18   Train loss: 0.1949   Val loss: 0.6842   Test loss: 0.0864   Train acc: 0.9200   Val acc: 0.7129   Test acc: 0.9653\n",
      "Epoch: 19   Train loss: 0.2664   Val loss: 0.6777   Test loss: 0.0994   Train acc: 0.8800   Val acc: 0.7079   Test acc: 0.9618\n",
      "Epoch: 20   Train loss: 0.1773   Val loss: 0.6613   Test loss: 0.0903   Train acc: 0.9600   Val acc: 0.7277   Test acc: 0.9722\n",
      "Epoch: 21   Train loss: 0.1739   Val loss: 0.6988   Test loss: 0.0956   Train acc: 0.9400   Val acc: 0.6881   Test acc: 0.9653\n",
      "Epoch: 22   Train loss: 0.2621   Val loss: 0.6939   Test loss: 0.0948   Train acc: 0.9000   Val acc: 0.7376   Test acc: 0.9653\n",
      "Epoch: 23   Train loss: 0.2831   Val loss: 0.6703   Test loss: 0.0968   Train acc: 0.8200   Val acc: 0.7277   Test acc: 0.9618\n",
      "Epoch: 24   Train loss: 0.2168   Val loss: 0.6363   Test loss: 0.0888   Train acc: 0.9200   Val acc: 0.7277   Test acc: 0.9757\n",
      "The average accuracy is: 0.9687500000000001\n",
      "The best accuracy is: 0.9826388888888888\n",
      "THE BEST ACCURACY IS 0.9826388888888888\n",
      "subject 3 duration: 0:01:10.936971\n",
      "seed is 908\n",
      "Subject 4\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1494   Val loss: 0.5560   Test loss: 0.1285   Train acc: 0.9200   Val acc: 0.7673   Test acc: 0.9618\n",
      "Epoch: 1   Train loss: 0.1746   Val loss: 0.5514   Test loss: 0.1404   Train acc: 0.9400   Val acc: 0.7871   Test acc: 0.9549\n",
      "Epoch: 2   Train loss: 0.0901   Val loss: 0.6192   Test loss: 0.1411   Train acc: 0.9800   Val acc: 0.7475   Test acc: 0.9583\n",
      "Epoch: 3   Train loss: 0.2208   Val loss: 0.6000   Test loss: 0.1815   Train acc: 0.8800   Val acc: 0.7723   Test acc: 0.9340\n",
      "Epoch: 4   Train loss: 0.3567   Val loss: 0.6300   Test loss: 0.1687   Train acc: 0.9200   Val acc: 0.7475   Test acc: 0.9410\n",
      "Epoch: 5   Train loss: 0.2367   Val loss: 0.5840   Test loss: 0.1505   Train acc: 0.8800   Val acc: 0.7624   Test acc: 0.9479\n",
      "Epoch: 6   Train loss: 0.1824   Val loss: 0.5900   Test loss: 0.1391   Train acc: 0.9600   Val acc: 0.8020   Test acc: 0.9479\n",
      "Epoch: 7   Train loss: 0.2518   Val loss: 0.5890   Test loss: 0.1734   Train acc: 0.9000   Val acc: 0.7723   Test acc: 0.9271\n",
      "Epoch: 8   Train loss: 0.2058   Val loss: 0.6158   Test loss: 0.1681   Train acc: 0.9000   Val acc: 0.7574   Test acc: 0.9444\n",
      "Epoch: 9   Train loss: 0.2280   Val loss: 0.5711   Test loss: 0.1815   Train acc: 0.9200   Val acc: 0.7673   Test acc: 0.9375\n",
      "Epoch: 10   Train loss: 0.1828   Val loss: 0.6418   Test loss: 0.1757   Train acc: 0.9400   Val acc: 0.7624   Test acc: 0.9306\n",
      "Epoch: 11   Train loss: 0.1809   Val loss: 0.6399   Test loss: 0.1680   Train acc: 0.9200   Val acc: 0.7624   Test acc: 0.9375\n",
      "Epoch: 12   Train loss: 0.2325   Val loss: 0.6179   Test loss: 0.1803   Train acc: 0.9600   Val acc: 0.7871   Test acc: 0.9410\n",
      "Epoch: 13   Train loss: 0.2379   Val loss: 0.6459   Test loss: 0.1836   Train acc: 0.9400   Val acc: 0.7525   Test acc: 0.9340\n",
      "Epoch: 14   Train loss: 0.1814   Val loss: 0.6345   Test loss: 0.1789   Train acc: 0.9400   Val acc: 0.7723   Test acc: 0.9410\n",
      "Epoch: 15   Train loss: 0.2431   Val loss: 0.6828   Test loss: 0.1934   Train acc: 0.9400   Val acc: 0.7723   Test acc: 0.9340\n",
      "Epoch: 16   Train loss: 0.0971   Val loss: 0.6883   Test loss: 0.2910   Train acc: 0.9600   Val acc: 0.7376   Test acc: 0.9062\n",
      "Epoch: 17   Train loss: 0.0992   Val loss: 0.6901   Test loss: 0.2245   Train acc: 0.9600   Val acc: 0.7574   Test acc: 0.9236\n",
      "Epoch: 18   Train loss: 0.1592   Val loss: 0.6817   Test loss: 0.2224   Train acc: 0.9400   Val acc: 0.7228   Test acc: 0.9340\n",
      "Epoch: 19   Train loss: 0.2441   Val loss: 0.6385   Test loss: 0.2102   Train acc: 0.8200   Val acc: 0.7525   Test acc: 0.9375\n",
      "Epoch: 20   Train loss: 0.1153   Val loss: 0.6911   Test loss: 0.2834   Train acc: 0.9400   Val acc: 0.7475   Test acc: 0.8958\n",
      "Epoch: 21   Train loss: 0.1722   Val loss: 0.6766   Test loss: 0.2557   Train acc: 0.9400   Val acc: 0.7624   Test acc: 0.9167\n",
      "Epoch: 22   Train loss: 0.1146   Val loss: 0.7100   Test loss: 0.2187   Train acc: 0.9800   Val acc: 0.7525   Test acc: 0.9201\n",
      "Epoch: 23   Train loss: 0.2426   Val loss: 0.6748   Test loss: 0.2054   Train acc: 0.9600   Val acc: 0.7624   Test acc: 0.9271\n",
      "Epoch: 24   Train loss: 0.1719   Val loss: 0.6780   Test loss: 0.1998   Train acc: 0.9000   Val acc: 0.7327   Test acc: 0.9375\n",
      "The average accuracy is: 0.9348611111111111\n",
      "The best accuracy is: 0.9618055555555556\n",
      "THE BEST ACCURACY IS 0.9618055555555556\n",
      "subject 4 duration: 0:01:12.337013\n",
      "seed is 1680\n",
      "Subject 5\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2165   Val loss: 0.5467   Test loss: 0.1182   Train acc: 0.9400   Val acc: 0.7871   Test acc: 0.9618\n",
      "Epoch: 1   Train loss: 0.0845   Val loss: 0.5108   Test loss: 0.1337   Train acc: 0.9800   Val acc: 0.7921   Test acc: 0.9549\n",
      "Epoch: 2   Train loss: 0.2038   Val loss: 0.5787   Test loss: 0.1351   Train acc: 0.9200   Val acc: 0.8069   Test acc: 0.9549\n",
      "Epoch: 3   Train loss: 0.1613   Val loss: 0.5720   Test loss: 0.1379   Train acc: 0.9400   Val acc: 0.8069   Test acc: 0.9653\n",
      "Epoch: 4   Train loss: 0.2595   Val loss: 0.5517   Test loss: 0.1562   Train acc: 0.9000   Val acc: 0.7921   Test acc: 0.9444\n",
      "Epoch: 5   Train loss: 0.1894   Val loss: 0.5907   Test loss: 0.1520   Train acc: 0.9000   Val acc: 0.7921   Test acc: 0.9514\n",
      "Epoch: 6   Train loss: 0.1373   Val loss: 0.5567   Test loss: 0.1385   Train acc: 0.9600   Val acc: 0.8218   Test acc: 0.9618\n",
      "Epoch: 7   Train loss: 0.0954   Val loss: 0.5952   Test loss: 0.1208   Train acc: 0.9800   Val acc: 0.7772   Test acc: 0.9618\n",
      "Epoch: 8   Train loss: 0.1912   Val loss: 0.5949   Test loss: 0.1128   Train acc: 0.9200   Val acc: 0.7822   Test acc: 0.9583\n",
      "Epoch: 9   Train loss: 0.1774   Val loss: 0.5726   Test loss: 0.1248   Train acc: 0.9600   Val acc: 0.8020   Test acc: 0.9583\n",
      "Epoch: 10   Train loss: 0.1796   Val loss: 0.5637   Test loss: 0.1298   Train acc: 0.9000   Val acc: 0.7871   Test acc: 0.9618\n",
      "Epoch: 11   Train loss: 0.0880   Val loss: 0.5959   Test loss: 0.1664   Train acc: 0.9600   Val acc: 0.7921   Test acc: 0.9410\n",
      "Epoch: 12   Train loss: 0.1716   Val loss: 0.5354   Test loss: 0.1714   Train acc: 0.9600   Val acc: 0.7871   Test acc: 0.9306\n",
      "Epoch: 13   Train loss: 0.3472   Val loss: 0.5866   Test loss: 0.1767   Train acc: 0.8800   Val acc: 0.7970   Test acc: 0.9306\n",
      "Epoch: 14   Train loss: 0.0997   Val loss: 0.6098   Test loss: 0.1690   Train acc: 0.9600   Val acc: 0.8119   Test acc: 0.9375\n",
      "Epoch: 15   Train loss: 0.1167   Val loss: 0.5638   Test loss: 0.1676   Train acc: 0.9800   Val acc: 0.7970   Test acc: 0.9340\n",
      "Epoch: 16   Train loss: 0.0492   Val loss: 0.6171   Test loss: 0.1890   Train acc: 1.0000   Val acc: 0.8020   Test acc: 0.9306\n",
      "Epoch: 17   Train loss: 0.0925   Val loss: 0.6172   Test loss: 0.1772   Train acc: 0.9800   Val acc: 0.8218   Test acc: 0.9271\n",
      "Epoch: 18   Train loss: 0.1853   Val loss: 0.6159   Test loss: 0.1874   Train acc: 0.9200   Val acc: 0.8317   Test acc: 0.9271\n",
      "Epoch: 19   Train loss: 0.0975   Val loss: 0.6251   Test loss: 0.2020   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.9375\n",
      "Epoch: 20   Train loss: 0.0770   Val loss: 0.6799   Test loss: 0.1838   Train acc: 0.9800   Val acc: 0.7426   Test acc: 0.9306\n",
      "Epoch: 21   Train loss: 0.2529   Val loss: 0.6419   Test loss: 0.2140   Train acc: 0.9000   Val acc: 0.8069   Test acc: 0.9201\n",
      "Epoch: 22   Train loss: 0.0535   Val loss: 0.6491   Test loss: 0.1766   Train acc: 0.9800   Val acc: 0.7772   Test acc: 0.9340\n",
      "Epoch: 23   Train loss: 0.0731   Val loss: 0.6304   Test loss: 0.2227   Train acc: 0.9800   Val acc: 0.8069   Test acc: 0.9236\n",
      "Epoch: 24   Train loss: 0.0529   Val loss: 0.6511   Test loss: 0.2013   Train acc: 0.9800   Val acc: 0.7723   Test acc: 0.9306\n",
      "The average accuracy is: 0.9427777777777778\n",
      "The best accuracy is: 0.9652777777777778\n",
      "THE BEST ACCURACY IS 0.9652777777777778\n",
      "subject 5 duration: 0:01:10.487913\n",
      "seed is 1151\n",
      "Subject 6\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1487   Val loss: 0.5799   Test loss: 0.1235   Train acc: 0.9400   Val acc: 0.8069   Test acc: 0.9722\n",
      "Epoch: 1   Train loss: 0.0974   Val loss: 0.5424   Test loss: 0.1312   Train acc: 0.9600   Val acc: 0.8069   Test acc: 0.9688\n",
      "Epoch: 2   Train loss: 0.1680   Val loss: 0.5285   Test loss: 0.1437   Train acc: 0.9000   Val acc: 0.7822   Test acc: 0.9688\n",
      "Epoch: 3   Train loss: 0.1781   Val loss: 0.5152   Test loss: 0.1374   Train acc: 0.9200   Val acc: 0.8069   Test acc: 0.9653\n",
      "Epoch: 4   Train loss: 0.1165   Val loss: 0.5236   Test loss: 0.1567   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.9549\n",
      "Epoch: 5   Train loss: 0.1006   Val loss: 0.5050   Test loss: 0.1442   Train acc: 0.9200   Val acc: 0.8069   Test acc: 0.9618\n",
      "Epoch: 6   Train loss: 0.1470   Val loss: 0.5165   Test loss: 0.1401   Train acc: 0.9400   Val acc: 0.8069   Test acc: 0.9722\n",
      "Epoch: 7   Train loss: 0.0756   Val loss: 0.5491   Test loss: 0.1540   Train acc: 0.9600   Val acc: 0.8069   Test acc: 0.9549\n",
      "Epoch: 8   Train loss: 0.1658   Val loss: 0.5347   Test loss: 0.1582   Train acc: 0.9600   Val acc: 0.7921   Test acc: 0.9583\n",
      "Epoch: 9   Train loss: 0.1392   Val loss: 0.5537   Test loss: 0.1499   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.9583\n",
      "Epoch: 10   Train loss: 0.1999   Val loss: 0.5798   Test loss: 0.1718   Train acc: 0.9200   Val acc: 0.7723   Test acc: 0.9549\n",
      "Epoch: 11   Train loss: 0.0508   Val loss: 0.6385   Test loss: 0.1637   Train acc: 0.9800   Val acc: 0.7921   Test acc: 0.9618\n",
      "Epoch: 12   Train loss: 0.1372   Val loss: 0.6001   Test loss: 0.2049   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.9306\n",
      "Epoch: 13   Train loss: 0.0636   Val loss: 0.5455   Test loss: 0.1838   Train acc: 0.9800   Val acc: 0.8119   Test acc: 0.9479\n",
      "Epoch: 14   Train loss: 0.1922   Val loss: 0.5424   Test loss: 0.1925   Train acc: 0.9200   Val acc: 0.7921   Test acc: 0.9410\n",
      "Epoch: 15   Train loss: 0.3126   Val loss: 0.6145   Test loss: 0.1630   Train acc: 0.9200   Val acc: 0.7871   Test acc: 0.9653\n",
      "Epoch: 16   Train loss: 0.1229   Val loss: 0.6114   Test loss: 0.1964   Train acc: 0.9600   Val acc: 0.7574   Test acc: 0.9375\n",
      "Epoch: 17   Train loss: 0.0403   Val loss: 0.5885   Test loss: 0.1987   Train acc: 0.9800   Val acc: 0.7822   Test acc: 0.9340\n",
      "Epoch: 18   Train loss: 0.0552   Val loss: 0.6387   Test loss: 0.1881   Train acc: 1.0000   Val acc: 0.7723   Test acc: 0.9410\n",
      "Epoch: 19   Train loss: 0.0563   Val loss: 0.5541   Test loss: 0.2675   Train acc: 0.9600   Val acc: 0.8020   Test acc: 0.8889\n",
      "Epoch: 20   Train loss: 0.0913   Val loss: 0.5844   Test loss: 0.2042   Train acc: 0.9800   Val acc: 0.7871   Test acc: 0.9375\n",
      "Epoch: 21   Train loss: 0.2772   Val loss: 0.5761   Test loss: 0.2481   Train acc: 0.9000   Val acc: 0.7822   Test acc: 0.9236\n",
      "Epoch: 22   Train loss: 0.0956   Val loss: 0.6080   Test loss: 0.1858   Train acc: 0.9600   Val acc: 0.7822   Test acc: 0.9410\n",
      "Epoch: 23   Train loss: 0.0467   Val loss: 0.6186   Test loss: 0.1830   Train acc: 1.0000   Val acc: 0.7822   Test acc: 0.9479\n",
      "Epoch: 24   Train loss: 0.2034   Val loss: 0.5946   Test loss: 0.2091   Train acc: 0.9400   Val acc: 0.7921   Test acc: 0.9306\n",
      "The average accuracy is: 0.9487500000000001\n",
      "The best accuracy is: 0.9722222222222222\n",
      "THE BEST ACCURACY IS 0.9722222222222222\n",
      "subject 6 duration: 0:01:11.916609\n",
      "seed is 286\n",
      "Subject 7\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.2252   Val loss: 0.4427   Test loss: 0.1267   Train acc: 0.9000   Val acc: 0.8416   Test acc: 0.9583\n",
      "Epoch: 1   Train loss: 0.0936   Val loss: 0.4653   Test loss: 0.1288   Train acc: 0.9800   Val acc: 0.8317   Test acc: 0.9618\n",
      "Epoch: 2   Train loss: 0.0386   Val loss: 0.4331   Test loss: 0.1311   Train acc: 1.0000   Val acc: 0.8465   Test acc: 0.9618\n",
      "Epoch: 3   Train loss: 0.0820   Val loss: 0.4474   Test loss: 0.1484   Train acc: 0.9400   Val acc: 0.8366   Test acc: 0.9618\n",
      "Epoch: 4   Train loss: 0.0762   Val loss: 0.4743   Test loss: 0.1338   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9618\n",
      "Epoch: 5   Train loss: 0.0967   Val loss: 0.4813   Test loss: 0.1501   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.9549\n",
      "Epoch: 6   Train loss: 0.2409   Val loss: 0.5138   Test loss: 0.1660   Train acc: 0.9200   Val acc: 0.8267   Test acc: 0.9549\n",
      "Epoch: 7   Train loss: 0.1746   Val loss: 0.5316   Test loss: 0.1364   Train acc: 0.9600   Val acc: 0.7970   Test acc: 0.9653\n",
      "Epoch: 8   Train loss: 0.0862   Val loss: 0.4757   Test loss: 0.1568   Train acc: 0.9600   Val acc: 0.8218   Test acc: 0.9514\n",
      "Epoch: 9   Train loss: 0.0687   Val loss: 0.4967   Test loss: 0.1537   Train acc: 0.9800   Val acc: 0.8168   Test acc: 0.9549\n",
      "Epoch: 10   Train loss: 0.1081   Val loss: 0.4743   Test loss: 0.1553   Train acc: 0.9200   Val acc: 0.8267   Test acc: 0.9479\n",
      "Epoch: 11   Train loss: 0.0622   Val loss: 0.4345   Test loss: 0.1609   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.9479\n",
      "Epoch: 12   Train loss: 0.0669   Val loss: 0.4857   Test loss: 0.1630   Train acc: 0.9800   Val acc: 0.8119   Test acc: 0.9549\n",
      "Epoch: 13   Train loss: 0.1620   Val loss: 0.4678   Test loss: 0.1693   Train acc: 0.9200   Val acc: 0.8267   Test acc: 0.9583\n",
      "Epoch: 14   Train loss: 0.0968   Val loss: 0.4960   Test loss: 0.1517   Train acc: 0.9400   Val acc: 0.8267   Test acc: 0.9549\n",
      "Epoch: 15   Train loss: 0.1044   Val loss: 0.4687   Test loss: 0.1537   Train acc: 0.9400   Val acc: 0.8218   Test acc: 0.9653\n",
      "Epoch: 16   Train loss: 0.1417   Val loss: 0.4838   Test loss: 0.1647   Train acc: 0.9400   Val acc: 0.8168   Test acc: 0.9583\n",
      "Epoch: 17   Train loss: 0.0387   Val loss: 0.4607   Test loss: 0.1594   Train acc: 0.9800   Val acc: 0.8168   Test acc: 0.9618\n",
      "Epoch: 18   Train loss: 0.0510   Val loss: 0.4643   Test loss: 0.1558   Train acc: 0.9800   Val acc: 0.8416   Test acc: 0.9514\n",
      "Epoch: 19   Train loss: 0.1606   Val loss: 0.4804   Test loss: 0.1686   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.9514\n",
      "Epoch: 20   Train loss: 0.0850   Val loss: 0.5144   Test loss: 0.1833   Train acc: 0.9600   Val acc: 0.8465   Test acc: 0.9549\n",
      "Epoch: 21   Train loss: 0.1171   Val loss: 0.4618   Test loss: 0.1611   Train acc: 0.9800   Val acc: 0.8317   Test acc: 0.9444\n",
      "Epoch: 22   Train loss: 0.1081   Val loss: 0.5133   Test loss: 0.1456   Train acc: 0.9600   Val acc: 0.8119   Test acc: 0.9549\n",
      "Epoch: 23   Train loss: 0.0628   Val loss: 0.5253   Test loss: 0.1783   Train acc: 0.9800   Val acc: 0.8317   Test acc: 0.9444\n",
      "Epoch: 24   Train loss: 0.0249   Val loss: 0.4506   Test loss: 0.1893   Train acc: 1.0000   Val acc: 0.8218   Test acc: 0.9410\n",
      "The average accuracy is: 0.9551388888888888\n",
      "The best accuracy is: 0.9652777777777778\n",
      "THE BEST ACCURACY IS 0.9652777777777778\n",
      "subject 7 duration: 0:01:09.724049\n",
      "seed is 1949\n",
      "Subject 8\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.1659   Val loss: 0.5826   Test loss: 0.0314   Train acc: 0.9200   Val acc: 0.8267   Test acc: 0.9861\n",
      "Epoch: 1   Train loss: 0.0676   Val loss: 0.5304   Test loss: 0.0200   Train acc: 0.9600   Val acc: 0.8218   Test acc: 0.9896\n",
      "Epoch: 2   Train loss: 0.0889   Val loss: 0.5608   Test loss: 0.0173   Train acc: 0.9600   Val acc: 0.8416   Test acc: 0.9931\n",
      "Epoch: 3   Train loss: 0.0818   Val loss: 0.5340   Test loss: 0.0180   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9896\n",
      "Epoch: 4   Train loss: 0.0461   Val loss: 0.5025   Test loss: 0.0371   Train acc: 0.9800   Val acc: 0.8465   Test acc: 0.9861\n",
      "Epoch: 5   Train loss: 0.0857   Val loss: 0.5132   Test loss: 0.0385   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.9861\n",
      "Epoch: 6   Train loss: 0.1564   Val loss: 0.5898   Test loss: 0.0195   Train acc: 0.9400   Val acc: 0.8119   Test acc: 0.9896\n",
      "Epoch: 7   Train loss: 0.0327   Val loss: 0.5298   Test loss: 0.0316   Train acc: 1.0000   Val acc: 0.8317   Test acc: 0.9896\n",
      "Epoch: 8   Train loss: 0.0571   Val loss: 0.6042   Test loss: 0.0332   Train acc: 1.0000   Val acc: 0.8317   Test acc: 0.9861\n",
      "Epoch: 9   Train loss: 0.0882   Val loss: 0.5308   Test loss: 0.0231   Train acc: 0.9600   Val acc: 0.8317   Test acc: 0.9861\n",
      "Epoch: 10   Train loss: 0.1070   Val loss: 0.5460   Test loss: 0.0143   Train acc: 0.9600   Val acc: 0.8168   Test acc: 0.9965\n",
      "Epoch: 11   Train loss: 0.0327   Val loss: 0.4944   Test loss: 0.0159   Train acc: 1.0000   Val acc: 0.8465   Test acc: 0.9965\n",
      "Epoch: 12   Train loss: 0.0665   Val loss: 0.5497   Test loss: 0.0303   Train acc: 1.0000   Val acc: 0.8267   Test acc: 0.9861\n",
      "Epoch: 13   Train loss: 0.1409   Val loss: 0.5513   Test loss: 0.0238   Train acc: 0.9600   Val acc: 0.8020   Test acc: 0.9896\n",
      "Epoch: 14   Train loss: 0.0967   Val loss: 0.5347   Test loss: 0.0301   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.9861\n",
      "Epoch: 15   Train loss: 0.0863   Val loss: 0.5217   Test loss: 0.0224   Train acc: 0.9800   Val acc: 0.8366   Test acc: 0.9861\n",
      "Epoch: 16   Train loss: 0.1053   Val loss: 0.5699   Test loss: 0.0316   Train acc: 0.9600   Val acc: 0.8267   Test acc: 0.9861\n",
      "Epoch: 17   Train loss: 0.1352   Val loss: 0.6018   Test loss: 0.0200   Train acc: 0.9400   Val acc: 0.8069   Test acc: 0.9896\n",
      "Epoch: 18   Train loss: 0.1633   Val loss: 0.5560   Test loss: 0.0232   Train acc: 0.9400   Val acc: 0.8168   Test acc: 0.9896\n",
      "Epoch: 19   Train loss: 0.0476   Val loss: 0.5707   Test loss: 0.0211   Train acc: 0.9600   Val acc: 0.8218   Test acc: 0.9931\n",
      "Epoch: 20   Train loss: 0.2013   Val loss: 0.5616   Test loss: 0.0306   Train acc: 0.9200   Val acc: 0.8218   Test acc: 0.9861\n",
      "Epoch: 21   Train loss: 0.1608   Val loss: 0.5599   Test loss: 0.0402   Train acc: 0.9200   Val acc: 0.8020   Test acc: 0.9861\n",
      "Epoch: 22   Train loss: 0.1100   Val loss: 0.5508   Test loss: 0.0291   Train acc: 0.9400   Val acc: 0.8317   Test acc: 0.9896\n",
      "Epoch: 23   Train loss: 0.0955   Val loss: 0.4903   Test loss: 0.0324   Train acc: 0.9800   Val acc: 0.8515   Test acc: 0.9861\n",
      "Epoch: 24   Train loss: 0.1017   Val loss: 0.5269   Test loss: 0.0251   Train acc: 0.9600   Val acc: 0.8366   Test acc: 0.9861\n",
      "The average accuracy is: 0.988611111111111\n",
      "The best accuracy is: 0.9965277777777778\n",
      "THE BEST ACCURACY IS 0.9965277777777778\n",
      "subject 8 duration: 0:01:12.393162\n",
      "seed is 2003\n",
      "Subject 9\n",
      "Number of parameters:  153219\n",
      "Dataset:  datasets/aBNCI2014001R.pickle\n",
      "Epoch: 0   Train loss: 0.0603   Val loss: 0.0946   Test loss: 1.5330   Train acc: 0.9649   Val acc: 0.9610   Test acc: 0.6771\n",
      "Epoch: 1   Train loss: 0.1385   Val loss: 0.1011   Test loss: 1.5411   Train acc: 0.9649   Val acc: 0.9697   Test acc: 0.6875\n",
      "Epoch: 2   Train loss: 0.1370   Val loss: 0.1071   Test loss: 1.7456   Train acc: 0.9474   Val acc: 0.9567   Test acc: 0.6493\n",
      "Epoch: 3   Train loss: 0.1844   Val loss: 0.0982   Test loss: 1.6150   Train acc: 0.9123   Val acc: 0.9610   Test acc: 0.6528\n",
      "Epoch: 4   Train loss: 0.0259   Val loss: 0.1105   Test loss: 1.6776   Train acc: 1.0000   Val acc: 0.9610   Test acc: 0.6562\n",
      "Epoch: 5   Train loss: 0.0593   Val loss: 0.1266   Test loss: 1.4514   Train acc: 0.9825   Val acc: 0.9567   Test acc: 0.6597\n",
      "Epoch: 6   Train loss: 0.1258   Val loss: 0.1155   Test loss: 1.5953   Train acc: 0.9474   Val acc: 0.9654   Test acc: 0.6632\n",
      "Epoch: 7   Train loss: 0.0814   Val loss: 0.0976   Test loss: 1.4793   Train acc: 0.9825   Val acc: 0.9610   Test acc: 0.6771\n",
      "Epoch: 8   Train loss: 0.0673   Val loss: 0.1155   Test loss: 1.6956   Train acc: 0.9825   Val acc: 0.9654   Test acc: 0.6562\n",
      "Epoch: 9   Train loss: 0.1655   Val loss: 0.1068   Test loss: 1.4918   Train acc: 0.9474   Val acc: 0.9610   Test acc: 0.6667\n",
      "Epoch: 10   Train loss: 0.1063   Val loss: 0.0964   Test loss: 1.4718   Train acc: 0.9474   Val acc: 0.9610   Test acc: 0.6701\n",
      "Epoch: 11   Train loss: 0.0595   Val loss: 0.1066   Test loss: 1.4811   Train acc: 0.9649   Val acc: 0.9654   Test acc: 0.6736\n",
      "Epoch: 12   Train loss: 0.0510   Val loss: 0.0946   Test loss: 1.9111   Train acc: 0.9825   Val acc: 0.9654   Test acc: 0.6458\n",
      "Epoch: 13   Train loss: 0.0329   Val loss: 0.1184   Test loss: 1.6950   Train acc: 1.0000   Val acc: 0.9697   Test acc: 0.6597\n",
      "Epoch: 14   Train loss: 0.0956   Val loss: 0.1136   Test loss: 1.4664   Train acc: 0.9474   Val acc: 0.9697   Test acc: 0.6736\n",
      "Epoch: 15   Train loss: 0.0754   Val loss: 0.1143   Test loss: 1.6973   Train acc: 0.9649   Val acc: 0.9610   Test acc: 0.6528\n",
      "Epoch: 16   Train loss: 0.0675   Val loss: 0.1185   Test loss: 1.8750   Train acc: 0.9649   Val acc: 0.9567   Test acc: 0.6181\n",
      "Epoch: 17   Train loss: 0.0329   Val loss: 0.1088   Test loss: 1.8548   Train acc: 1.0000   Val acc: 0.9567   Test acc: 0.6389\n",
      "Epoch: 18   Train loss: 0.0522   Val loss: 0.1181   Test loss: 1.8093   Train acc: 1.0000   Val acc: 0.9610   Test acc: 0.6389\n",
      "Epoch: 19   Train loss: 0.0413   Val loss: 0.1403   Test loss: 1.4982   Train acc: 1.0000   Val acc: 0.9610   Test acc: 0.6597\n",
      "Epoch: 20   Train loss: 0.0645   Val loss: 0.1274   Test loss: 1.6648   Train acc: 0.9649   Val acc: 0.9654   Test acc: 0.6528\n",
      "Epoch: 21   Train loss: 0.1757   Val loss: 0.1310   Test loss: 1.5154   Train acc: 0.9474   Val acc: 0.9697   Test acc: 0.6424\n",
      "Epoch: 22   Train loss: 0.0231   Val loss: 0.1320   Test loss: 1.6417   Train acc: 1.0000   Val acc: 0.9524   Test acc: 0.6597\n",
      "Epoch: 23   Train loss: 0.0694   Val loss: 0.1074   Test loss: 1.7209   Train acc: 0.9825   Val acc: 0.9654   Test acc: 0.6562\n",
      "Epoch: 24   Train loss: 0.1732   Val loss: 0.1217   Test loss: 1.8600   Train acc: 0.9474   Val acc: 0.9654   Test acc: 0.6424\n",
      "The average accuracy is: 0.6572222222222223\n",
      "The best accuracy is: 0.6875\n",
      "THE BEST ACCURACY IS 0.6875\n",
      "subject 9 duration: 0:01:27.118578\n",
      "Mean of best is 0.9000771604938271\n",
      "Mean of average is 0.8658024691358025\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
